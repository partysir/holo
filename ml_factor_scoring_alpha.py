"""
ml_factor_scoring_alpha.py - MLè¯„åˆ†Alphaå¢å¼ºç‰ˆ

æ ¸å¿ƒå¢å¼º:
âœ… 1. ä¸‰åˆ†ç±»æ ‡ç­¾ (Triple Barrier Method)
    - Buy: æœªæ¥æ”¶ç›Š > 5% ä¸”å›æ’¤ < 2%
    - Sell: æœªæ¥æ”¶ç›Š < -2%
    - Hold: éœ‡è¡åŒºé—´
âœ… 2. åŒé‡è¿‡æ»¤æ ‡ç­¾ä¼˜åŒ–
    - ç›¸å¯¹æ”¶ç›Š Top 20% (æˆ˜èƒœå¸‚åœº)
    - ç»å¯¹æ”¶ç›Š > 0 (å‰”é™¤ç†Šå¸‚æŠ—è·Œè‚¡)
âœ… 3. Learning to Rank ç›®æ ‡å‡½æ•°
âœ… 4. æ¨¡å‹é›†æˆ (XGBoost + LightGBM + RandomForest)
âœ… 5. é«˜ç½®ä¿¡åº¦è¿‡æ»¤ (prob > 0.7)
"""

import pandas as pd
import numpy as np
import warnings
from typing import List, Dict, Tuple, Optional
from datetime import datetime, timedelta

warnings.filterwarnings('ignore')

# æœºå™¨å­¦ä¹ åº“
try:
    import xgboost as xgb
    XGBOOST_AVAILABLE = True
except ImportError:
    xgb = None
    XGBOOST_AVAILABLE = False

try:
    import lightgbm as lgb
    LIGHTGBM_AVAILABLE = True
except ImportError:
    lgb = None
    LIGHTGBM_AVAILABLE = False

from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.metrics import roc_auc_score, accuracy_score


class TripleBarrierLabeler:
    """
    âœ¨ ä¸‰åˆ†ç±»æ ‡ç­¾ç”Ÿæˆå™¨ (Triple Barrier Method)
    
    åŸç†: ä¸ä»…çœ‹æ”¶ç›Šï¼Œè¿˜è¦çœ‹é£é™©
    - ç›ˆäºæ¯” > 2:1 æ‰æ ‡è®°ä¸º Buy
    - å¤§å¹…äºæŸæ ‡è®°ä¸º Sell
    - å…¶ä»–ä¸º Holdï¼ˆä¸äº¤æ˜“ï¼‰
    
    ä¼˜åŠ¿:
    - æé«˜èƒœç‡ï¼ˆå®ç¼ºæ¯‹æ»¥ï¼‰
    - é™ä½å›æ’¤
    - ç¬¦åˆå®ç›˜å¿ƒç†
    """
    
    def __init__(self, 
                 profit_threshold=0.05,  # ç›ˆåˆ©é˜ˆå€¼ 5%
                 stop_loss_threshold=-0.02,  # æ­¢æŸé˜ˆå€¼ -2%
                 max_drawdown_threshold=0.02,  # æœ€å¤§å›æ’¤é™åˆ¶ 2%
                 holding_period=5):
        """
        Args:
            profit_threshold: ç›ˆåˆ©é˜ˆå€¼
            stop_loss_threshold: æ­¢æŸé˜ˆå€¼
            max_drawdown_threshold: æŒæœ‰æœŸé—´æœ€å¤§å›æ’¤
            holding_period: æŒæœ‰å‘¨æœŸï¼ˆå¤©ï¼‰
        """
        self.profit_threshold = profit_threshold
        self.stop_loss_threshold = stop_loss_threshold
        self.max_drawdown_threshold = max_drawdown_threshold
        self.holding_period = holding_period
        
        print(f"\nğŸ¯ åˆå§‹åŒ–ä¸‰åˆ†ç±»æ ‡ç­¾ç”Ÿæˆå™¨")
        print(f"   ç›ˆåˆ©ç›®æ ‡: {profit_threshold:.1%}")
        print(f"   æ­¢æŸçº¿: {stop_loss_threshold:.1%}")
        print(f"   æœ€å¤§å›æ’¤: {max_drawdown_threshold:.1%}")
    
    def generate_labels(self, price_data: pd.DataFrame) -> pd.DataFrame:
        """
        ç”Ÿæˆä¸‰åˆ†ç±»æ ‡ç­¾
        
        æ ‡ç­¾å®šä¹‰:
        1 (Buy): è¾¾åˆ°ç›ˆåˆ©ç›®æ ‡ ä¸” å›æ’¤å¯æ§
        -1 (Sell): è§¦å‘æ­¢æŸ
        0 (Hold): éœ‡è¡ï¼Œä¸äº¤æ˜“
        """
        print(f"  ğŸ“Š ç”Ÿæˆä¸‰åˆ†ç±»æ ‡ç­¾ (æŒæœ‰æœŸ: {self.holding_period}å¤©)...")
        
        data = price_data.copy()
        data = data.sort_values(['instrument', 'date']).reset_index(drop=True)
        
        # åˆå§‹åŒ–æ ‡ç­¾
        data['triple_label'] = 0
        data['max_profit'] = np.nan
        data['max_drawdown'] = np.nan
        
        grouped = data.groupby('instrument')
        
        for instrument, group in grouped:
            for i in range(len(group)):
                current_idx = group.index[i]
                current_price = group.iloc[i]['close']
                
                # è·å–æœªæ¥Nå¤©çš„ä»·æ ¼
                future_prices = group.iloc[i+1:i+1+self.holding_period]['close'].values
                
                if len(future_prices) < self.holding_period:
                    continue
                
                # è®¡ç®—æ”¶ç›Šç‡åºåˆ—
                returns = (future_prices - current_price) / current_price
                
                # æœ€å¤§ç›ˆåˆ©
                max_profit = returns.max()
                
                # æœ€å¤§å›æ’¤ï¼ˆä»å½“å‰åˆ°ä»»æ„æ—¶ç‚¹çš„æœ€å¤§ä¸‹è·Œï¼‰
                cummax = np.maximum.accumulate(returns)
                drawdowns = returns - cummax
                max_drawdown = abs(drawdowns.min())
                
                # æœ€ç»ˆæ”¶ç›Š
                final_return = returns[-1]
                
                # æ ‡ç­¾é€»è¾‘
                if (max_profit >= self.profit_threshold and 
                    max_drawdown <= self.max_drawdown_threshold):
                    # Buy: é«˜ç›ˆåˆ© + ä½å›æ’¤
                    label = 1
                elif final_return <= self.stop_loss_threshold:
                    # Sell: è§¦å‘æ­¢æŸ
                    label = -1
                else:
                    # Hold: éœ‡è¡
                    label = 0
                
                data.loc[current_idx, 'triple_label'] = label
                data.loc[current_idx, 'max_profit'] = max_profit
                data.loc[current_idx, 'max_drawdown'] = max_drawdown
        
        # ç»Ÿè®¡æ ‡ç­¾åˆ†å¸ƒ
        label_counts = data['triple_label'].value_counts()
        print(f"  âœ“ æ ‡ç­¾åˆ†å¸ƒ:")
        print(f"     Buy  (1):  {label_counts.get(1, 0):>6d} ({label_counts.get(1, 0)/len(data):.1%})")
        print(f"     Hold (0):  {label_counts.get(0, 0):>6d} ({label_counts.get(0, 0)/len(data):.1%})")
        print(f"     Sell (-1): {label_counts.get(-1, 0):>6d} ({label_counts.get(-1, 0)/len(data):.1%})")
        
        return data


class OptimizedTargetGenerator:
    """
    âœ¨ ä¼˜åŒ–ç›®æ ‡ç”Ÿæˆå™¨
    
    åŒé‡è¿‡æ»¤ç­–ç•¥:
    1. ç›¸å¯¹æ”¶ç›Š Top 20% (Active Return)
    2. ç»å¯¹æ”¶ç›Š > 0 (å‰”é™¤ç†Šå¸‚æŠ—è·Œè‚¡)
    
    æ ¸å¿ƒæ€æƒ³:
    - ç†Šå¸‚ç©ºä»“æ¯”ä¹°æŠ—è·Œè‚¡æ›´å¥½
    - åªåœ¨ä¸Šæ¶¨ä¸­é€‰æœ€å¼ºçš„è‚¡ç¥¨
    """
    
    def __init__(self, top_percentile=0.20, min_absolute_return=0.0):
        """
        Args:
            top_percentile: ç›¸å¯¹æ”¶ç›ŠTopæ¯”ä¾‹
            min_absolute_return: æœ€å°ç»å¯¹æ”¶ç›Š
        """
        self.top_percentile = top_percentile
        self.min_absolute_return = min_absolute_return
        
        print(f"\nğŸ¯ åˆå§‹åŒ–ä¼˜åŒ–ç›®æ ‡ç”Ÿæˆå™¨")
        print(f"   ç›¸å¯¹æ”¶ç›Šé˜ˆå€¼: Top {top_percentile:.0%}")
        print(f"   ç»å¯¹æ”¶ç›Šé˜ˆå€¼: {min_absolute_return:.1%}")
    
    def generate_target(self, merged_data: pd.DataFrame, 
                       future_return_col='future_return',
                       abs_return_col='abs_return') -> pd.DataFrame:
        """
        ç”Ÿæˆä¼˜åŒ–çš„äºŒåˆ†ç±»ç›®æ ‡
        
        Target = 1: ç›¸å¯¹æ”¶ç›ŠTop 20% ä¸” ç»å¯¹æ”¶ç›Š > 0
        Target = 0: å…¶ä»–
        """
        print(f"  ğŸ“Š ç”Ÿæˆä¼˜åŒ–ç›®æ ‡...")
        
        data = merged_data.copy()
        data['target'] = 0
        
        for date in data['date'].unique():
            mask = data['date'] == date
            daily_data = data[mask]
            
            # ç›¸å¯¹æ”¶ç›Šé˜ˆå€¼
            relative_thresh = daily_data[future_return_col].quantile(
                1 - self.top_percentile
            )
            
            # åŒé‡è¿‡æ»¤
            target_mask = (
                (daily_data[future_return_col] >= relative_thresh) &
                (daily_data[abs_return_col] > self.min_absolute_return)
            )
            
            data.loc[mask & target_mask, 'target'] = 1
        
        # ç»Ÿè®¡
        target_ratio = data['target'].mean()
        print(f"  âœ“ ç›®æ ‡æ¯”ä¾‹: {target_ratio:.2%}")
        
        return data


class EnsembleMLScorer:
    """
    âœ¨ é›†æˆMLè¯„åˆ†å™¨
    
    æ¨¡å‹æŠ•ç¥¨æœºåˆ¶:
    1. XGBoost - æ¢¯åº¦æå‡æ ‘
    2. LightGBM - å¿«é€Ÿæ¢¯åº¦æå‡
    3. RandomForest - éšæœºæ£®æ—
    
    å†³ç­–: è‡³å°‘2ä¸ªæ¨¡å‹åŒæ„æ‰æ ‡è®°ä¸º Top 20%
    """
    
    def __init__(self, 
                 use_xgboost=True,
                 use_lightgbm=True,
                 use_random_forest=True,
                 voting_threshold=2,  # è‡³å°‘2ä¸ªæ¨¡å‹åŒæ„
                 confidence_threshold=0.7,  # é«˜ç½®ä¿¡åº¦è¿‡æ»¤
                 target_period=5,
                 random_state=42):
        """
        Args:
            use_xgboost: æ˜¯å¦ä½¿ç”¨XGBoost
            use_lightgbm: æ˜¯å¦ä½¿ç”¨LightGBM
            use_random_forest: æ˜¯å¦ä½¿ç”¨RandomForest
            voting_threshold: æŠ•ç¥¨é˜ˆå€¼
            confidence_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
        """
        self.use_xgboost = use_xgboost and XGBOOST_AVAILABLE
        self.use_lightgbm = use_lightgbm and LIGHTGBM_AVAILABLE
        self.use_random_forest = use_random_forest
        self.voting_threshold = voting_threshold
        self.confidence_threshold = confidence_threshold
        self.target_period = target_period
        self.random_state = random_state
        
        self.models = {}
        self.scaler = RobustScaler()
        self.feature_names = None
        
        print(f"\nğŸš€ åˆå§‹åŒ–é›†æˆMLè¯„åˆ†å™¨")
        print(f"   XGBoost: {'âœ“' if self.use_xgboost else 'âœ—'}")
        print(f"   LightGBM: {'âœ“' if self.use_lightgbm else 'âœ—'}")
        print(f"   RandomForest: {'âœ“' if self.use_random_forest else 'âœ—'}")
        print(f"   æŠ•ç¥¨é˜ˆå€¼: {voting_threshold}/3")
        print(f"   ç½®ä¿¡åº¦é˜ˆå€¼: {confidence_threshold:.0%}")
    
    def prepare_features(self, factor_data: pd.DataFrame, 
                        price_data: pd.DataFrame) -> Tuple:
        """å‡†å¤‡è®­ç»ƒç‰¹å¾"""
        print(f"\nğŸ“¦ å‡†å¤‡è®­ç»ƒæ•°æ®...")
        
        # åˆå¹¶æ•°æ®
        price_col = 'close' if 'close' in price_data.columns else 'Close'
        
        merged = factor_data.merge(
            price_data[['instrument', 'date', price_col]],
            on=['instrument', 'date'], how='left'
        )
        merged = merged.sort_values(['instrument', 'date']).reset_index(drop=True)
        
        # è®¡ç®—æ”¶ç›Šç‡
        merged['abs_return'] = merged.groupby('instrument')[price_col].pct_change(
            self.target_period
        ).shift(-self.target_period)
        
        # è¶…é¢æ”¶ç›Š
        market_return = merged.groupby('date')['abs_return'].transform('mean')
        merged['future_return'] = merged['abs_return'] - market_return
        
        # ç”Ÿæˆä¼˜åŒ–ç›®æ ‡
        target_gen = OptimizedTargetGenerator(
            top_percentile=0.20,
            min_absolute_return=0.0
        )
        merged = target_gen.generate_target(merged)
        
        # æ’é™¤æ³„éœ²åˆ—
        exclude = [
            'date', 'instrument', 'future_return', 'abs_return', 'target',
            price_col, 'close', 'Close', 'price',
            'position', 'ml_score', 'score_rank',
            'industry', 'sector'
        ]
        
        feature_cols = [
            c for c in merged.columns 
            if c not in exclude 
            and pd.api.types.is_numeric_dtype(merged[c])
        ]
        
        # éªŒè¯æ— æ³„éœ²
        leaked = [c for c in ['position', 'ml_score'] if c in feature_cols]
        if leaked:
            raise ValueError(f"æ£€æµ‹åˆ°æ•°æ®æ³„éœ²: {leaked}")
        
        X = merged[feature_cols].replace([np.inf, -np.inf], np.nan).fillna(0)
        y = merged['target'].values
        
        self.feature_names = feature_cols
        
        print(f"  âœ“ ç‰¹å¾æ•°: {len(feature_cols)}")
        print(f"  âœ“ æ ·æœ¬æ•°: {len(X)}")
        print(f"  âœ“ æ­£æ ·æœ¬: {y.sum()} ({y.mean():.2%})")
        
        return X, y, merged
    
    def train(self, X: pd.DataFrame, y: np.ndarray, 
             X_val: pd.DataFrame = None, y_val: np.ndarray = None):
        """è®­ç»ƒæ‰€æœ‰æ¨¡å‹"""
        print(f"\nğŸ“ è®­ç»ƒé›†æˆæ¨¡å‹...")
        
        # æ ‡å‡†åŒ–
        X_scaled = self.scaler.fit_transform(X)
        X_val_scaled = self.scaler.transform(X_val) if X_val is not None else None
        
        # 1. XGBoost
        if self.use_xgboost:
            print(f"  è®­ç»ƒ XGBoost...")
            self.models['xgboost'] = xgb.XGBClassifier(
                n_estimators=300,
                learning_rate=0.05,
                max_depth=6,
                eval_metric='auc',
                random_state=self.random_state,
                n_jobs=-1,
                early_stopping_rounds=30
            )
            
            eval_set = [(X_val_scaled, y_val)] if X_val is not None else None
            self.models['xgboost'].fit(
                X_scaled, y, 
                eval_set=eval_set,
                verbose=False
            )
        
        # 2. LightGBM
        if self.use_lightgbm:
            print(f"  è®­ç»ƒ LightGBM...")
            self.models['lightgbm'] = lgb.LGBMClassifier(
                n_estimators=300,
                learning_rate=0.05,
                max_depth=6,
                metric='auc',
                random_state=self.random_state,
                n_jobs=-1,
                verbose=-1
            )
            
            eval_set = [(X_val_scaled, y_val)] if X_val is not None else None
            self.models['lightgbm'].fit(
                X_scaled, y,
                eval_set=eval_set,
                callbacks=[lgb.early_stopping(30, verbose=False)]
            )
        
        # 3. RandomForest
        if self.use_random_forest:
            print(f"  è®­ç»ƒ RandomForest...")
            self.models['random_forest'] = RandomForestClassifier(
                n_estimators=100,
                max_depth=6,
                random_state=self.random_state,
                n_jobs=-1
            )
            self.models['random_forest'].fit(X_scaled, y)
        
        print(f"  âœ“ æ¨¡å‹è®­ç»ƒå®Œæˆ")
    
    def predict_with_voting(self, X: pd.DataFrame) -> np.ndarray:
        """
        é›†æˆé¢„æµ‹ - æ¨¡å‹æŠ•ç¥¨
        
        Returns:
            æŠ•ç¥¨ç»“æœ (0-3)ï¼Œè¡¨ç¤ºæœ‰å¤šå°‘ä¸ªæ¨¡å‹è®¤ä¸ºæ˜¯æ­£ç±»
        """
        if not self.models:
            raise ValueError("æ¨¡å‹æœªè®­ç»ƒ")
        
        X_scaled = self.scaler.transform(X)
        
        votes = np.zeros(len(X))
        
        # æ”¶é›†å„æ¨¡å‹æŠ•ç¥¨
        for name, model in self.models.items():
            try:
                if hasattr(model, 'predict_proba'):
                    proba = model.predict_proba(X_scaled)
                    # è·å–æ­£ç±»æ¦‚ç‡
                    pos_proba = proba[:, 1] if proba.shape[1] > 1 else proba[:, 0]
                else:
                    # å¯¹äºæ²¡æœ‰predict_probaçš„æ¨¡å‹ï¼Œä½¿ç”¨predict
                    pos_proba = model.predict(X_scaled)
                
                # é«˜ç½®ä¿¡åº¦è¿‡æ»¤
                confident_votes = (pos_proba > self.confidence_threshold).astype(int)
                votes += confident_votes
                
                print(f"     {name}: {confident_votes.sum()} ä¸ªé«˜ç½®ä¿¡åº¦é¢„æµ‹")
                
            except Exception as e:
                print(f"     {name} é¢„æµ‹å‡ºé”™: {e}")
        
        return votes
    
    def predict_scores(self, factor_data: pd.DataFrame) -> pd.DataFrame:
        """
        ç”Ÿæˆæœ€ç»ˆè¯„åˆ†
        
        è¯„åˆ†é€»è¾‘:
        1. æ¨¡å‹æŠ•ç¥¨ (2/3åŒæ„)
        2. é«˜ç½®ä¿¡åº¦è¿‡æ»¤ (>0.7)
        """
        print(f"\nğŸ”® ç”Ÿæˆé›†æˆè¯„åˆ†...")
        
        data = factor_data.copy()
        
        # æå–ç‰¹å¾
        X = data[self.feature_names].replace([np.inf, -np.inf], np.nan).fillna(0)
        
        # æŠ•ç¥¨é¢„æµ‹
        votes = self.predict_with_voting(X)
        
        # æŠ•ç¥¨å†³ç­– (è‡³å°‘2ä¸ªæ¨¡å‹åŒæ„)
        final_predictions = (votes >= self.voting_threshold).astype(int)
        
        # ç”Ÿæˆç»“æœDataFrame
        result = pd.DataFrame({
            'date': data['date'].values,
            'instrument': data['instrument'].values,
            'ml_score': votes / len(self.models),  # å½’ä¸€åŒ–æŠ•ç¥¨åˆ†æ•°
            'votes': votes.astype(int),
            'prediction': final_predictions
        })
        
        # è®¡ç®—æ’å
        result['position'] = result.groupby('date')['ml_score'].rank(pct=True)
        
        print(f"  âœ“ è¯„åˆ†ç”Ÿæˆå®Œæˆ")
        print(f"     é«˜ç½®ä¿¡åº¦é¢„æµ‹: {(votes >= self.voting_threshold).sum()}")
        print(f"     å¹³å‡æŠ•ç¥¨æ•°: {votes.mean():.2f}")
        
        return result


def run_alpha_ml_strategy(factor_data: pd.DataFrame, 
                         price_data: pd.DataFrame,
                         use_ensemble=True,
                         confidence_threshold=0.7) -> Dict:
    """
    è¿è¡ŒAlphaå¢å¼ºMLç­–ç•¥
    
    Args:
        factor_data: å› å­æ•°æ®
        price_data: ä»·æ ¼æ•°æ®
        use_ensemble: æ˜¯å¦ä½¿ç”¨é›†æˆæ¨¡å‹
        confidence_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
    
    Returns:
        ç­–ç•¥ç»“æœå­—å…¸
    """
    print("\n" + "=" * 60)
    print("âš¡ Alphaå¢å¼ºMLç­–ç•¥å¯åŠ¨")
    print("=" * 60)
    
    # 1. ç”Ÿæˆä¸‰åˆ†ç±»æ ‡ç­¾
    labeler = TripleBarrierLabeler(
        profit_threshold=0.05,
        stop_loss_threshold=-0.02,
        max_drawdown_threshold=0.02,
        holding_period=5
    )
    labeled_data = labeler.generate_labels(price_data)
    
    # 2. åˆå§‹åŒ–é›†æˆè¯„åˆ†å™¨
    scorer = EnsembleMLScorer(
        use_xgboost=True,
        use_lightgbm=True,
        use_random_forest=True,
        voting_threshold=2,
        confidence_threshold=confidence_threshold
    )
    
    # 3. å‡†å¤‡ç‰¹å¾
    X, y, merged = scorer.prepare_features(factor_data, price_data)
    
    # 4. ç®€å•åˆ†å‰²è®­ç»ƒ/éªŒè¯é›†
    split_idx = int(len(X) * 0.8)
    X_train, X_val = X.iloc[:split_idx], X.iloc[split_idx:]
    y_train, y_val = y[:split_idx], y[split_idx:]
    
    # 5. è®­ç»ƒæ¨¡å‹
    scorer.train(X_train, y_train, X_val, y_val)
    
    # 6. ç”Ÿæˆè¯„åˆ†
    scores = scorer.predict_scores(merged)
    
    # 7. åˆå¹¶å›åŸæ•°æ®
    result_data = merged.merge(
        scores[['date', 'instrument', 'ml_score', 'position']], 
        on=['date', 'instrument'], 
        how='left'
    )
    
    print("\nâœ… Alphaå¢å¼ºMLç­–ç•¥æ‰§è¡Œå®Œæˆ")
    
    return {
        'labeled_data': labeled_data,
        'scored_data': result_data,
        'scorer': scorer,
        'feature_importance': None  # å¯é€‰ï¼šæ·»åŠ ç‰¹å¾é‡è¦æ€§åˆ†æ
    }


if __name__ == '__main__':
    print("Alphaå¢å¼ºMLè¯„åˆ†æ¨¡å— - è¯·åœ¨ä¸»ç¨‹åºä¸­å¯¼å…¥ä½¿ç”¨")
    print("\nç¤ºä¾‹:")
    print("from ml_factor_scoring_alpha import run_alpha_ml_strategy")
    print("\nresults = run_alpha_ml_strategy(factor_data, price_data)")