"""
ml_factor_scoring_integrated.py - æ•´åˆç‰ˆMLè¯„åˆ†å™¨

æ•´åˆäº†ä»¥ä¸‹ç‰ˆæœ¬çš„ä¼˜ç‚¹ï¼š
1. ml_factor_scoring_fixed.py - ä¸¥æ ¼çš„æ»šåŠ¨é¢„æµ‹
2. ml_factor_scoring_unified.py - ç»Ÿä¸€ä¿®å¤ç‰ˆï¼Œæ›´å¥½çš„æ•°æ®å¤„ç†
3. ml_factor_scoring_ultra_standalone.py - ç‹¬ç«‹ç‰ˆæœ¬ï¼Œç»“æ„ç®€æ´

ä¸»è¦ç‰¹æ€§ï¼š
âœ… ä¸¥æ ¼çš„æ»šåŠ¨çª—å£é¢„æµ‹ (Strict Walk-Forward)
âœ… æ•°æ®éš”ç¦» (Purging & Embargoing)
âœ… ç‰¹å¾æ­£äº¤åŒ– (Feature Orthogonalization)
âœ… æ¨¡å‹é›†æˆ (Ensemble Voting)
âœ… ç²¾å‡†ç›®æ ‡ (Precision@K Focus)
"""

import pandas as pd
import numpy as np
import warnings
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import roc_auc_score, precision_score, recall_score
from sklearn.linear_model import LinearRegression

warnings.filterwarnings('ignore')

try:
    import xgboost as xgb
    XGBOOST_AVAILABLE = True
except ImportError:
    xgb = None
    XGBOOST_AVAILABLE = False

try:
    import lightgbm as lgb
    LIGHTGBM_AVAILABLE = True
except ImportError:
    lgb = None
    LIGHTGBM_AVAILABLE = False


# ============================================================================
# 1. æ•°æ®éš”ç¦»å™¨ (Purging & Embargoing)
# ============================================================================

class PurgingEmbargoSplitter:
    """
    æ•°æ®éš”ç¦»åˆ‡åˆ†å™¨

    æ ¸å¿ƒæ€æƒ³ï¼š
    - Purging: åˆ é™¤è®­ç»ƒé›†æœ«å°¾ä¸éªŒè¯é›†æœ‰é‡å çš„æ ·æœ¬
    - Embargo: åœ¨è®­ç»ƒé›†å’ŒéªŒè¯é›†ä¹‹é—´åŠ å…¥Gapï¼ˆéš”ç¦»æœŸï¼‰

    ç¤ºä¾‹ï¼š
        é¢„æµ‹5æ—¥æ”¶ç›Šï¼Œéœ€è¦5æ—¥Gap
        Train: [æœˆ1-12] -> Gap: [12æœˆæœ«5å¤©] -> Valid: [æœˆ13]
    """

    def __init__(self, train_months=12, valid_months=1, test_months=1,
                 embargo_days=5):
        """
        Args:
            embargo_days: éš”ç¦»æœŸï¼ˆå¤©ï¼‰- åº”è¯¥ >= é¢„æµ‹å‘¨æœŸ
        """
        self.train_months = train_months
        self.valid_months = valid_months
        self.test_months = test_months
        self.embargo_days = embargo_days

    def split(self, data, date_column='date'):
        """æ—¶é—´åºåˆ—åˆ‡åˆ† + æ•°æ®éš”ç¦»"""
        data = data.copy()
        data[date_column] = pd.to_datetime(data[date_column])
        data = data.sort_values(date_column)

        data['year_month'] = data[date_column].dt.to_period('M')
        months = sorted(data['year_month'].unique())

        splits = []

        # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„æœˆä»½
        required_months = self.train_months + self.valid_months + self.test_months
        if len(months) < required_months:
            return splits

        for i in range(len(months) - self.train_months - self.valid_months - self.test_months + 1):
            train_end = i + self.train_months
            valid_end = train_end + self.valid_months
            test_end = valid_end + self.test_months

            train_months_list = months[i:train_end]
            valid_months_list = months[train_end:valid_end]
            test_months_list = months[valid_end:test_end]

            # åˆå§‹ç´¢å¼•
            train_idx = data[data['year_month'].isin(train_months_list)].index
            valid_idx = data[data['year_month'].isin(valid_months_list)].index
            test_idx = data[data['year_month'].isin(test_months_list)].index

            # âœ… å…³é”®ä¼˜åŒ–ï¼šPurging + Embargo
            if self.embargo_days > 0 and len(train_idx) > 0 and len(valid_idx) > 0:
                # è·å–è®­ç»ƒé›†æœ€åä¸€å¤©
                train_last_date = data.loc[train_idx, date_column].max()

                # åˆ é™¤è®­ç»ƒé›†ä¸­ä¼šä¸éªŒè¯é›†é‡å çš„æ ·æœ¬
                # å³åˆ é™¤è®­ç»ƒé›†æœ€å embargo_days å¤©çš„æ•°æ®
                embargo_cutoff = train_last_date - pd.Timedelta(days=self.embargo_days)
                train_idx = train_idx[data.loc[train_idx, date_column] <= embargo_cutoff]

            if len(train_idx) > 0 and len(valid_idx) > 0 and len(test_idx) > 0:
                splits.append((train_idx, valid_idx, test_idx))

        return splits


# ============================================================================
# 2. ç‰¹å¾æ­£äº¤åŒ–å™¨ (Feature Orthogonalization)
# ============================================================================

class FeatureOrthogonalizer:
    """
    ç‰¹å¾æ­£äº¤åŒ– - æå–çº¯Alpha

    æ–¹æ³•ï¼š
    1. å¸‚åœºä¸­æ€§åŒ–ï¼šæ®‹å·® = å› å­ - Î²_market Ã— å¸‚åœºæ”¶ç›Š
    2. è¡Œä¸šä¸­æ€§åŒ–ï¼šæ®‹å·® = å› å­ - Î£(Î²_industry Ã— è¡Œä¸šå“‘å˜é‡)
    """

    def __init__(self, neutralize_market=True, neutralize_industry=True):
        self.neutralize_market = neutralize_market
        self.neutralize_industry = neutralize_industry
        self.market_models = {}  # {factor: LinearRegression}
        self.industry_models = {}

    def fit_transform(self, factor_data, factor_columns, price_data=None):
        """
        æ‹Ÿåˆå¹¶è½¬æ¢å› å­

        Args:
            factor_data: å› å­æ•°æ®ï¼ˆå¿…é¡»åŒ…å«date, instrumentï¼‰
            factor_columns: éœ€è¦ä¸­æ€§åŒ–çš„å› å­åˆ—è¡¨
            price_data: ä»·æ ¼æ•°æ®ï¼ˆç”¨äºè®¡ç®—å¸‚åœºæ”¶ç›Šï¼‰
        """
        print("\nğŸ”§ ç‰¹å¾æ­£äº¤åŒ–...")

        factor_data = factor_data.copy()

        # ===== 1. å¸‚åœºä¸­æ€§åŒ– =====
        if self.neutralize_market and price_data is not None:
            print("  âœ“ å¸‚åœºä¸­æ€§åŒ–...")
            factor_data = self._neutralize_market(
                factor_data, factor_columns, price_data
            )

        # ===== 2. è¡Œä¸šä¸­æ€§åŒ– =====
        if self.neutralize_industry and 'industry' in factor_data.columns:
            print("  âœ“ è¡Œä¸šä¸­æ€§åŒ–...")
            factor_data = self._neutralize_industry(
                factor_data, factor_columns
            )

        print("  âœ“ æ­£äº¤åŒ–å®Œæˆ")
        return factor_data

    def _neutralize_market(self, factor_data, factor_columns, price_data):
        """å¸‚åœºä¸­æ€§åŒ–"""
        # è®¡ç®—å¸‚åœºæ”¶ç›Šï¼ˆæ¯æ—¥å¹³å‡æ”¶ç›Šï¼‰
        price_col = self._detect_price_column(price_data)
        if price_col is None:
            return factor_data

        # æ£€æŸ¥ price_col æ˜¯å¦åœ¨ price_data ä¸­å­˜åœ¨
        if price_col not in price_data.columns:
            return factor_data
            
        # æ£€æŸ¥æ‰€éœ€çš„åˆ—æ˜¯å¦å­˜åœ¨
        required_cols = ['instrument', 'date', price_col]
        missing_cols = [col for col in required_cols if col not in price_data.columns]
        if missing_cols:
            return factor_data

        # æ£€æŸ¥ price_col æ˜¯å¦å·²ç»åœ¨ factor_data ä¸­ï¼ˆå·²åˆå¹¶çš„æƒ…å†µï¼‰
        if price_col not in factor_data.columns:
            # å¦‚æœä¸åœ¨ï¼Œåˆ™è¿›è¡Œåˆå¹¶
            factor_data = factor_data.merge(
                price_data[['instrument', 'date', price_col]],
                on=['instrument', 'date'],
                how='left'
            )
        
        # æ£€æŸ¥åˆå¹¶åçš„æ•°æ®
        if price_col not in factor_data.columns:
            return factor_data

        # æ¯æ—¥å¸‚åœºæ”¶ç›Š
        factor_data['daily_return'] = factor_data.groupby('instrument')[price_col].pct_change()
        market_return = factor_data.groupby('date')['daily_return'].transform('mean')

        # å¯¹æ¯ä¸ªå› å­å›å½’
        for factor in factor_columns:
            if factor not in factor_data.columns:
                continue

            # è¿‡æ»¤æœ‰æ•ˆæ•°æ®
            valid = factor_data[[factor, 'daily_return']].dropna()
            if len(valid) < 100:
                continue

            # å›å½’ï¼šfactor = Î± + Î² Ã— market_return + Îµ
            X = valid['daily_return'].values.reshape(-1, 1)
            y = valid[factor].values

            model = LinearRegression()
            model.fit(X, y)

            # æ®‹å·® = å› å­ - é¢„æµ‹å€¼
            factor_data.loc[valid.index, factor] = y - model.predict(X)

            self.market_models[factor] = model

        # åˆ é™¤ä¸´æ—¶åˆ—
        factor_data = factor_data.drop(columns=['daily_return'], errors='ignore')
        return factor_data

    def _neutralize_industry(self, factor_data, factor_columns):
        """è¡Œä¸šä¸­æ€§åŒ–"""
        # åˆ›å»ºè¡Œä¸šå“‘å˜é‡
        industry_dummies = pd.get_dummies(
            factor_data['industry'],
            prefix='ind',
            drop_first=True  # é¿å…å®Œå…¨å…±çº¿æ€§
        )

        for factor in factor_columns:
            if factor not in factor_data.columns:
                continue

            # è¿‡æ»¤æœ‰æ•ˆæ•°æ®
            valid_idx = factor_data[factor].notna()
            if valid_idx.sum() < 100:
                continue

            X = industry_dummies.loc[valid_idx]
            y = factor_data.loc[valid_idx, factor].values

            # å›å½’ï¼šfactor = Î£(Î²_i Ã— industry_i) + Îµ
            model = LinearRegression()
            model.fit(X, y)

            # æ®‹å·®
            factor_data.loc[valid_idx, factor] = y - model.predict(X)

            self.industry_models[factor] = model

        return factor_data

    def _detect_price_column(self, df):
        candidates = ['close', 'Close', 'CLOSE', 'price', 'Price']
        for col in candidates:
            if col in df.columns:
                return col
        # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œè¿”å›ç¬¬ä¸€ä¸ªå¯ç”¨çš„æ•°å€¼åˆ—ä½œä¸ºä»·æ ¼åˆ—
        numeric_cols = [col for col in df.columns if pd.api.types.is_numeric_dtype(df[col]) and col not in ['volume', 'amount']]
        if numeric_cols:
            return numeric_cols[0]
        return None


# ============================================================================
# 3. é›†æˆæŠ•ç¥¨å™¨ (Ensemble Voting)
# ============================================================================

class EnsembleVotingScorer:
    """
    é›†æˆæŠ•ç¥¨è¯„åˆ†å™¨

    ç­–ç•¥ï¼š
    - åŒæ—¶è®­ç»ƒ XGBoost å’Œ LightGBM
    - é¢„æµ‹æ—¶å–æ¦‚ç‡å‡å€¼
    - å¯é€‰ï¼šåªæœ‰ä¸¤ä¸ªæ¨¡å‹éƒ½çœ‹å¤šï¼ˆæ¦‚ç‡>0.5ï¼‰æ—¶æ‰ç»™é«˜åˆ†
    """

    def __init__(self, voting_strategy='average', strict_threshold=0.6):
        """
        Args:
            voting_strategy: 'average' | 'strict'
                - average: ç®€å•å¹³å‡ä¸¤ä¸ªæ¨¡å‹çš„é¢„æµ‹
                - strict: åªæœ‰ä¸¤ä¸ªæ¨¡å‹éƒ½çœ‹å¤šæ—¶æ‰ç»™é«˜åˆ†
            strict_threshold: strictæ¨¡å¼ä¸‹çš„é˜ˆå€¼
        """
        self.voting_strategy = voting_strategy
        self.strict_threshold = strict_threshold
        self.xgb_model = None
        self.lgb_model = None
        self.scaler = StandardScaler()

    def train(self, X_train, y_train, X_valid, y_valid, verbose=False):
        """è®­ç»ƒä¸¤ä¸ªæ¨¡å‹"""
        print(f"\nğŸ¤ é›†æˆè®­ç»ƒ ({self.voting_strategy})...")

        # æ ‡å‡†åŒ–
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_valid_scaled = self.scaler.transform(X_valid)

        # ===== XGBoost =====
        if XGBOOST_AVAILABLE:
            print("  âœ“ è®­ç»ƒ XGBoost...")
            self.xgb_model = xgb.XGBClassifier(
                objective='binary:logistic',
                eval_metric='auc',
                max_depth=5,  # é™ä½å¤æ‚åº¦
                learning_rate=0.03,
                n_estimators=300,
                subsample=0.7,
                colsample_bytree=0.7,
                random_state=42,
                n_jobs=-1
            )

            try:
                self.xgb_model.fit(
                    X_train_scaled, y_train,
                    eval_set=[(X_valid_scaled, y_valid)],
                    early_stopping_rounds=30,
                    verbose=verbose
                )
            except:
                self.xgb_model.fit(X_train_scaled, y_train)

        # ===== LightGBM =====
        if LIGHTGBM_AVAILABLE:
            print("  âœ“ è®­ç»ƒ LightGBM...")
            self.lgb_model = lgb.LGBMClassifier(
                objective='binary',
                metric='auc',
                max_depth=5,
                learning_rate=0.03,
                n_estimators=300,
                subsample=0.7,
                colsample_bytree=0.7,
                random_state=42,
                n_jobs=-1,
                verbose=-1
            )

            try:
                self.lgb_model.fit(
                    X_train_scaled, y_train,
                    eval_set=[(X_valid_scaled, y_valid)],
                    callbacks=[lgb.early_stopping(30, verbose=verbose)]
                )
            except:
                self.lgb_model.fit(X_train_scaled, y_train)

        # è¯„ä¼°
        y_pred = self.predict_proba(X_valid)
        auc = roc_auc_score(y_valid, y_pred)
        print(f"  âœ“ é›†æˆéªŒè¯AUC: {auc:.4f}")

        return self

    def predict_proba(self, X):
        """é›†æˆé¢„æµ‹"""
        X_scaled = self.scaler.transform(X)

        predictions = []

        if self.xgb_model is not None:
            pred_xgb = self.xgb_model.predict_proba(X_scaled)[:, 1]
            predictions.append(pred_xgb)

        if self.lgb_model is not None:
            pred_lgb = self.lgb_model.predict_proba(X_scaled)[:, 1]
            predictions.append(pred_lgb)

        if len(predictions) == 0:
            raise ValueError("æ²¡æœ‰å¯ç”¨æ¨¡å‹")

        # ===== æŠ•ç¥¨ç­–ç•¥ =====
        if self.voting_strategy == 'average':
            # ç®€å•å¹³å‡
            return np.mean(predictions, axis=0)

        elif self.voting_strategy == 'strict':
            # ä¸¥æ ¼æ¨¡å¼ï¼šä¸¤ä¸ªéƒ½çœ‹å¤šæ‰ç»™é«˜åˆ†
            avg_pred = np.mean(predictions, axis=0)

            # åªæœ‰å½“ä¸¤ä¸ªæ¨¡å‹éƒ½è¶…è¿‡é˜ˆå€¼æ—¶ï¼Œæ‰ä¿ç•™åŸå§‹åˆ†æ•°
            if len(predictions) == 2:
                both_bullish = (predictions[0] > self.strict_threshold) & \
                               (predictions[1] > self.strict_threshold)
                return np.where(both_bullish, avg_pred, avg_pred * 0.5)
            else:
                return avg_pred


# ============================================================================
# 4. Precision@K è¯„ä¼°å™¨
# ============================================================================

class PrecisionAtKEvaluator:
    """
    Precision@K è¯„ä¼°å™¨

    å…³æ³¨æŒ‡æ ‡ï¼š
    - Precision@20%: Top 20% ä¸­æœ‰å¤šå°‘æ˜¯çœŸæ­£çš„èµ¢å®¶
    - Recall@20%: çœŸæ­£çš„èµ¢å®¶æœ‰å¤šå°‘è¢«é€‰ä¸­
    """

    @staticmethod
    def precision_at_k(y_true, y_pred_proba, k=0.2):
        """
        è®¡ç®— Precision@K

        Args:
            y_true: çœŸå®æ ‡ç­¾
            y_pred_proba: é¢„æµ‹æ¦‚ç‡
            k: Top Kæ¯”ä¾‹

        Returns:
            precision, recall
        """
        n = len(y_true)
        top_k = int(n * k)

        # é€‰å‡ºTop K
        top_k_idx = np.argsort(y_pred_proba)[-top_k:]

        y_true_top = y_true[top_k_idx]

        precision = y_true_top.sum() / len(y_true_top) if len(y_true_top) > 0 else 0
        recall = y_true_top.sum() / y_true.sum() if y_true.sum() > 0 else 0

        return precision, recall

    @staticmethod
    def evaluate_model(model, X_valid, y_valid, k=0.2):
        """å®Œæ•´è¯„ä¼°"""
        y_pred_proba = model.predict_proba(X_valid)

        auc = roc_auc_score(y_valid, y_pred_proba)
        prec, rec = PrecisionAtKEvaluator.precision_at_k(y_valid, y_pred_proba, k)

        print(f"    AUC: {auc:.4f}")
        print(f"    Precision@{int(k*100)}%: {prec:.4f}")
        print(f"    Recall@{int(k*100)}%: {rec:.4f}")

        return {'auc': auc, 'precision': prec, 'recall': rec}


# ============================================================================
# 5. æ•´åˆç‰ˆè¶…çº§MLè¯„åˆ†å™¨
# ============================================================================

class UltraMLScorer:
    """
    è¶…çº§MLè¯„åˆ†å™¨ - æ•´åˆç‰ˆ

    æ•´åˆä¼˜åŒ–ï¼š
    1. âœ… ä¸¥æ ¼çš„æ»šåŠ¨çª—å£é¢„æµ‹ (Strict Walk-Forward)
    2. âœ… Purging & Embargo
    3. âœ… Feature Orthogonalization
    4. âœ… Ensemble Voting
    5. âœ… Precision@K Focus
    """

    def __init__(self,
                 target_period=5,
                 top_percentile=0.20,
                 embargo_days=5,
                 neutralize_market=True,
                 neutralize_industry=True,
                 voting_strategy='average',
                 train_months=12,
                 random_state=42):

        self.target_period = target_period
        self.top_percentile = top_percentile
        self.embargo_days = embargo_days
        self.neutralize_market = neutralize_market
        self.neutralize_industry = neutralize_industry
        self.voting_strategy = voting_strategy
        self.train_months = train_months
        self.random_state = random_state

        self.orthogonalizer = FeatureOrthogonalizer(
            neutralize_market, neutralize_industry
        )
        self.ensemble = EnsembleVotingScorer(voting_strategy)
        self.feature_names = None

        print(f"\nğŸš€ è¶…çº§MLè¯„åˆ†å™¨ (æ•´åˆç‰ˆ)")
        print(f"  âœ… æ•°æ®éš”ç¦»: {embargo_days}å¤©Gap")
        print(f"  âœ… ç‰¹å¾æ­£äº¤: å¸‚åœº={neutralize_market}, è¡Œä¸š={neutralize_industry}")
        print(f"  âœ… é›†æˆæŠ•ç¥¨: {voting_strategy}")
        print(f"  âœ… ç›®æ ‡ä¼˜åŒ–: Precision@{int(top_percentile*100)}%")

    def prepare_data(self, factor_data, price_data, factor_columns):
        """å‡†å¤‡æ•°æ® + ç‰¹å¾æ­£äº¤åŒ–"""
        print(f"\nğŸ“¦ å‡†å¤‡è®­ç»ƒæ•°æ®...")

        # æ£€æµ‹ä»·æ ¼åˆ—
        price_col = self._detect_price_column(price_data)
        if price_col is None:
            raise ValueError("æœªæ‰¾åˆ°ä»·æ ¼åˆ—")

        # åˆå¹¶
        merged = factor_data.merge(
            price_data[['instrument', 'date', price_col]],
            on=['instrument', 'date'],
            how='left'
        )
        merged = merged.sort_values(['instrument', 'date'])

        # ===== ç‰¹å¾æ­£äº¤åŒ– =====
        merged = self.orthogonalizer.fit_transform(
            merged, factor_columns, price_data
        )

        # ===== è®¡ç®—è¶…é¢æ”¶ç›Šç›®æ ‡ =====
        merged['abs_return'] = merged.groupby('instrument')[price_col].pct_change(
            self.target_period
        ).shift(-self.target_period)

        market_return = merged.groupby('date')['abs_return'].transform('mean')
        merged['future_return'] = merged['abs_return'] - market_return

        # åˆ†ç±»ç›®æ ‡
        merged['target'] = 0
        for date in merged['date'].unique():
            date_mask = merged['date'] == date
            returns = merged.loc[date_mask, 'future_return']
            if len(returns) > 5:
                threshold = returns.quantile(1 - self.top_percentile)
                merged.loc[date_mask & (merged['future_return'] >= threshold), 'target'] = 1

        # è¿‡æ»¤
        merged = merged.dropna(subset=['target'])

        print(f"  âœ“ æœ‰æ•ˆæ ·æœ¬: {len(merged)}")
        print(f"  âœ“ æ­£æ ·æœ¬æ¯”ä¾‹: {merged['target'].mean():.2%}")

        # æ„å»ºç‰¹å¾
        exclude = [
            'date', 'instrument', 'future_return', 'abs_return',
            'target', price_col, 'industry', 'year_month'
        ]
        feature_cols = [c for c in merged.columns
                       if c not in exclude and pd.api.types.is_numeric_dtype(merged[c])]

        X = merged[feature_cols].copy()
        X = X.replace([np.inf, -np.inf], np.nan).fillna(X.median())
        y = merged['target'].values

        self.feature_names = feature_cols

        return X, y, merged

    def train(self, X, y, merged, verbose=True):
        """Walk-Forwardè®­ç»ƒ + Purging"""
        print(f"\nğŸ¯ Walk-Forwardè®­ç»ƒ (Purging={self.embargo_days}å¤©)...")

        # ä½¿ç”¨ä¼˜åŒ–çš„åˆ‡åˆ†å™¨
        splitter = PurgingEmbargoSplitter(
            train_months=self.train_months,
            valid_months=1,
            test_months=1,
            embargo_days=self.embargo_days
        )

        splits = splitter.split(merged, date_column='date')

        if len(splits) == 0:
            print("  âš ï¸  æ•°æ®ä¸è¶³")
            return self

        print(f"  âœ“ ç”Ÿæˆ {len(splits)} ä¸ªçª—å£")

        best_model = None
        best_score = -np.inf

        for i, (train_idx, valid_idx, test_idx) in enumerate(splits):
            X_train = X.iloc[train_idx]
            y_train = y[train_idx]
            X_valid = X.iloc[valid_idx]
            y_valid = y[valid_idx]

            print(f"\n  çª—å£ {i+1}/{len(splits)}")

            # è®­ç»ƒé›†æˆæ¨¡å‹
            ensemble = EnsembleVotingScorer(self.voting_strategy)
            ensemble.train(X_train, y_train, X_valid, y_valid, verbose=False)

            # ===== Precision@K è¯„ä¼° =====
            metrics = PrecisionAtKEvaluator.evaluate_model(
                ensemble, X_valid, y_valid, self.top_percentile
            )

            # ä½¿ç”¨ Precision@K ä½œä¸ºé€‰æ‹©æ ‡å‡†ï¼ˆè€ŒéAUCï¼‰
            score = metrics['precision']

            if score > best_score:
                best_score = score
                best_model = ensemble

        self.ensemble = best_model
        print(f"\n  âœ“ æœ€ä½³æ¨¡å‹ Precision@{int(self.top_percentile*100)}%: {best_score:.4f}")

        return self

    def predict(self, factor_data, price_data=None):
        """
        âœ… æ•´åˆç‰ˆé¢„æµ‹ï¼šä¸¥æ ¼æ»šåŠ¨çª—å£é¢„æµ‹ (Strict Walk-Forward)
        æœç»æœªæ¥å‡½æ•°ï¼šé¢„æµ‹ T æœˆçš„åˆ†æ•°ï¼Œåªä½¿ç”¨ T-1 æœˆåŠä¹‹å‰çš„æ•°æ®è®­ç»ƒ
        """
        if price_data is None:
            print("âš ï¸ è­¦å‘Šï¼šç¼ºå°‘ä»·æ ¼æ•°æ®ï¼Œæ— æ³•è¿›è¡Œæ»šåŠ¨è®­ç»ƒï¼Œä»…ä½¿ç”¨é™æ€æ¨¡å‹é¢„æµ‹ï¼ˆå­˜åœ¨å‰è§†åå·®é£é™©ï¼‰")
            # ... åŸæœ‰é€»è¾‘ ...
            return factor_data

        print(f"\nğŸ”„ å¯åŠ¨ä¸¥æ ¼æ»šåŠ¨é¢„æµ‹ (Strict Walk-Forward)...")
        
        # 1. å‡†å¤‡åŸºç¡€æ•°æ®
        # è‡ªåŠ¨è¯†åˆ«å› å­åˆ—
        exclude_cols = ['date', 'instrument', 'industry', 'target', 'future_return', 'abs_return']
        factor_columns = [col for col in factor_data.columns 
                         if col not in exclude_cols and pd.api.types.is_numeric_dtype(factor_data[col])]
        
        X, y, merged = self.prepare_data(factor_data, price_data, factor_columns)
        merged['date'] = pd.to_datetime(merged['date'])
        
        # 2. æŒ‰æœˆåˆ‡åˆ†æ—¶é—´è½´
        unique_months = sorted(merged['date'].dt.to_period('M').unique())
        
        # è‡³å°‘éœ€è¦ train_months ä¸ªæœˆçš„æ•°æ®æ‰èƒ½å¼€å§‹é¢„æµ‹
        start_predict_idx = self.train_months + 1
        if len(unique_months) <= start_predict_idx:
            print("âŒ æ•°æ®æ—¶é—´è·¨åº¦ä¸è¶³ä»¥è¿›è¡Œæ»šåŠ¨è®­ç»ƒ")
            return factor_data

        predictions = []
        
        # 3. æ»šåŠ¨å¾ªç¯
        # è¿™é‡Œçš„ i æ˜¯é¢„æµ‹æœˆä»½çš„ç´¢å¼•
        for i in range(start_predict_idx, len(unique_months)):
            predict_month = unique_months[i]
            train_end_month = unique_months[i - 1] # è®­ç»ƒæˆªæ­¢åˆ°ä¸Šä¸ªæœˆ
            
            # è®­ç»ƒé›†ï¼šæˆªæ­¢åˆ°ä¸Šä¸ªæœˆçš„æ‰€æœ‰æ•°æ® (Expanding Window)
            # æˆ–è€…ä½¿ç”¨ Rolling Window: unique_months[i-self.train_months : i]
            train_mask = merged['date'].dt.to_period('M') < predict_month
            # åŠ ä¸Š Embargo (éš”ç¦»æœŸ) é˜²æ­¢è¾¹ç¼˜æ³„éœ²
            if self.embargo_days > 0:
                max_train_date = merged.loc[train_mask, 'date'].max()
                train_mask = train_mask & (merged['date'] < (max_train_date - pd.Timedelta(days=self.embargo_days)))
                
            test_mask = merged['date'].dt.to_period('M') == predict_month
            
            if not train_mask.any() or not test_mask.any():
                continue
                
            X_train = X.loc[train_mask]
            y_train = y[train_mask]
            X_test = X.loc[test_mask]
            
            # ä¸´æ—¶è®­ç»ƒä¸€ä¸ªæ¨¡å‹
            model = EnsembleVotingScorer(self.voting_strategy)
            try:
                # ç®€åŒ–è®­ç»ƒè¿‡ç¨‹ä»¥åŠ å¿«é€Ÿåº¦ï¼Œä¸è¿›è¡Œå¤æ‚çš„æ—©åœéªŒè¯
                model.train(X_train, y_train, X_train.iloc[:100], y_train[:100], verbose=False)
                
                # é¢„æµ‹å½“æœˆ
                pred_scores = model.predict_proba(X_test)
                
                # ä¿å­˜ç»“æœ
                result_df = pd.DataFrame({
                    'instrument': merged.loc[test_mask, 'instrument'],
                    'date': merged.loc[test_mask, 'date'],
                    'ml_score': pred_scores
                })
                predictions.append(result_df)
                
                print(f"  âœ“ å®Œæˆé¢„æµ‹: {predict_month} (è®­ç»ƒæ ·æœ¬: {len(X_train)})")
            except Exception as e:
                print(f"  âš ï¸ {predict_month} é¢„æµ‹å¤±è´¥: {e}")

        # 4. åˆå¹¶æ‰€æœ‰é¢„æµ‹ç»“æœ
        if not predictions:
            print("âš ï¸ æ— æœ‰æ•ˆé¢„æµ‹ç»“æœ")
            factor_data['ml_score'] = 0.5
            return factor_data
            
        all_preds = pd.concat(predictions)
        
        # 5. æ›´æ–°åŸå§‹æ•°æ®
        # è½¬æ¢æ—¥æœŸæ ¼å¼ä»¥åŒ¹é…
        factor_data['date'] = pd.to_datetime(factor_data['date'])
        
        # å…ˆåˆ é™¤æ—§çš„ score åˆ—ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if 'ml_score' in factor_data.columns:
            del factor_data['ml_score']
        if 'position' in factor_data.columns:
            del factor_data['position']
            
        # åˆå¹¶æ–°åˆ†æ•°
        factor_data = factor_data.merge(all_preds, on=['date', 'instrument'], how='left')
        
        # å¡«å……æœªé¢„æµ‹æ—¶æ®µï¼ˆé€šå¸¸æ˜¯å›æµ‹åˆæœŸçš„å†·å¯åŠ¨æœŸï¼‰ä¸ºä¸­æ€§åˆ†
        factor_data['ml_score'] = factor_data['ml_score'].fillna(0.0) # åˆæœŸä¸æŒä»“
        
        # è®¡ç®—æ’å (position)
        factor_data['position'] = factor_data.groupby('date')['ml_score'].rank(pct=True).fillna(0)
        
        # æ¢å¤æ—¥æœŸæ ¼å¼ä¸ºå­—ç¬¦ä¸²ï¼ˆå…¼å®¹åç»­æ¨¡å—ï¼‰
        factor_data['date'] = factor_data['date'].dt.strftime('%Y-%m-%d')
        
        print(f"âœ… æ»šåŠ¨é¢„æµ‹å®Œæˆï¼Œè¦†ç›– {len(all_preds)} æ¡æ•°æ®")
        return factor_data

    def _detect_price_column(self, df):
        candidates = ['close', 'Close', 'CLOSE', 'price', 'Price']
        for col in candidates:
            if col in df.columns:
                return col
        return None


# ============================================================================
# å¯¼å‡º
# ============================================================================

__all__ = ['UltraMLScorer', 'PurgingEmbargoSplitter', 'FeatureOrthogonalizer', 'EnsembleVotingScorer', 'PrecisionAtKEvaluator']


# ============================================================================
# ä½¿ç”¨ç¤ºä¾‹
# ============================================================================

def demo_ultra_scorer():
    """æ¼”ç¤ºè¶…çº§è¯„åˆ†å™¨"""
    print("="*80)
    print("è¶…çº§MLè¯„åˆ†å™¨ - æ•´åˆç‰ˆæ¼”ç¤º")
    print("="*80)

    # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
    np.random.seed(42)
    dates = pd.date_range('2023-01-01', periods=400, freq='D')
    instruments = [f'STOCK_{i:03d}' for i in range(100)]

    data = []
    for date in dates:
        for inst in instruments:
            data.append({
                'date': date,
                'instrument': inst,
                'close': 100 + np.random.randn() * 10,
                'factor1': np.random.randn(),
                'factor2': np.random.randn(),
                'factor3': np.random.randn(),
                'industry': np.random.choice(['ç§‘æŠ€', 'é‡‘è', 'æ¶ˆè´¹', 'åŒ»è¯'])
            })

    df = pd.DataFrame(data)

    factor_cols = ['factor1', 'factor2', 'factor3']

    # åˆå§‹åŒ–è¶…çº§è¯„åˆ†å™¨
    scorer = UltraMLScorer(
        target_period=5,
        top_percentile=0.20,
        embargo_days=5,
        neutralize_market=True,
        neutralize_industry=True,
        voting_strategy='average',
        train_months=6
    )

    # å‡†å¤‡æ•°æ®
    X, y, merged = scorer.prepare_data(
        df, df, factor_cols
    )

    # è®­ç»ƒ
    scorer.train(X, y, merged)

    # é¢„æµ‹
    result = scorer.predict(df.tail(500), df)

    print("\n" + "="*80)
    print("âœ… æ¼”ç¤ºå®Œæˆï¼")
    print("="*80)


if __name__ == '__main__':
    demo_ultra_scorer()