"""
data_module_alpha_enhanced.py - Alphaå¢å¼ºå› å­å·¥ç¨‹æ¨¡å—

æ ¸å¿ƒå¢å¼º:
âœ… 1. Alpha101 é£æ ¼å› å­: é‡ä»·ç›¸å…³æ€§ã€ä¹–ç¦»ç‡ã€ä½æ³¢å› å­
âœ… 2. å¾®è§‚ç»“æ„å› å­: æ—¥å†…å¼ºåº¦ã€æˆäº¤å æ¯”
âœ… 3. å› å­æ­£äº¤åŒ–: å»é™¤å¤šé‡å…±çº¿æ€§
âœ… 4. é«˜çº§åŠ¨é‡å› å­: å¤šå‘¨æœŸå¤åˆåŠ¨é‡

ä½¿ç”¨æ–¹æ³•:
    from data_module_alpha_enhanced import EnhancedFactorGenerator
    
    generator = EnhancedFactorGenerator()
    enhanced_df = generator.generate_all_factors(price_data)
"""

import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
from typing import Optional


class EnhancedFactorGenerator:
    """
    Alphaå¢å¼ºå› å­ç”Ÿæˆå™¨
    
    é›†æˆ:
    - Alpha101 ç»å…¸å› å­
    - å¾®è§‚ç»“æ„å› å­
    - å¤šå‘¨æœŸåŠ¨é‡å¤åˆ
    - å› å­æ­£äº¤åŒ–
    """
    
    def __init__(self, enable_orthogonalization=True, debug=False):
        """
        Args:
            enable_orthogonalization: æ˜¯å¦å¯ç”¨å› å­æ­£äº¤åŒ–
            debug: æ˜¯å¦è¾“å‡ºè°ƒè¯•ä¿¡æ¯
        """
        self.enable_orthogonalization = enable_orthogonalization
        self.debug = debug
        
        print(f"\nğŸš€ åˆå§‹åŒ–Alphaå¢å¼ºå› å­ç”Ÿæˆå™¨")
        print(f"   å› å­æ­£äº¤åŒ–: {'å¯ç”¨' if enable_orthogonalization else 'ç¦ç”¨'}")
    
    def calculate_alpha101_factors(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        âœ¨ Alpha101 é£æ ¼å› å­
        
        è¿™äº›éçº¿æ€§å› å­èƒ½æ•æ‰æ›´å¤šå¸‚åœºå¼‚è±¡:
        1. é‡ä»·ç›¸å…³æ€§ (Smart Money)
        2. ä¹–ç¦»ç‡ (Bias) - å‡å€¼å›å½’
        3. ä½æ³¢å› å­ (Low Volatility Anomaly)
        """
        print("  ğŸ“Š è®¡ç®—Alpha101å› å­...")
        
        data = df.copy()
        grouped = data.groupby('instrument')
        
        # 1. æ—¥å†…å¼ºåº¦ (Intraday Strength)
        # è¡¡é‡ä¸»åŠ›èµ„é‡‘ä¹°å…¥/å–å‡ºå‹åŠ›
        # (æ”¶ç›˜-å¼€ç›˜) / (æœ€é«˜-æœ€ä½) * æˆäº¤é‡å æ¯”
        data['intraday_strength'] = (
            (data['close'] - data['open']) / 
            ((data['high'] - data['low']) + 1e-6)
        )
        
        # 2. é‡ä»·ç›¸å…³æ€§ (Volume-Price Correlation)
        # é‡ä»·é½å‡é€šå¸¸æ¯”ç¼©é‡ä¸Šæ¶¨æ›´å¯é 
        def rolling_corr_price_volume(x):
            """10æ—¥æ»šåŠ¨ç›¸å…³æ€§"""
            if len(x) < 10:
                return pd.Series(np.nan, index=x.index)
            return x['close'].rolling(10).corr(x['volume'])
        
        # ç®€åŒ–ç‰ˆï¼šä½¿ç”¨ä»·æ ¼å˜åŒ–ä¸æˆäº¤é‡å˜åŒ–çš„ç›¸å…³æ€§
        data['price_chg'] = grouped['close'].pct_change()
        data['volume_chg'] = grouped['volume'].pct_change()
        
        # 10æ—¥æ»šåŠ¨ç›¸å…³æ€§
        data['vol_price_corr'] = grouped.apply(
            lambda x: x['price_chg'].rolling(10).corr(x['volume_chg'])
        ).reset_index(level=0, drop=True)
        
        # 3. ä¹–ç¦»ç‡ (Bias Rate)
        # ä»·æ ¼åç¦»å‡çº¿ç¨‹åº¦ï¼Œæ•æ‰è¶…ä¹°è¶…å–
        data['ma_20'] = grouped['close'].transform(lambda x: x.rolling(20).mean())
        data['bias_20'] = (data['close'] - data['ma_20']) / (data['ma_20'] + 1e-6)
        
        # 4. ä½æ³¢å› å­ (Low Volatility Preference)
        # ä½æ³¢åŠ¨è‚¡ç¥¨é•¿æœŸè¡¨ç°ä¼˜äºé«˜æ³¢åŠ¨è‚¡ç¥¨
        data['volatility_20'] = grouped['close'].transform(
            lambda x: x.rolling(20).std()
        )
        data['low_vol_score'] = 1.0 / (data['volatility_20'] + 1e-6)
        
        # 5. Alpha006 ç®€åŒ–ç‰ˆ: -1 * Correlation(Open, Volume, 10)
        # å¼€ç›˜ä»·ä¸æˆäº¤é‡è´Ÿç›¸å…³è¡¨ç¤ºæœºæ„é€†å‘æ“ä½œ
        data['open_chg'] = grouped['open'].pct_change()
        data['alpha006'] = -1 * grouped.apply(
            lambda x: x['open_chg'].rolling(10).corr(x['volume_chg'])
        ).reset_index(level=0, drop=True)
        
        if self.debug:
            print(f"     æ–°å¢5ä¸ªAlpha101å› å­")
        
        return data
    
    def calculate_microstructure_factors(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        âœ¨ å¾®è§‚ç»“æ„å› å­
        
        æ•æ‰æ—¥å†…é«˜é¢‘äº¤æ˜“çš„é™é¢‘ä¿¡å·:
        1. ä¹°å–å‹åŠ›ä¸å¹³è¡¡
        2. æˆäº¤é¢å æ¯”
        3. ä»·æ ¼è·³è·ƒ
        """
        print("  ğŸ”¬ è®¡ç®—å¾®è§‚ç»“æ„å› å­...")
        
        data = df.copy()
        grouped = data.groupby('instrument')
        
        # 1. ä¹°å–å‹åŠ› (Buy/Sell Pressure)
        # ä½¿ç”¨å½±çº¿é•¿åº¦è¡¡é‡
        data['upper_shadow'] = data['high'] - data[['open', 'close']].max(axis=1)
        data['lower_shadow'] = data[['open', 'close']].min(axis=1) - data['low']
        data['shadow_ratio'] = (
            (data['upper_shadow'] - data['lower_shadow']) / 
            ((data['high'] - data['low']) + 1e-6)
        )
        
        # 2. æˆäº¤é¢å æ¯” (Amount Ratio)
        # è¯¥è‚¡ç¥¨æˆäº¤é¢ç›¸å¯¹äºæ€»æˆäº¤é¢çš„å æ¯”å˜åŒ–
        if 'amount' in data.columns:
            data['amount_ma5'] = grouped['amount'].transform(
                lambda x: x.rolling(5).mean()
            )
            data['amount_ma20'] = grouped['amount'].transform(
                lambda x: x.rolling(20).mean()
            )
            data['amount_ratio'] = data['amount_ma5'] / (data['amount_ma20'] + 1e-6)
        else:
            # å¦‚æœæ²¡æœ‰amountåˆ—ï¼Œç”¨volumeæ›¿ä»£
            data['volume_ma5'] = grouped['volume'].transform(
                lambda x: x.rolling(5).mean()
            )
            data['volume_ma20'] = grouped['volume'].transform(
                lambda x: x.rolling(20).mean()
            )
            data['amount_ratio'] = data['volume_ma5'] / (data['volume_ma20'] + 1e-6)
        
        # 3. ä»·æ ¼è·³è·ƒ (Price Jump)
        # å¼€ç›˜ä»·ç›¸å¯¹äºå‰ä¸€æ—¥æ”¶ç›˜ä»·çš„è·³ç©º
        data['price_jump'] = grouped.apply(
            lambda x: (x['open'] - x['close'].shift(1)) / (x['close'].shift(1) + 1e-6)
        ).reset_index(level=0, drop=True)
        
        if self.debug:
            print(f"     æ–°å¢4ä¸ªå¾®è§‚ç»“æ„å› å­")
        
        return data
    
    def calculate_composite_momentum(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        âœ¨ å¤šå‘¨æœŸå¤åˆåŠ¨é‡
        
        ä¸åŒå‘¨æœŸçš„åŠ¨é‡æœ‰ä¸åŒå«ä¹‰:
        - çŸ­æœŸ(5-10æ—¥): åè½¬æ•ˆåº”
        - ä¸­æœŸ(20-60æ—¥): è¶‹åŠ¿å»¶ç»­
        - é•¿æœŸ(120-250æ—¥): ä»·å€¼å›å½’
        """
        print("  ğŸ“ˆ è®¡ç®—å¤åˆåŠ¨é‡å› å­...")
        
        data = df.copy()
        grouped = data.groupby('instrument')
        
        # å¤šå‘¨æœŸåŠ¨é‡
        periods = [5, 10, 20, 60, 120]
        
        for p in periods:
            data[f'momentum_{p}d'] = grouped['close'].pct_change(p)
        
        # å¤åˆåŠ¨é‡: åŠ æƒå¹³å‡
        # çŸ­æœŸæƒé‡å°ï¼Œé•¿æœŸæƒé‡å¤§ï¼ˆæ•æ‰è¶‹åŠ¿ï¼‰
        if all(f'momentum_{p}d' in data.columns for p in periods):
            weights = np.array([0.1, 0.15, 0.25, 0.3, 0.2])  # æƒé‡å’Œä¸º1
            
            momentum_cols = [f'momentum_{p}d' for p in periods]
            data['composite_momentum'] = (
                data[momentum_cols].fillna(0) * weights
            ).sum(axis=1)
        
        # åŠ¨é‡åŠ é€Ÿåº¦ (Momentum Acceleration)
        # åŠ¨é‡çš„å˜åŒ–ç‡
        data['momentum_accel'] = grouped['momentum_20d'].diff()
        
        if self.debug:
            print(f"     æ–°å¢{len(periods)+2}ä¸ªåŠ¨é‡å› å­")
        
        return data
    
    def calculate_volatility_factors(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        âœ¨ æ³¢åŠ¨ç‡å› å­ç°‡
        
        æ³¢åŠ¨ç‡çš„å¤šç»´åº¦åˆ»ç”»:
        1. å†å²æ³¢åŠ¨ç‡ (å¤šå‘¨æœŸ)
        2. æ³¢åŠ¨ç‡ååº¦ (Volatility Skew)
        3. ä¸Šè¡Œ/ä¸‹è¡Œæ³¢åŠ¨ç‡
        """
        print("  ğŸ“Š è®¡ç®—æ³¢åŠ¨ç‡å› å­...")
        
        data = df.copy()
        grouped = data.groupby('instrument')
        
        # è®¡ç®—æ”¶ç›Šç‡
        data['returns'] = grouped['close'].pct_change()
        
        # 1. å¤šå‘¨æœŸå†å²æ³¢åŠ¨ç‡
        for period in [5, 10, 20, 60]:
            data[f'volatility_{period}d'] = grouped['returns'].transform(
                lambda x: x.rolling(period).std() * np.sqrt(252)  # å¹´åŒ–
            )
        
        # 2. ä¸Šè¡Œ/ä¸‹è¡Œæ³¢åŠ¨ç‡ (Upside/Downside Volatility)
        # åˆ†åˆ«è®¡ç®—æ­£æ”¶ç›Šå’Œè´Ÿæ”¶ç›Šçš„æ³¢åŠ¨ç‡
        data['upside_vol'] = grouped['returns'].transform(
            lambda x: x[x > 0].rolling(20, min_periods=5).std()
        )
        data['downside_vol'] = grouped['returns'].transform(
            lambda x: x[x < 0].rolling(20, min_periods=5).std()
        )
        
        # æ³¢åŠ¨ç‡ååº¦
        data['vol_skew'] = (data['upside_vol'] - data['downside_vol']) / (
            data['upside_vol'] + data['downside_vol'] + 1e-6
        )
        
        if self.debug:
            print(f"     æ–°å¢7ä¸ªæ³¢åŠ¨ç‡å› å­")
        
        return data
    
    def orthogonalize_factors(self, df: pd.DataFrame, 
                              factor_columns: list) -> pd.DataFrame:
        """
        âœ¨ å› å­æ­£äº¤åŒ– (Orthogonalization)
        
        ç›®çš„: å»é™¤å› å­ä¹‹é—´çš„å¤šé‡å…±çº¿æ€§
        æ–¹æ³•: å¯¹æ¯ä¸ªå› å­ï¼Œå»é™¤å…¶ä»–å› å­çš„çº¿æ€§å½±å“
        
        ä¼˜åŠ¿:
        - è®©XGBoostå­¦åˆ°æ›´çº¯ç²¹çš„ä¿¡æ¯
        - æå‡æ¨¡å‹ç¨³å®šæ€§
        - å‡å°‘è¿‡æ‹Ÿåˆ
        """
        if not self.enable_orthogonalization:
            return df
        
        print("  ğŸ”§ å› å­æ­£äº¤åŒ–...")
        
        data = df.copy()
        
        # æŒ‰æ—¥æœŸåˆ†ç»„æ­£äº¤åŒ–
        orthogonalized_data = []
        
        for date in data['date'].unique():
            date_mask = data['date'] == date
            daily_data = data[date_mask].copy()
            
            if len(daily_data) < 10:  # æ ·æœ¬å¤ªå°‘è·³è¿‡
                orthogonalized_data.append(daily_data)
                continue
            
            # æå–å› å­æ•°æ®
            X = daily_data[factor_columns].fillna(0)
            
            # æ ‡å‡†åŒ–
            X_mean = X.mean()
            X_std = X.std()
            X_normalized = (X - X_mean) / (X_std + 1e-6)
            
            # æ­£äº¤åŒ–ï¼šå¯¹æ¯ä¸ªå› å­ï¼Œå‡å»å…¶ä»–å› å­çš„æŠ•å½±
            X_ortho = X_normalized.copy()
            
            for i, factor in enumerate(factor_columns):
                # å…¶ä»–å› å­
                other_factors = [f for f in factor_columns if f != factor]
                
                if len(other_factors) == 0:
                    continue
                
                # å›å½’
                y = X_normalized[factor].values.reshape(-1, 1)
                X_others = X_normalized[other_factors].values
                
                try:
                    # å»é™¤å…¶ä»–å› å­çš„å½±å“
                    reg = LinearRegression()
                    reg.fit(X_others, y)
                    predicted = reg.predict(X_others)
                    residual = y - predicted
                    
                    X_ortho[factor] = residual.flatten()
                except:
                    pass  # å›å½’å¤±è´¥ä¿æŒåŸå€¼
            
            # é‡æ–°æ ‡å‡†åŒ–
            X_ortho = (X_ortho - X_ortho.mean()) / (X_ortho.std() + 1e-6)
            
            # æ›´æ–°æ•°æ®
            for factor in factor_columns:
                daily_data[f'{factor}_ortho'] = X_ortho[factor].values
            
            orthogonalized_data.append(daily_data)
        
        result = pd.concat(orthogonalized_data, ignore_index=True)
        
        if self.debug:
            print(f"     æ­£äº¤åŒ–å®Œæˆï¼Œæ–°å¢{len(factor_columns)}ä¸ªæ­£äº¤å› å­")
        
        return result
    
    def generate_all_factors(self, price_data: pd.DataFrame) -> pd.DataFrame:
        """
        ç”Ÿæˆæ‰€æœ‰Alphaå¢å¼ºå› å­
        
        Args:
            price_data: ä»·æ ¼æ•°æ®ï¼Œéœ€åŒ…å« open, high, low, close, volume
        
        Returns:
            å¢å¼ºåçš„æ•°æ®æ¡†ï¼ŒåŒ…å«æ‰€æœ‰æ–°å› å­
        """
        print("\n" + "=" * 60)
        print("ğŸ”¬ Alphaå¢å¼ºå› å­å·¥ç¨‹")
        print("=" * 60)
        
        df = price_data.copy()
        
        # 1. Alpha101 å› å­
        df = self.calculate_alpha101_factors(df)
        
        # 2. å¾®è§‚ç»“æ„å› å­
        df = self.calculate_microstructure_factors(df)
        
        # 3. å¤åˆåŠ¨é‡å› å­
        df = self.calculate_composite_momentum(df)
        
        # 4. æ³¢åŠ¨ç‡å› å­
        df = self.calculate_volatility_factors(df)
        
        # 5. è¯†åˆ«æ‰€æœ‰æ–°ç”Ÿæˆçš„å› å­
        new_factor_columns = [
            'intraday_strength', 'vol_price_corr', 'bias_20', 'low_vol_score', 'alpha006',
            'shadow_ratio', 'amount_ratio', 'price_jump',
            'composite_momentum', 'momentum_accel',
            'vol_skew'
        ]
        
        # æ·»åŠ å¤šå‘¨æœŸåŠ¨é‡å’Œæ³¢åŠ¨ç‡
        new_factor_columns += [f'momentum_{p}d' for p in [5, 10, 20, 60, 120]]
        new_factor_columns += [f'volatility_{p}d' for p in [5, 10, 20, 60]]
        new_factor_columns += ['upside_vol', 'downside_vol']
        
        # è¿‡æ»¤å‡ºå®é™…å­˜åœ¨çš„å› å­
        existing_factors = [f for f in new_factor_columns if f in df.columns]
        
        # 6. å› å­æ­£äº¤åŒ–ï¼ˆå¯é€‰ï¼‰
        if self.enable_orthogonalization and len(existing_factors) > 0:
            df = self.orthogonalize_factors(df, existing_factors)
        
        print("\nâœ… å› å­ç”Ÿæˆå®Œæˆ")
        print(f"   æ€»è®¡æ–°å¢: {len(existing_factors)} ä¸ªåŸå§‹å› å­")
        if self.enable_orthogonalization:
            print(f"   æ­£äº¤åŒ–å: {len(existing_factors)} ä¸ªæ­£äº¤å› å­")
        
        return df