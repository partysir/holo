"""
data_module_incremental.py - å¢é‡æ›´æ–°æ¨¡å—ä¿®å¤ç‰ˆ v2.3

å…³é”®ä¿®å¤ï¼š
âœ… æ·»åŠ  min_days_listed å‚æ•°ä¼ é€’
âœ… åœ¨è·å–è‚¡ç¥¨åˆ—è¡¨æ—¶è¿‡æ»¤æ–°è‚¡
âœ… åœ¨è·å–ä»·æ ¼æ•°æ®æ—¶è¿‡æ»¤ä¸Šå¸‚å‰æ•°æ®
"""

import pandas as pd
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor, as_completed
import time

# å¯¼å…¥ä¿®å¤åçš„æ•°æ®æ¨¡å—
from data_module import (
    DataCache,
    TushareDataSource,
    StockRankerModel,
    calculate_simple_factors
)


def load_data_with_incremental_update(
    start_date,
    end_date,
    max_stocks=50,
    cache_manager=None,
    use_stockranker=True,
    custom_weights=None,
    tushare_token=None,
    use_fundamental=True,
    force_full_update=False,
    use_sampling=True,
    sample_size=100,
    max_workers=4,
    min_days_listed=180  # âœ… å…³é”®æ–°å¢å‚æ•°
):
    """
    å¢é‡æ›´æ–°æ•°æ®åŠ è½½å‡½æ•° (ä¿®å¤ç‰ˆ v2.3)

    æ–°å¢å‚æ•°:
        min_days_listed: è‚¡ç¥¨æœ€å°‘ä¸Šå¸‚å¤©æ•°ï¼Œé»˜è®¤180å¤©
    """

    print("\n" + "=" * 80)
    print("ğŸ“¦ å¢é‡æ›´æ–°æ•°æ®åŠ è½½ (v2.3 - ä¿®å¤å‰è§†åå·®)")
    print("=" * 80)

    # æ˜¾ç¤ºå‰è§†åå·®é˜²æŠ¤é…ç½®
    print(f"\nğŸ”’ å‰è§†åå·®é˜²æŠ¤:")
    print(f"  - æœ€çŸ­ä¸Šå¸‚æ—¶é—´: {min_days_listed} å¤©")
    print(f"  - å›æµ‹å¼€å§‹æ—¥æœŸ: {start_date}")

    # è®¡ç®—æœ€æ™šä¸Šå¸‚æ—¥æœŸ
    backtest_start = pd.to_datetime(start_date)
    latest_list_date = backtest_start - timedelta(days=min_days_listed)
    print(f"  - è¦æ±‚ä¸Šå¸‚äº: {latest_list_date.strftime('%Y-%m-%d')} ä¹‹å‰")

    model_type = "StockRankerå¤šå› å­" if use_stockranker else "ç®€å•æŠ€æœ¯å› å­"
    if use_stockranker and use_fundamental:
        model_type += " + åŸºæœ¬é¢"
    print(f"  - å› å­æ¨¡å‹: {model_type}")

    # ç”Ÿæˆç¼“å­˜é”®ï¼ˆåŒ…å«ç‰ˆæœ¬å·å’Œmin_days_listedï¼‰
    model_suffix = "stockranker" if use_stockranker else "simple"
    if use_fundamental:
        model_suffix += "_fundamental"

    cache_key = f"factor_data_incr_v2.3_{start_date}_{end_date}_{max_stocks}_{model_suffix}_{min_days_listed}"
    price_cache_key = f"price_data_incr_v2.3_{start_date}_{end_date}_{max_stocks}_{min_days_listed}"

    # å°è¯•ä»ç¼“å­˜åŠ è½½
    if not force_full_update and cache_manager:
        print("\nğŸ” æ£€æŸ¥ç¼“å­˜...")
        factor_data = cache_manager.load_from_csv(cache_key)
        price_data = cache_manager.load_from_csv(price_cache_key)

        if factor_data is not None and price_data is not None:
            print("âœ“ ä½¿ç”¨ç¼“å­˜æ•°æ®")
            print(f"  - å› å­æ•°æ®: {len(factor_data)} æ¡")
            print(f"  - ä»·æ ¼æ•°æ®: {len(price_data)} æ¡")
            return factor_data, price_data
        else:
            print("âœ— ç¼“å­˜æœªæ‰¾åˆ°ï¼Œå¼€å§‹å¢é‡æ›´æ–°...")

    # åˆå§‹åŒ–æ•°æ®æº
    from data_module import RateLimiter
    rate_limiter = RateLimiter(max_calls=800, time_window=60)
    data_source = TushareDataSource(
        cache_manager=cache_manager,
        token=tushare_token,
        rate_limiter=rate_limiter
    )

    # ========== å…³é”®ä¿®å¤1ï¼šè·å–è‚¡ç¥¨åˆ—è¡¨æ—¶ä¼ å…¥æ—¥æœŸ ==========
    print("\nğŸ“‹ è·å–è‚¡ç¥¨åˆ—è¡¨...")
    stock_list = data_source.get_stock_list(
        date=start_date,              # âœ… ä¼ å…¥å›æµ‹å¼€å§‹æ—¥æœŸ
        min_days_listed=min_days_listed  # âœ… ä¼ å…¥æœ€çŸ­ä¸Šå¸‚å¤©æ•°
    )

    if not stock_list:
        print("âœ— æ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨!")
        return None, None

    # é‡‡æ ·å¤„ç†
    if use_sampling:
        original_count = len(stock_list)
        stock_list = stock_list[:sample_size]
        print(f"  ğŸ“Š é‡‡æ ·æ¨¡å¼: {len(stock_list)}/{original_count} åªè‚¡ç¥¨")
    else:
        stock_list = stock_list[:max_stocks]
        print(f"  ğŸ“Š å®Œæ•´æ¨¡å¼: {len(stock_list)} åªè‚¡ç¥¨")

    # ========== å…³é”®ä¿®å¤2ï¼šè·å–è‚¡ç¥¨ä¸Šå¸‚æ—¥æœŸä¿¡æ¯ ==========
    print("\nğŸ“… è·å–è‚¡ç¥¨ä¸Šå¸‚æ—¥æœŸä¿¡æ¯...")
    stock_info_df = data_source.pro.stock_basic(
        exchange='',
        list_status='L',
        fields='ts_code,list_date'
    )
    stock_info_dict = dict(zip(stock_info_df['ts_code'], stock_info_df['list_date']))
    print(f"  âœ“ è·å–åˆ° {len(stock_info_dict)} åªè‚¡ç¥¨çš„ä¸Šå¸‚æ—¥æœŸ")

    # ========== å¤šçº¿ç¨‹è·å–ä»·æ ¼æ•°æ® ==========
    print(f"\nğŸ“Š ä½¿ç”¨ {max_workers} ä¸ªçº¿ç¨‹å¹¶è¡Œè·å–æ•°æ®...")
    all_price_data = []
    success_count = 0
    failed_stocks = []

    def fetch_price_data(ts_code):
        """è·å–å•åªè‚¡ç¥¨æ•°æ®ï¼ˆå¸¦ä¸Šå¸‚æ—¥æœŸè¿‡æ»¤ï¼‰"""
        try:
            list_date = stock_info_dict.get(ts_code)  # âœ… è·å–ä¸Šå¸‚æ—¥æœŸ
            df = data_source.get_price_data(
                ts_code,
                start_date,
                end_date,
                list_date=list_date  # âœ… ä¼ å…¥ä¸Šå¸‚æ—¥æœŸè¿›è¡Œè¿‡æ»¤
            )
            return ts_code, df
        except Exception as e:
            print(f"  âœ— {ts_code} å¤±è´¥: {e}")
            return ts_code, None

    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = {executor.submit(fetch_price_data, code): code for code in stock_list}

        for i, future in enumerate(as_completed(futures), 1):
            ts_code, df = future.result()

            if df is not None and len(df) > 0:
                all_price_data.append(df)
                success_count += 1
            else:
                failed_stocks.append(ts_code)

            # è¿›åº¦æ˜¾ç¤º
            if i % 50 == 0:
                print(f"  è¿›åº¦: {i}/{len(stock_list)} (æˆåŠŸ: {success_count})")

    print(f"\nâœ“ ä»·æ ¼æ•°æ®è·å–å®Œæˆ:")
    print(f"  - æˆåŠŸ: {success_count}/{len(stock_list)} åª")
    if failed_stocks:
        print(f"  - å¤±è´¥: {len(failed_stocks)} åª")
        print(f"    ç¤ºä¾‹: {failed_stocks[:5]}")

    if len(all_price_data) == 0:
        print("âœ— æœªè·å–åˆ°ä»»ä½•æ•°æ®!")
        return None, None

    # åˆå¹¶ä»·æ ¼æ•°æ®
    price_df = pd.concat(all_price_data, ignore_index=True)
    print(f"  - æ€»è®°å½•æ•°: {len(price_df)} æ¡")

    # ========== éªŒè¯ï¼šæ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ–°è‚¡ ==========
    print("\nğŸ” æ•°æ®è´¨é‡éªŒè¯:")
    unique_stocks = price_df['instrument'].unique()
    print(f"  - å®é™…è‚¡ç¥¨æ•°: {len(unique_stocks)} åª")

    # æ£€æŸ¥åŒ—äº¤æ‰€æ–°è‚¡ï¼ˆ920å¼€å¤´ï¼‰å’Œç§‘åˆ›æ¿æ–°è‚¡ï¼ˆ689å¼€å¤´ï¼‰
    new_stock_codes = [s for s in unique_stocks if s.startswith(('920', '689', '787'))]
    if new_stock_codes:
        print(f"  âš ï¸  è­¦å‘Šï¼šä»å‘ç° {len(new_stock_codes)} åªå¯ç–‘æ–°è‚¡ä»£ç ")
        print(f"     ç¤ºä¾‹: {new_stock_codes[:5]}")
        print(f"  âš ï¸  å»ºè®®ï¼šå¢å¤§ min_days_listed å‚æ•°æˆ–æ£€æŸ¥ get_stock_list è¿‡æ»¤é€»è¾‘")
    else:
        print(f"  âœ… é€šè¿‡ï¼šæœªå‘ç°å¯ç–‘æ–°è‚¡ä»£ç ")

    # ========== è·å–åŸºæœ¬é¢æ•°æ® ==========
    if use_stockranker and use_fundamental:
        print(f"\nğŸ“ˆ è·å–åŸºæœ¬é¢è´¢åŠ¡æ•°æ® (å¹¶è¡Œæ¨¡å¼)...")
        all_financial_data = []
        financial_success = 0

        def fetch_financial_data(ts_code):
            """è·å–å•åªè‚¡ç¥¨è´¢åŠ¡æ•°æ®"""
            try:
                df = data_source.get_financial_indicators(ts_code, start_date, end_date)
                return ts_code, df
            except Exception as e:
                return ts_code, None

        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = {executor.submit(fetch_financial_data, code): code
                      for code in unique_stocks}

            for i, future in enumerate(as_completed(futures), 1):
                ts_code, df = future.result()

                if df is not None and len(df) > 0:
                    all_financial_data.append(df)
                    financial_success += 1

                if i % 50 == 0:
                    print(f"  è¿›åº¦: {i}/{len(unique_stocks)} (æˆåŠŸ: {financial_success})")

        print(f"âœ“ è´¢åŠ¡æ•°æ®è·å–å®Œæˆ: {financial_success}/{len(unique_stocks)} åª")

        if len(all_financial_data) > 0:
            financial_df = pd.concat(all_financial_data, ignore_index=True)
            print("\nğŸ”— åˆå¹¶åŸºæœ¬é¢æ•°æ®åˆ°æ—¥çº¿æ•°æ®...")
            price_df = data_source.merge_financial_data_to_daily(price_df, financial_df)
        else:
            print("âš ï¸  æœªè·å–åˆ°åŸºæœ¬é¢æ•°æ®ï¼Œå°†ä¸ä½¿ç”¨åŸºæœ¬é¢å› å­")
            use_fundamental = False

    # ç¡®ä¿æ—¥æœŸæ ¼å¼ä¸€è‡´
    price_df['date'] = price_df['date'].astype(str)

    # ========== å› å­è®¡ç®— ==========
    if use_stockranker:
        model = StockRankerModel(
            custom_weights=custom_weights,
            use_fundamental=use_fundamental
        )
        factor_df = model.calculate_all_factors(price_df)
        factor_df = model.calculate_position_score(factor_df)
    else:
        print("\nâš™ï¸  è®¡ç®—ç®€å•æŠ€æœ¯å› å­...")
        factor_df = calculate_simple_factors(price_df)

    factor_df = factor_df.dropna(subset=['position'])

    # ========== å…³é”®ä¿®å¤ï¼šä¿ç•™æ‰€æœ‰å› å­åˆ— ==========
    essential_columns = ['date', 'instrument', 'position']
    price_only_columns = ['open', 'high', 'low', 'close', 'volume', 'amount']

    all_columns = factor_df.columns.tolist()
    factor_columns = [col for col in all_columns
                     if col not in essential_columns + price_only_columns]

    print(f"\nğŸ“Š å› å­åˆ—è¯†åˆ«:")
    print(f"  - å¿…é¡»åˆ—: {essential_columns}")
    print(f"  - è¯†åˆ«åˆ°çš„å› å­åˆ—: {len(factor_columns)} ä¸ª")
    if len(factor_columns) <= 10:
        print(f"    {factor_columns}")
    else:
        print(f"    å‰10ä¸ª: {factor_columns[:10]}")
        print(f"    ... è¿˜æœ‰ {len(factor_columns)-10} ä¸ª")

    # ä¿ç•™å› å­åˆ—
    columns_to_keep = essential_columns + factor_columns
    result_factor = factor_df[columns_to_keep].copy()

    # ä¿ç•™ä»·æ ¼åˆ—
    price_columns_to_keep = essential_columns + price_only_columns
    if use_fundamental:
        fundamental_cols = ['roe', 'roa', 'gross_margin', 'net_margin', 'debt_ratio']
        for col in fundamental_cols:
            if col in price_df.columns:
                price_columns_to_keep.append(col)

    result_price = price_df[price_columns_to_keep].copy()

    # ========== è·å–è¡Œä¸šæ•°æ® ==========
    print("\nğŸ“Š è·å–è¡Œä¸šæ•°æ®...")
    industry_data = data_source.get_industry_data(unique_stocks.tolist(), use_cache=True)

    if industry_data is not None and len(industry_data) > 0:
        result_factor = result_factor.merge(industry_data, on='instrument', how='left')
        result_factor['industry'] = result_factor['industry'].fillna('å…¶ä»–')
        print(f"  âœ“ è¡Œä¸šæ•°æ®å·²åˆå¹¶")
    else:
        result_factor['industry'] = 'Unknown'
        print(f"  âš ï¸  æœªè·å–åˆ°è¡Œä¸šæ•°æ®")

    # ========== ä¿å­˜åˆ°ç¼“å­˜ ==========
    if cache_manager:
        print("\nğŸ’¾ ä¿å­˜åˆ°ç¼“å­˜...")
        cache_manager.save_to_csv(result_factor, cache_key)
        cache_manager.save_to_csv(result_price, price_cache_key)

    # ========== æœ€ç»ˆç»Ÿè®¡ ==========
    print(f"\nâœ“ æ•°æ®å‡†å¤‡å®Œæˆ:")
    print(f"  - å› å­æ•°æ®: {len(result_factor)} æ¡")
    print(f"  - ä»·æ ¼æ•°æ®: {len(result_price)} æ¡")
    print(f"  - è‚¡ç¥¨æ•°é‡: {result_factor['instrument'].nunique()} åª")
    print(f"  - äº¤æ˜“æ—¥æ•°: {result_factor['date'].nunique()} å¤©")
    print(f"  - å› å­åˆ—æ•°: {len(factor_columns)} ä¸ª")  # âœ… æ˜¾ç¤ºå› å­æ•°é‡
    print(f"  - è¡Œä¸šæ•°é‡: {result_factor['industry'].nunique()} ä¸ª")

    if use_fundamental and use_stockranker:
        print(f"  - åŸºæœ¬é¢å› å­: å·²å¯ç”¨")

    return result_factor, result_price