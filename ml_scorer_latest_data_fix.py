# -*- coding: utf-8 -*-
"""
ml_scorer_latest_data_fix.py - ä¿®å¤ç‰ˆ v3.0

ğŸ”§ æ ¸å¿ƒä¿®å¤ï¼š
1. âœ… ä¿®æ­£æ¨¡å‹è®¿é—®è·¯å¾„ï¼šml_scorer.models['best'] è€Œé ml_scorer.model
2. âœ… ä¿®æ­£ç‰¹å¾æ ‡å‡†åŒ–ï¼šä½¿ç”¨ ml_scorer.scaler
3. âœ… æ·»åŠ å®Œæ•´çš„é”™è¯¯å¤„ç†
4. âœ… æ”¯æŒåˆ†ç±»å’Œå›å½’ä¸¤ç§æ¨¡å‹
5. âœ… ä¿è¯æœ€æ–°æ•°æ®å§‹ç»ˆæœ‰è¯„åˆ†

ç‰ˆæœ¬ï¼šv3.0
æ—¥æœŸï¼š2025-12-20
çŠ¶æ€ï¼šç”Ÿäº§å°±ç»ª
"""

import pandas as pd
import numpy as np
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')


def diagnose_prediction_gap(factor_data, price_data, target_period=5):
    """
    è¯Šæ–­é¢„æµ‹ç¼ºå¤±é—®é¢˜
    """
    print("\n" + "="*80)
    print("ğŸ” é¢„æµ‹ç¼ºå¤±è¯Šæ–­")
    print("="*80)

    latest_factor_date = factor_data['date'].max()
    latest_price_date = price_data['date'].max()

    print(f"\nğŸ“… æ•°æ®æ—¥æœŸ:")
    print(f"   å› å­æœ€æ–°: {latest_factor_date}")
    print(f"   ä»·æ ¼æœ€æ–°: {latest_price_date}")

    # æ£€æŸ¥æœ‰è¯„åˆ†çš„æœ€æ–°æ—¥æœŸ
    if 'ml_score' in factor_data.columns:
        valid_scores = factor_data[factor_data['ml_score'].notna()]
        if len(valid_scores) > 0:
            latest_scored_date = valid_scores['date'].max()
            print(f"   è¯„åˆ†æœ€æ–°: {latest_scored_date}")

            gap_days = (pd.to_datetime(latest_factor_date) -
                       pd.to_datetime(latest_scored_date)).days

            if gap_days > 0:
                print(f"\nâš ï¸  è¯„åˆ†ç¼ºå¤±: {gap_days} å¤©")
                print(f"   ç¼ºå¤±åŒºé—´: {latest_scored_date} åˆ° {latest_factor_date}")
            else:
                print(f"\nâœ… è¯„åˆ†å®Œæ•´")
        else:
            print(f"\nâŒ å®Œå…¨æ— è¯„åˆ†")
    else:
        print(f"\nâŒ æ—  ml_score åˆ—")

    # æ£€æŸ¥æœªæ¥æ”¶ç›Šæ ‡ç­¾
    factor_with_price = factor_data.merge(
        price_data[['date', 'instrument', 'close']],
        on=['date', 'instrument'],
        how='left'
    )

    factor_with_price = factor_with_price.sort_values(['instrument', 'date'])
    factor_with_price[f'future_return_{target_period}d'] = (
        factor_with_price.groupby('instrument')['close']
        .shift(-target_period) / factor_with_price['close'] - 1
    )

    latest_data = factor_with_price[factor_with_price['date'] == latest_factor_date]
    valid_returns = latest_data[f'future_return_{target_period}d'].notna().sum()

    print(f"\nğŸ“Š æœ€æ–°æ•°æ® ({latest_factor_date}):")
    print(f"   æ€»è‚¡ç¥¨æ•°: {len(latest_data)}")
    print(f"   æœ‰æœªæ¥æ”¶ç›Šæ ‡ç­¾: {valid_returns}")
    print(f"   ç¼ºå¤±æ¯”ä¾‹: {(len(latest_data)-valid_returns)/len(latest_data)*100:.1f}%")

    if valid_returns == 0:
        print(f"\nğŸ’¡ æ ¹å› åˆ†æ:")
        print(f"   â€¢ æœ€æ–°æ•°æ®éœ€è¦ {target_period} å¤©åçš„ä»·æ ¼è®¡ç®—æ”¶ç›Š")
        print(f"   â€¢ ä½†æˆ‘ä»¬åªæœ‰åˆ° {latest_price_date} çš„ä»·æ ¼")
        print(f"   â€¢ å› æ­¤æ— æ³•ç”Ÿæˆè®­ç»ƒæ ‡ç­¾ y")
        print(f"   â€¢ å¯¼è‡´ Walk-Forward è·³è¿‡æœ€æ–°çª—å£")

    print("="*80)


def quick_fix_ml_scorer(ml_scorer, factor_data, price_data, factor_columns):
    """
    ğŸ”§ ä¿®å¤ç‰ˆï¼šä¸ºæœ€æ–°æ•°æ®ç”ŸæˆMLè¯„åˆ†

    æ ¸å¿ƒä¿®å¤ç‚¹ï¼š
    1. ä½¿ç”¨ ml_scorer.models['best'] è€Œé ml_scorer.model
    2. ä½¿ç”¨ ml_scorer.scaler è¿›è¡Œç‰¹å¾æ ‡å‡†åŒ–
    3. å¤„ç†å…¨éƒ¨æ— è¯„åˆ†æ•°æ®ï¼ˆä¸ä»…æ˜¯æœ€æ–°æ—¥æœŸï¼‰

    Args:
        ml_scorer: å·²è®­ç»ƒçš„AdvancedMLScorerå®ä¾‹
        factor_data: å› å­æ•°æ®
        price_data: ä»·æ ¼æ•°æ®
        factor_columns: å› å­åˆ—ååˆ—è¡¨

    Returns:
        factor_data: è¡¥å…¨äº†è¯„åˆ†çš„DataFrame
    """
    print("\n" + "="*80)
    print("ğŸ”§ åº”ç”¨æœ€æ–°æ•°æ®é¢„æµ‹ä¿®å¤ (v3.0)")
    print("="*80)

    # ============ æ­¥éª¤0: éªŒè¯MLè¯„åˆ†å™¨çŠ¶æ€ ============
    if ml_scorer is None:
        print("  âŒ MLè¯„åˆ†å™¨ä¸º None")
        return _fallback_scoring(factor_data, factor_columns)

    # ğŸ”§ ä¿®å¤ç‚¹1ï¼šæ£€æŸ¥æ­£ç¡®çš„æ¨¡å‹è·¯å¾„
    if not hasattr(ml_scorer, 'models') or 'best' not in ml_scorer.models:
        print("  âŒ æ¨¡å‹æœªè®­ç»ƒ (ç¼ºå°‘ models['best'])")
        return _fallback_scoring(factor_data, factor_columns)

    model = ml_scorer.models['best']
    if model is None:
        print("  âŒ æœ€ä½³æ¨¡å‹ä¸º None")
        return _fallback_scoring(factor_data, factor_columns)

    # æ£€æŸ¥æ ‡å‡†åŒ–å™¨
    if not hasattr(ml_scorer, 'scaler') or ml_scorer.scaler is None:
        print("  âš ï¸  è­¦å‘Šï¼šç¼ºå°‘æ ‡å‡†åŒ–å™¨ï¼Œé¢„æµ‹ç²¾åº¦å¯èƒ½é™ä½")

    print(f"  âœ… æ¨¡å‹çŠ¶æ€éªŒè¯é€šè¿‡:")
    print(f"     â€¢ æ¨¡å‹ç±»å‹: {type(model).__name__}")
    print(f"     â€¢ åˆ†ç±»æ¨¡å¼: {ml_scorer.use_classification if hasattr(ml_scorer, 'use_classification') else 'Unknown'}")

    # ============ æ­¥éª¤1: è¯†åˆ«éœ€è¦é¢„æµ‹çš„æ•°æ® ============
    print(f"\n  ğŸ“… åˆ†æè¯„åˆ†è¦†ç›–æƒ…å†µ...")

    if 'ml_score' not in factor_data.columns:
        # å¦‚æœå®Œå…¨æ²¡æœ‰ml_scoreåˆ—ï¼Œéœ€è¦å…¨éƒ¨é¢„æµ‹
        factor_data['ml_score'] = np.nan
        dates_to_predict = factor_data['date'].unique()
        print(f"     â€¢ æ— ç°æœ‰è¯„åˆ†ï¼Œéœ€å…¨éƒ¨é¢„æµ‹")
    else:
        # æ‰¾å‡ºè¯„åˆ†ç¼ºå¤±çš„æ—¥æœŸ
        date_coverage = factor_data.groupby('date')['ml_score'].apply(
            lambda x: x.notna().sum() / len(x)
        )
        dates_to_predict = date_coverage[date_coverage < 0.5].index.tolist()

        if len(dates_to_predict) == 0:
            print(f"     â„¹ï¸  è¯„åˆ†å·²å®Œæ•´ï¼Œæ— éœ€ä¿®å¤")
            return factor_data

    print(f"     â€¢ éœ€é¢„æµ‹æ—¥æœŸ: {len(dates_to_predict)} å¤©")
    if len(dates_to_predict) <= 5:
        for date in dates_to_predict:
            print(f"       - {date}")
    else:
        for date in dates_to_predict[:3]:
            print(f"       - {date}")
        print(f"       ... è¿˜æœ‰ {len(dates_to_predict)-3} å¤©")

    # ============ æ­¥éª¤2: å‡†å¤‡ç‰¹å¾ ============
    print(f"\n  ğŸ”¨ å‡†å¤‡ç‰¹å¾æ•°æ®...")

    # ğŸ”§ ä¿®å¤ç‚¹2ï¼šä½¿ç”¨æ­£ç¡®çš„ç‰¹å¾åˆ—è¡¨
    if hasattr(ml_scorer, 'feature_names') and ml_scorer.feature_names:
        model_features = ml_scorer.feature_names
    else:
        print(f"     âš ï¸  è­¦å‘Šï¼šä½¿ç”¨ä¼ å…¥çš„factor_columnsä½œä¸ºç‰¹å¾")
        model_features = factor_columns

    print(f"     â€¢ æ¨¡å‹ç‰¹å¾æ•°: {len(model_features)}")

    # æå–éœ€è¦é¢„æµ‹çš„æ•°æ®
    data_to_predict = factor_data[factor_data['date'].isin(dates_to_predict)].copy()
    print(f"     â€¢ å¾…é¢„æµ‹æ ·æœ¬: {len(data_to_predict)}")

    # æ£€æŸ¥ç¼ºå¤±ç‰¹å¾
    missing_features = [f for f in model_features if f not in data_to_predict.columns]
    if missing_features:
        print(f"     âš ï¸  ç¼ºå¤± {len(missing_features)} ä¸ªç‰¹å¾ï¼Œç”¨0å¡«å……")
        if len(missing_features) <= 5:
            print(f"        {missing_features}")
        for feat in missing_features:
            data_to_predict[feat] = 0

    # æ„å»ºç‰¹å¾çŸ©é˜µ
    try:
        X_predict = data_to_predict[model_features].values
    except Exception as e:
        print(f"     âŒ ç‰¹å¾æå–å¤±è´¥: {e}")
        return _fallback_scoring(factor_data, factor_columns)

    # å¤„ç†NaNå’ŒInf
    X_predict = np.nan_to_num(X_predict, nan=0.0, posinf=0.0, neginf=0.0)

    # ğŸ”§ ä¿®å¤ç‚¹3ï¼šä½¿ç”¨æ ‡å‡†åŒ–å™¨
    if hasattr(ml_scorer, 'scaler') and ml_scorer.scaler is not None:
        try:
            X_predict_scaled = ml_scorer.scaler.transform(X_predict)
            print(f"     âœ… ç‰¹å¾æ ‡å‡†åŒ–å®Œæˆ")
        except Exception as e:
            print(f"     âš ï¸  æ ‡å‡†åŒ–å¤±è´¥: {e}ï¼Œä½¿ç”¨åŸå§‹ç‰¹å¾")
            X_predict_scaled = X_predict
    else:
        X_predict_scaled = X_predict

    # ============ æ­¥éª¤3: æ‰§è¡Œé¢„æµ‹ ============
    print(f"\n  ğŸš€ æ‰§è¡Œé¢„æµ‹...")

    try:
        use_classification = ml_scorer.use_classification if hasattr(ml_scorer, 'use_classification') else False

        if use_classification:
            # åˆ†ç±»æ¨¡å‹ï¼šé¢„æµ‹æ¦‚ç‡
            if hasattr(model, 'predict_proba'):
                predictions = model.predict_proba(X_predict_scaled)
                # å¤„ç†ä¸åŒçš„è¾“å‡ºæ ¼å¼
                if len(predictions.shape) > 1 and predictions.shape[1] > 1:
                    predictions = predictions[:, 1]  # å–æ­£ç±»æ¦‚ç‡
                else:
                    predictions = predictions.flatten()
                print(f"     âœ… åˆ†ç±»é¢„æµ‹å®Œæˆ: {len(predictions)} ä¸ªæ ·æœ¬")
            else:
                print(f"     âš ï¸  æ¨¡å‹æ—  predict_probaï¼Œä½¿ç”¨ predict")
                predictions = model.predict(X_predict_scaled)
        else:
            # å›å½’æ¨¡å‹ï¼šç›´æ¥é¢„æµ‹
            predictions = model.predict(X_predict_scaled)
            print(f"     âœ… å›å½’é¢„æµ‹å®Œæˆ: {len(predictions)} ä¸ªæ ·æœ¬")

        # ç¡®ä¿é¢„æµ‹ç»“æœæ˜¯1ç»´æ•°ç»„
        predictions = np.asarray(predictions).flatten()

    except Exception as e:
        print(f"     âŒ é¢„æµ‹å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return _fallback_scoring(factor_data, factor_columns)

    # ============ æ­¥éª¤4: åå¤„ç†ä¸å†™å…¥ ============
    print(f"\n  ğŸ“ åå¤„ç†ä¸å†™å…¥...")

    # å†™å…¥åŸå§‹é¢„æµ‹å€¼
    data_to_predict['ml_score'] = predictions

    # æŒ‰æ—¥æœŸæ ‡å‡†åŒ–åˆ°0-1åŒºé—´ï¼ˆä½¿ç”¨æ’åç™¾åˆ†ä½ï¼‰
    for date in dates_to_predict:
        date_mask = data_to_predict['date'] == date
        scores = data_to_predict.loc[date_mask, 'ml_score']

        if len(scores) > 0:
            # ä½¿ç”¨æ’åç™¾åˆ†ä½ï¼ˆæ›´ç¨³å¥ï¼‰
            ranked = scores.rank(pct=True)
            data_to_predict.loc[date_mask, 'ml_score'] = ranked

    print(f"     â€¢ å·²å¯¹ {len(dates_to_predict)} ä¸ªæ—¥æœŸè¿›è¡Œæ’åæ ‡å‡†åŒ–")

    # åˆå¹¶å›åŸæ•°æ®
    for idx, row in data_to_predict.iterrows():
        mask = (factor_data['date'] == row['date']) & \
               (factor_data['instrument'] == row['instrument'])
        factor_data.loc[mask, 'ml_score'] = row['ml_score']

    # ç¡®ä¿åŒæ—¶åˆ›å»ºpositionåˆ—ï¼ˆç”¨äºå›æµ‹ï¼‰
    if 'position' not in factor_data.columns:
        factor_data['position'] = factor_data['ml_score']
    else:
        # æ›´æ–°positionåˆ—ï¼ˆä»…æ›´æ–°æ–°é¢„æµ‹çš„éƒ¨åˆ†ï¼‰
        for date in dates_to_predict:
            date_mask = factor_data['date'] == date
            factor_data.loc[date_mask, 'position'] = factor_data.loc[date_mask, 'ml_score']

    # ============ æ­¥éª¤5: éªŒè¯ç»“æœ ============
    print(f"\n  âœ… ä¿®å¤å®Œæˆï¼ŒéªŒè¯ç»“æœ...")

    latest_date = factor_data['date'].max()
    latest_data = factor_data[factor_data['date'] == latest_date]
    valid_count = latest_data['ml_score'].notna().sum()

    print(f"\n  ğŸ“Š ä¿®å¤åçŠ¶æ€:")
    print(f"     â€¢ æœ€æ–°æ—¥æœŸ: {latest_date}")
    print(f"     â€¢ æœ‰æ•ˆè¯„åˆ†: {valid_count}/{len(latest_data)} ({valid_count/len(latest_data)*100:.1f}%)")

    if valid_count == 0:
        print(f"     âŒ è­¦å‘Šï¼šæœ€æ–°æ—¥æœŸä»æ— è¯„åˆ†ï¼")
        return _fallback_scoring(factor_data, factor_columns)
    elif valid_count < len(latest_data) * 0.5:
        print(f"     âš ï¸  è­¦å‘Šï¼šè¦†ç›–ç‡åä½")
    else:
        print(f"     âœ… è¦†ç›–ç‡è‰¯å¥½")

    # å…¨å±€ç»Ÿè®¡
    total_valid = factor_data['ml_score'].notna().sum()
    total_count = len(factor_data)
    print(f"     â€¢ å…¨å±€è¦†ç›–: {total_valid}/{total_count} ({total_valid/total_count*100:.1f}%)")

    print("="*80)
    return factor_data


def _fallback_scoring(factor_data, factor_columns):
    """
    ğŸ†˜ Fallbackè¯„åˆ†æ–¹æ¡ˆï¼ˆå½“MLé¢„æµ‹å¤±è´¥æ—¶ï¼‰
    """
    print("\n  ğŸš¨ å¯åŠ¨ Fallback è¯„åˆ†æ–¹æ¡ˆ...")

    data = factor_data.copy()

    # æ–¹æ¡ˆ1ï¼šä½¿ç”¨positionåˆ—
    if 'position' in data.columns:
        if data['position'].notna().sum() > len(data) * 0.5:
            print("     â€¢ ä½¿ç”¨ç°æœ‰ position åˆ—ä½œä¸º ml_score")
            data['ml_score'] = data['position']
            return data

    # æ–¹æ¡ˆ2ï¼šä½¿ç”¨å› å­å‡å€¼
    valid_factors = [col for col in factor_columns
                    if col in data.columns and pd.api.types.is_numeric_dtype(data[col])]

    if valid_factors:
        print(f"     â€¢ ä½¿ç”¨ {len(valid_factors)} ä¸ªå› å­çš„å‡å€¼")
        data['ml_score'] = data[valid_factors].mean(axis=1)
        data['ml_score'] = data.groupby('date')['ml_score'].rank(pct=True)
        data['position'] = data['ml_score']
        return data

    # æ–¹æ¡ˆ3ï¼šéšæœºè¯„åˆ†ï¼ˆæœ€åæ‰‹æ®µï¼‰
    print("     â€¢ âš ï¸  ç´§æ€¥æªæ–½ï¼šéšæœºè¯„åˆ†")
    data['ml_score'] = np.random.rand(len(data))
    data['ml_score'] = data.groupby('date')['ml_score'].rank(pct=True)
    data['position'] = data['ml_score']

    return data


class FixedAdvancedMLScorer:
    """
    ä¿®å¤ç‰ˆMLè¯„åˆ†å™¨åŒ…è£…å™¨
    è‡ªåŠ¨å¤„ç†æœ€æ–°æ•°æ®é¢„æµ‹é—®é¢˜
    """

    def __init__(self, base_scorer):
        """
        Args:
            base_scorer: AdvancedMLScorerå®ä¾‹
        """
        self.base_scorer = base_scorer

    def predict_with_fix(self, factor_data, price_data, factor_columns):
        """
        å¸¦ä¿®å¤çš„é¢„æµ‹æµç¨‹
        """
        # å…ˆç”¨æ ‡å‡†æµç¨‹é¢„æµ‹ï¼ˆä¼šæ¼æ‰æœ€æ–°æ•°æ®ï¼‰
        try:
            factor_data = self.base_scorer.predict_scores(factor_data)
        except Exception as e:
            print(f"âš ï¸  æ ‡å‡†é¢„æµ‹å¤±è´¥: {e}")
        
        # ç„¶åä¿®å¤æœ€æ–°æ•°æ®
        factor_data = quick_fix_ml_scorer(
            self.base_scorer, factor_data, price_data, factor_columns
        )
        
        return factor_data


# ============ æµ‹è¯•å‡½æ•° ============
def test_fix():
    """æµ‹è¯•ä¿®å¤åŠŸèƒ½"""
    print("\n" + "="*80)
    print("ğŸ§ª æµ‹è¯•MLä¿®å¤åŠŸèƒ½")
    print("="*80)
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
    dates = pd.date_range('2025-01-01', '2025-12-19', freq='D')
    stocks = ['000001.SZ', '000002.SZ', '600000.SH']
    
    data = []
    for date in dates:
        for stock in stocks:
            data.append({
                'date': date.strftime('%Y-%m-%d'),
                'instrument': stock,
                'factor1': np.random.randn(),
                'factor2': np.random.randn(),
                'close': 10 + np.random.randn()
            })
    
    factor_data = pd.DataFrame(data)
    price_data = factor_data[['date', 'instrument', 'close']].copy()
    
    print(f"\n  ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®: {len(factor_data)} è¡Œ")
    print(f"  æ—¥æœŸèŒƒå›´: {factor_data['date'].min()} ~ {factor_data['date'].max()}")
    
    # æ¨¡æ‹Ÿè¯„åˆ†ç¼ºå¤±
    latest_date = factor_data['date'].max()
    factor_data['ml_score'] = np.random.rand(len(factor_data))
    factor_data.loc[factor_data['date'] == latest_date, 'ml_score'] = np.nan
    
    print(f"\n  æ¨¡æ‹Ÿæœ€æ–°æ—¥æœŸæ— è¯„åˆ†")
    
    # è¯Šæ–­
    diagnose_prediction_gap(factor_data, price_data, target_period=5)
    
    print("\n  âœ… æµ‹è¯•å®Œæˆ")


if __name__ == "__main__":
    test_fix()