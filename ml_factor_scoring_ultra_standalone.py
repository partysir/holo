
import pandas as pd
import numpy as np
import warnings
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import roc_auc_score

warnings.filterwarnings('ignore')

# æ£€æŸ¥æ¨¡å‹åº“
try:
    import xgboost as xgb
    XGBOOST_AVAILABLE = True
except ImportError:
    xgb = None
    XGBOOST_AVAILABLE = False

try:
    import lightgbm as lgb
    LIGHTGBM_AVAILABLE = True
except ImportError:
    lgb = None
    LIGHTGBM_AVAILABLE = False


# ============================================================================
# 1. æ•°æ®éš”ç¦»å™¨ (Purged Walk-Forward)
# ============================================================================
class PurgingEmbargoSplitter:
    """æ•°æ®éš”ç¦»åˆ‡åˆ†å™¨"""
    def __init__(self, train_months=12, valid_months=1, embargo_days=5):
        self.train_months = train_months
        self.valid_months = valid_months
        self.embargo_days = embargo_days

    def split(self, data, date_column='date'):
        data = data.copy()
        data[date_column] = pd.to_datetime(data[date_column])
        data = data.sort_values(date_column)

        data['year_month'] = data[date_column].dt.to_period('M')
        unique_months = sorted(data['year_month'].unique())

        splits = []

        for i in range(len(unique_months) - self.train_months - self.valid_months + 1):
            train_start = unique_months[i]
            train_end = unique_months[i + self.train_months - 1]
            valid_start = unique_months[i + self.train_months]
            valid_end = unique_months[i + self.train_months + self.valid_months - 1]

            train_idx = data[data['year_month'].between(train_start, train_end)].index
            valid_idx = data[data['year_month'].between(valid_start, valid_end)].index

            # Purging: å‰”é™¤è®­ç»ƒé›†å°¾éƒ¨
            if self.embargo_days > 0 and len(train_idx) > 0:
                train_dates = data.loc[train_idx, date_column]
                train_cutoff = train_dates.max() - pd.Timedelta(days=self.embargo_days)
                train_idx = train_idx[data.loc[train_idx, date_column] <= train_cutoff]

            if len(train_idx) > 100 and len(valid_idx) > 0:
                splits.append((train_idx, valid_idx))

        return splits


# ============================================================================
# 2. ç‰¹å¾æ­£äº¤åŒ–å™¨ (æˆªé¢ç‰ˆ)
# ============================================================================
class FeatureOrthogonalizer:
    """ç‰¹å¾æ­£äº¤åŒ– - æˆªé¢å›å½’ç‰ˆ"""
    def __init__(self, neutralize_market=True, neutralize_industry=True):
        self.neutralize_market = neutralize_market
        self.neutralize_industry = neutralize_industry

    def fit_transform(self, data, factor_columns):
        """é€æ—¥æˆªé¢å›å½’æ­£äº¤åŒ–"""
        if not self.neutralize_market and not self.neutralize_industry:
            return data

        print(f"  ğŸ”§ æ‰§è¡Œæ­£äº¤åŒ– (å¸‚åœº={self.neutralize_market}, è¡Œä¸š={self.neutralize_industry})...")
        data = data.copy()

        # 1. å‡†å¤‡å¸‚åœºå› å­ (å…¨å¸‚åœºå‡å€¼)
        price_col = self._detect_price_column(data)
        has_market_col = False

        if self.neutralize_market:
            if price_col:
                # ä¸´æ—¶è®¡ç®—æ”¶ç›Šç‡
                data['_ret'] = data.groupby('instrument')[price_col].pct_change()
                data['_mkt'] = data.groupby('date')['_ret'].transform('mean').fillna(0)
                has_market_col = True
            else:
                print("  âš ï¸  è­¦å‘Š: æœªæ‰¾åˆ°ä»·æ ¼åˆ—ï¼Œè·³è¿‡å¸‚åœºä¸­æ€§åŒ–")

        # 2. å‡†å¤‡è¡Œä¸šå› å­
        has_industry_col = False
        if self.neutralize_industry and 'industry' in data.columns:
            data['industry'] = data['industry'].fillna('Other')
            has_industry_col = True

        valid_factors = [f for f in factor_columns if f in data.columns]

        # 3. å‡†å¤‡GroupByéœ€è¦çš„åˆ—åˆ—è¡¨
        # å…³é”®ä¿®å¤ï¼šåªæœ‰å½“åˆ—çœŸæ­£å­˜åœ¨æ—¶ï¼Œæ‰åŠ å…¥åˆ° groupby åˆ—è¡¨
        group_cols = list(valid_factors)
        if has_market_col: group_cols.append('_mkt')
        if has_industry_col: group_cols.append('industry')

        # å®šä¹‰å•æ—¥å¤„ç†å‡½æ•°
        def neutralize_day(df_day):
            if len(df_day) < 10: return df_day[valid_factors]

            X_list = []
            if has_market_col:
                X_list.append(df_day[['_mkt']].values)

            if has_industry_col:
                # ä½¿ç”¨ numpy å¤„ç† dummy å˜é‡æ¯” pandas get_dummies å¿«ä¸”ç¨³
                # è¿™é‡Œä¸ºäº†ç®€å•ç¨³å¥ï¼Œè¿˜æ˜¯ç”¨ get_dummiesï¼Œä½†åœ¨ apply å†…éƒ¨è¦å°å¿ƒ
                ind = pd.get_dummies(df_day['industry'], drop_first=True).values
                if ind.shape[1] > 0:
                    X_list.append(ind)

            if not X_list: return df_day[valid_factors]

            try:
                X = np.hstack(X_list)
                y = df_day[valid_factors].values

                # çº¿æ€§å›å½’æ±‚æ®‹å·®: e = y - X*beta
                # rcond=None è§£å†³å¥‡å¼‚çŸ©é˜µè­¦å‘Š
                beta = np.linalg.lstsq(X, y, rcond=None)[0]
                res = y - X @ beta
                return pd.DataFrame(res, index=df_day.index, columns=valid_factors)
            except Exception:
                # å¦‚æœå›å½’å¤±è´¥ï¼ˆå¦‚æ•°æ®å…¨ä¸€æ ·ï¼‰ï¼Œè¿”å›åŸå€¼
                return df_day[valid_factors]

        # 4. æ‰§è¡Œ GroupBy Apply
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬åªå–éœ€è¦çš„åˆ—è¿›è¡Œ groupbyï¼Œæé«˜æ•ˆç‡å¹¶é˜²æ­¢ key error
        ortho = data.groupby('date')[group_cols].apply(neutralize_day)

        # å¤„ç†å¤šçº§ç´¢å¼•é—®é¢˜ (pandasç‰ˆæœ¬å·®å¼‚)
        if isinstance(ortho, pd.DataFrame):
            if 'date' in ortho.index.names:
                try:
                    ortho = ortho.reset_index(level='date', drop=True)
                except IndexError:
                    pass # æœ‰æ—¶ç´¢å¼•å·²ç»è¢«é‡ç½®

            # ä½¿ç”¨ update åŸåœ°æ›´æ–°
            data.update(ortho)

        # æ¸…ç†
        data = data.drop(columns=['_ret', '_mkt'], errors='ignore')
        return data

    def _detect_price_column(self, df):
        # ä¼˜å…ˆåŒ¹é…å®Œå…¨ä¸€è‡´çš„
        for col in ['close', 'Close', 'price', 'Price', 'CLOSE']:
            if col in df.columns: return col
        # æ¨¡ç³ŠåŒ¹é… (å¤„ç† close_x, close_y çš„æƒ…å†µï¼Œè¿”å›ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„å« close çš„æ•°å€¼åˆ—)
        for col in df.columns:
            if 'close' in col.lower() and pd.api.types.is_numeric_dtype(df[col]):
                return col
        return None


# ============================================================================
# 3. é›†æˆæŠ•ç¥¨å™¨
# ============================================================================
class EnsembleVotingScorer:
    """é›†æˆæŠ•ç¥¨å™¨"""
    def __init__(self, voting_strategy='strict'):
        self.voting_strategy = voting_strategy
        self.xgb_model = None
        self.lgb_model = None
        self.scaler = StandardScaler()

    def train(self, X_train, y_train, X_valid, y_valid):
        # å¡«å……NaNé˜²æ­¢æŠ¥é”™
        X_train = X_train.fillna(0)
        X_valid = X_valid.fillna(0)

        X_train_s = self.scaler.fit_transform(X_train)
        X_valid_s = self.scaler.transform(X_valid)

        if XGBOOST_AVAILABLE:
            self.xgb_model = xgb.XGBClassifier(
                n_estimators=200, max_depth=4, learning_rate=0.05,
                subsample=0.8, colsample_bytree=0.8, n_jobs=-1, random_state=42,
                eval_metric='logloss', verbosity=0, use_label_encoder=False
            )
            try:
                self.xgb_model.fit(X_train_s, y_train, eval_set=[(X_valid_s, y_valid)], verbose=False)
            except:
                self.xgb_model.fit(X_train_s, y_train)

        if LIGHTGBM_AVAILABLE:
            self.lgb_model = lgb.LGBMClassifier(
                n_estimators=200, max_depth=4, learning_rate=0.05, num_leaves=20,
                subsample=0.8, colsample_bytree=0.8, n_jobs=-1, random_state=42, verbose=-1
            )
            try:
                self.lgb_model.fit(X_train_s, y_train, eval_set=[(X_valid_s, y_valid)],
                                   callbacks=[lgb.early_stopping(20, verbose=False)])
            except:
                self.lgb_model.fit(X_train_s, y_train)
        return self

    def predict_proba(self, X):
        X = X.fillna(0)
        X_s = self.scaler.transform(X)
        preds = []
        if self.xgb_model: preds.append(self.xgb_model.predict_proba(X_s)[:, 1])
        if self.lgb_model: preds.append(self.lgb_model.predict_proba(X_s)[:, 1])

        if not preds: return np.zeros(len(X))

        p_avg = np.mean(preds, axis=0)

        if self.voting_strategy == 'strict' and len(preds) == 2:
            # åªæœ‰ä¸¤ä¸ªæ¨¡å‹éƒ½çœ‹å¥½(>0.5)æ‰ç»™é«˜åˆ†ï¼Œå¦åˆ™æƒ©ç½š
            consensus = (preds[0] > 0.5) & (preds[1] > 0.5)
            # åŠ å¤§åŒºåˆ†åº¦
            return np.where(consensus, p_avg * 1.2, p_avg * 0.8)

        return p_avg


# ============================================================================
# 4. UltraMLScorer (ä¸»ç±» - APIå…¼å®¹ç‰ˆ)
# ============================================================================
class UltraMLScorer:
    """è¶…çº§MLè¯„åˆ†å™¨ - APIå…¼å®¹ç‰ˆ"""

    def __init__(self,
                 target_period=5,
                 top_percentile=0.20,
                 embargo_days=5,
                 neutralize_market=True,
                 neutralize_industry=True,
                 voting_strategy='average',
                 train_months=12,
                 random_state=42):

        self.target_period = target_period
        self.top_percentile = top_percentile
        self.embargo_days = embargo_days
        self.train_months = train_months
        self.voting_strategy = voting_strategy

        # åˆå§‹åŒ–ç»„ä»¶
        self.orthogonalizer = FeatureOrthogonalizer(neutralize_market, neutralize_industry)
        self.ensemble = None
        self.feature_names = None
        self.scaler = StandardScaler()

        print(f"\nğŸš€ åˆå§‹åŒ–UltraMLScorer:")
        print(f"  Gap={embargo_days}d, MktNeut={neutralize_market}, IndNeut={neutralize_industry}, Vote={voting_strategy}")

    def prepare_data(self, factor_data, price_data, factor_columns):
        """å‡†å¤‡æ•°æ®ï¼šåˆå¹¶ + æ­£äº¤åŒ– + æ ‡ç­¾ç”Ÿæˆ"""
        print(f"\nğŸ“¦ å‡†å¤‡è®­ç»ƒæ•°æ®...")

        # 1. æ£€æµ‹ä»·æ ¼åˆ—
        price_col = self.orthogonalizer._detect_price_column(price_data)
        if not price_col:
            raise ValueError("æœªåœ¨ price_data ä¸­æ‰¾åˆ°ä»·æ ¼åˆ—")

        # 2. æ™ºèƒ½åˆå¹¶ (å…³é”®ä¿®å¤)
        # å¦‚æœ factor_data å’Œ price_data æ˜¯åŒä¸€ä¸ªå¯¹è±¡æˆ–åŒ…å«ç›¸åŒåˆ—ï¼Œå…ˆå¤„ç†
        merged = factor_data.copy()

        # å¦‚æœmergedé‡Œå·²ç»æœ‰ä»·æ ¼åˆ—ï¼Œå°±ä¸ç”¨mergeäº†ï¼Œæˆ–è€…ç¡®ä¿ä¸é‡å¤merge
        if price_col in merged.columns:
            print(f"  âœ“ ä»·æ ¼åˆ— '{price_col}' å·²å­˜åœ¨ï¼Œè·³è¿‡åˆå¹¶")
        else:
            # æ‰§è¡Œåˆå¹¶
            merged = merged.merge(price_data[['instrument', 'date', price_col]], on=['instrument', 'date'], how='left')

        merged = merged.sort_values(['instrument', 'date'])

        # 3. ç‰¹å¾æ­£äº¤åŒ– (åœ¨å…¨é‡æ•°æ®ä¸ŠæŒ‰æ—¥å¤„ç†)
        merged = self.orthogonalizer.fit_transform(merged, factor_columns)

        # 4. ç”ŸæˆTarget (è¶…é¢æ”¶ç›Š Top K)
        # å†æ¬¡ç¡®è®¤ä»·æ ¼åˆ—å­˜åœ¨ (é˜²æ­¢æ­£äº¤åŒ–è¿‡ç¨‹è¯¯åˆ )
        price_col = self.orthogonalizer._detect_price_column(merged)

        merged['fwd_ret'] = merged.groupby('instrument')[price_col].pct_change(self.target_period).shift(-self.target_period)
        merged['mkt_ret'] = merged.groupby('date')['fwd_ret'].transform('mean')
        merged['active_ret'] = merged['fwd_ret'] - merged['mkt_ret']

        merged['target'] = 0
        def get_label(x):
            if len(x) < 5: return pd.Series(0, index=x.index)
            # ä½¿ç”¨ float é˜²æ­¢ dtype é—®é¢˜
            thresh = float(x.quantile(1 - self.top_percentile))
            return (x >= thresh).astype(int)

        merged['target'] = merged.groupby('date')['active_ret'].transform(get_label)

        # è¿‡æ»¤æœ‰æ•ˆæ ·æœ¬
        valid_data = merged.dropna(subset=['target', 'active_ret'] + factor_columns)
        print(f"  âœ“ æœ‰æ•ˆæ ·æœ¬: {len(valid_data)}")

        self.feature_names = factor_columns

        # è¿”å› X, y, full_df
        return valid_data[factor_columns], valid_data['target'], valid_data

    def train(self, X, y, merged, verbose=False):
        """æ»šåŠ¨è®­ç»ƒ"""
        print(f"\nğŸ¯ æ»šåŠ¨è®­ç»ƒ (Train={self.train_months}m)...")

        splitter = PurgingEmbargoSplitter(self.train_months, embargo_days=self.embargo_days)
        splits = splitter.split(merged)

        if not splits:
            print("  âš ï¸ æ•°æ®ä¸è¶³ï¼Œæ— æ³•åˆ‡åˆ†")
            return

        # æ¨¡æ‹Ÿæ»šåŠ¨è®­ç»ƒï¼Œåªä¿ç•™æœ€åæ¨¡å‹
        for i, (tr_idx, val_idx) in enumerate(splits):
            X_tr, y_tr = X.iloc[tr_idx], y.iloc[tr_idx]
            X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]

            model = EnsembleVotingScorer(self.voting_strategy)
            model.train(X_tr, y_tr, X_val, y_val)

            self.ensemble = model

            if verbose:
                print(f"  Window {i+1}: Done")

        print("  âœ“ è®­ç»ƒå®Œæˆ")
        return self

    def predict(self, factor_data, price_data=None):
        """é¢„æµ‹"""
        if price_data is not None:
            # å›æµ‹æ¨¡å¼ï¼šé‡æ–°è·‘æ­£äº¤åŒ–
            # ä¸ºäº†é˜²æ­¢ merge å†²çªï¼Œè¿™é‡Œåšä¸€ä¸ªç®€åŒ–å¤„ç†ï¼š
            # å¦‚æœ factor_data å·²ç»åŒ…å«æ‰€æœ‰åˆ—ä¸”å·²ç»æ­£äº¤åŒ–è¿‡ï¼ˆé€šå¸¸åœ¨å›æµ‹è„šæœ¬é‡Œä¸å®¹æ˜“åˆ¤æ–­ï¼‰ï¼Œ
            # æœ€å®‰å…¨çš„æ–¹å¼æ˜¯é‡æ–°è°ƒç”¨ fit_transform
            factor_data = self.orthogonalizer.fit_transform(factor_data, self.feature_names)

        print(f"\nğŸ”® æ‰§è¡Œé¢„æµ‹...")
        X = factor_data[self.feature_names].fillna(0)

        if self.ensemble is None:
            raise ValueError("æ¨¡å‹æœªè®­ç»ƒ")

        preds = self.ensemble.predict_proba(X)

        result = factor_data.copy()
        result['ml_score'] = preds
        return result

# å¯¼å‡º
__all__ = ['UltraMLScorer']