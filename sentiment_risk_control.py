# -*- coding: utf-8 -*-
"""
sentiment_risk_control.py - èˆ†æƒ…é£æ§/å¢å¼ºæ¨¡å— (v1.0)

ğŸ¯ æ ¸å¿ƒåŠŸèƒ½ï¼š
1. âš ï¸  ä¸€ç¥¨å¦å†³ï¼šæ£€æµ‹ä¸¥é‡è´Ÿé¢èˆ†æƒ…ï¼ˆç«‹æ¡ˆè°ƒæŸ¥ã€è¿è§„å¤„ç½šç­‰ï¼‰
2. ğŸ“ˆ åŠ åˆ†ææƒï¼šæ•æ‰æ­£é¢é¢˜æï¼ˆæ”¿ç­–æ”¯æŒã€è¡Œä¸šçƒ­ç‚¹ç­‰ï¼‰
3. ğŸ” æ™ºèƒ½è¿‡æ»¤ï¼šåŒºåˆ†å™ªéŸ³ä¸çœŸå®ä¿¡å·

æ•°æ®æºï¼š
- Tushare news (è´¢ç»æ–°é—»)
- Tushare cctv_news (æ–°é—»è”æ’­ - æ”¿ç­–é£å‘æ ‡)
- Tushare fina_audit (è´¢åŠ¡å®¡è®¡)
- Tushare disclosure (å…¬å‘Šé¢„è­¦)

ä½¿ç”¨æ–¹å¼ï¼š
```python
from sentiment_risk_control import SentimentRiskController

# åˆå§‹åŒ–
controller = SentimentRiskController(tushare_token=YOUR_TOKEN)

# å¯¹é€‰è‚¡ç»“æœè¿›è¡Œé£æ§å¢å¼º
filtered_stocks = controller.apply_sentiment_filter(
    selected_stocks=top_stocks_df,
    factor_data=factor_data,
    price_data=price_data
)
```

ç‰ˆæœ¬ï¼šv1.0
æ—¥æœŸï¼š2025-12-17
ä½œè€…ï¼šClaude
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import time
import re
from typing import List, Dict, Tuple, Optional
import warnings

warnings.filterwarnings('ignore')

try:
    import tushare as ts

    TUSHARE_AVAILABLE = True
except ImportError:
    TUSHARE_AVAILABLE = False
    print("âš ï¸  Tushareæœªå®‰è£…: pip install tushare")


# ============================================================================
# ç¬¬ä¸€éƒ¨åˆ†ï¼šèˆ†æƒ…æ•°æ®é‡‡é›†å™¨
# ============================================================================

class SentimentDataCollector:
    """èˆ†æƒ…æ•°æ®é‡‡é›†å™¨"""

    def __init__(self, token: Optional[str] = None, cache_manager=None):
        """åˆå§‹åŒ–é‡‡é›†å™¨"""
        if not TUSHARE_AVAILABLE:
            raise ImportError("è¯·å…ˆå®‰è£…Tushare: pip install tushare")

        if token:
            ts.set_token(token)  # type: ignore

        try:
            self.pro = ts.pro_api()  # type: ignore
            print("âœ“ Tushare APIåˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âœ— Tushareåˆå§‹åŒ–å¤±è´¥: {e}")
            self.pro = None

        self.cache = cache_manager
        self.request_count = 0
        self.last_request_time = time.time()

    def _rate_limit(self, wait_time: float = 0.5):
        """è®¿é—®é¢‘ç‡æ§åˆ¶"""
        current_time = time.time()
        elapsed = current_time - self.last_request_time

        if elapsed < wait_time:
            time.sleep(wait_time - elapsed)

        self.last_request_time = time.time()
        self.request_count += 1

        # æ¯100æ¬¡è¯·æ±‚æš‚åœ5ç§’
        if self.request_count % 100 == 0:
            print(f"  â³ APIè°ƒç”¨{self.request_count}æ¬¡ï¼Œæš‚åœ5ç§’...")
            time.sleep(5)

    def get_news(self, start_date: str, end_date: str, src: Optional[str] = None) -> pd.DataFrame:
        """
        è·å–è´¢ç»æ–°é—»

        Args:
            start_date: å¼€å§‹æ—¥æœŸ 'YYYY-MM-DD'
            end_date: ç»“æŸæ—¥æœŸ 'YYYY-MM-DD'
            src: æ–°é—»æ¥æº (sina/ths/wallstreetç­‰)

        Returns:
            DataFrame: æ–°é—»æ•°æ®
        """
        if self.pro is None:
            return pd.DataFrame()

        try:
            self._rate_limit()

            df = self.pro.news(
                start_date=start_date.replace('-', ''),
                end_date=end_date.replace('-', ''),
                src=src
            )

            if df is not None and len(df) > 0:
                df['date'] = pd.to_datetime(df['datetime'], errors='coerce').dt.date
                df['date'] = df['date'].astype(str)
                print(f"  âœ“ è·å–è´¢ç»æ–°é—»: {len(df)} æ¡")
                return df if isinstance(df, pd.DataFrame) else pd.DataFrame()

            return pd.DataFrame()

        except Exception as e:
            print(f"  âš ï¸  è·å–æ–°é—»å¤±è´¥: {e}")
            return pd.DataFrame()

    def get_cctv_news(self, start_date: str, end_date: str) -> pd.DataFrame:
        """
        è·å–æ–°é—»è”æ’­å†…å®¹ (æ”¿ç­–é£å‘æ ‡)

        Args:
            start_date: å¼€å§‹æ—¥æœŸ 'YYYY-MM-DD'
            end_date: ç»“æŸæ—¥æœŸ 'YYYY-MM-DD'

        Returns:
            DataFrame: æ–°é—»è”æ’­æ•°æ®
        """
        if self.pro is None:
            return pd.DataFrame()

        try:
            self._rate_limit()

            df = self.pro.cctv_news(
                start_date=start_date.replace('-', ''),
                end_date=end_date.replace('-', '')
            )

            if df is not None and len(df) > 0:
                print(f"  âœ“ è·å–æ–°é—»è”æ’­: {len(df)} æ¡")
                return df

            return pd.DataFrame()

        except Exception as e:
            print(f"  âš ï¸  è·å–æ–°é—»è”æ’­å¤±è´¥: {e}")
            return pd.DataFrame()

    def get_financial_audit(self, ts_codes: List[str], start_date: str, end_date: str) -> pd.DataFrame:
        """
        è·å–è´¢åŠ¡å®¡è®¡/ç«‹æ¡ˆè°ƒæŸ¥ä¿¡æ¯ (æ‰¹é‡æŸ¥è¯¢ä¼˜åŒ–ç‰ˆ)

        Args:
            ts_codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            start_date: å¼€å§‹æ—¥æœŸ 'YYYY-MM-DD'
            end_date: ç»“æŸæ—¥æœŸ 'YYYY-MM-DD'

        Returns:
            DataFrame: å®¡è®¡æ•°æ®
        """
        if self.pro is None:
            return pd.DataFrame()

        try:
            self._rate_limit(wait_time=1.0)  # è¿™ä¸ªæ¥å£é™åˆ¶æ›´ä¸¥æ ¼

            # æ‰¹é‡æŸ¥è¯¢æ•´ä¸ªå¸‚åœºçš„å®¡è®¡ä¿¡æ¯
            df = self.pro.fina_audit(
                start_date=start_date.replace('-', ''),
                end_date=end_date.replace('-', '')
            )

            if df is not None and len(df) > 0:
                # åªä¿ç•™æŒ‡å®šè‚¡ç¥¨çš„å®¡è®¡ä¿¡æ¯
                df = df[df['ts_code'].isin(ts_codes)]
                
                if len(df) > 0:
                    df['ann_date'] = pd.to_datetime(df['ann_date'], format='%Y%m%d', errors='coerce')
                    df['date'] = df['ann_date'].dt.strftime('%Y-%m-%d')  # type: ignore
                    print(f"  âœ“ è·å–è´¢åŠ¡å®¡è®¡: {len(df)} æ¡ (æ‰¹é‡æŸ¥è¯¢)")
                    return df if isinstance(df, pd.DataFrame) else pd.DataFrame()
                else:
                    print(f"  â„¹ï¸  æŒ‡å®šæœŸé—´å†…æ— ç›¸å…³è‚¡ç¥¨çš„è´¢åŠ¡å®¡è®¡ä¿¡æ¯")
                    return pd.DataFrame()
            else:
                print(f"  â„¹ï¸  æŒ‡å®šæœŸé—´å†…æ— è´¢åŠ¡å®¡è®¡ä¿¡æ¯")
                return pd.DataFrame()

        except Exception as e:
            if "å¿…å¡«å‚æ•°" in str(e):
                # å¦‚æœæ˜¯å¿…å¡«å‚æ•°é”™è¯¯ï¼Œå°è¯•æŒ‰è‚¡ç¥¨é€ä¸ªæŸ¥è¯¢
                print(f"  âš ï¸  æ‰¹é‡æŸ¥è¯¢è´¢åŠ¡å®¡è®¡å¤±è´¥ï¼Œå°è¯•é€ä¸ªæŸ¥è¯¢...")
                all_data = []
                
                for ts_code in ts_codes[:10]:  # é™åˆ¶æŸ¥è¯¢æ•°é‡é¿å…è¶…é™
                    try:
                        self._rate_limit(wait_time=1.0)
                        stock_df = self.pro.fina_audit(
                            ts_code=ts_code,
                            start_date=start_date.replace('-', ''),
                            end_date=end_date.replace('-', '')
                        )
                        
                        if stock_df is not None and len(stock_df) > 0:
                            all_data.append(stock_df)
                            
                    except Exception:
                        continue  # é™é»˜å¤±è´¥
                
                if all_data:
                    result = pd.concat(all_data, ignore_index=True)
                    result['ann_date'] = pd.to_datetime(result['ann_date'], format='%Y%m%d', errors='coerce')
                    result['date'] = result['ann_date'].dt.strftime('%Y-%m-%d')  # type: ignore
                    result = result[result['ts_code'].isin(ts_codes)]  # å†æ¬¡è¿‡æ»¤
                    print(f"  âœ“ é€ä¸ªæŸ¥è¯¢è·å–è´¢åŠ¡å®¡è®¡: {len(result)} æ¡")
                    return result if isinstance(result, pd.DataFrame) else pd.DataFrame()
                else:
                    print(f"  â„¹ï¸  é€ä¸ªæŸ¥è¯¢ä¹Ÿæœªè·å–åˆ°è´¢åŠ¡å®¡è®¡ä¿¡æ¯")
                    return pd.DataFrame()
            else:
                print(f"  âš ï¸  è·å–è´¢åŠ¡å®¡è®¡å¤±è´¥: {e}")
                return pd.DataFrame()

    def get_disclosure_info(self, ts_codes: List[str], start_date: str, end_date: str) -> pd.DataFrame:
        """
        è·å–å…¬å‘Šé¢„è­¦ä¿¡æ¯ (ç«‹æ¡ˆè°ƒæŸ¥ã€è¿è§„å¤„ç½šç­‰) (æ‰¹é‡æŸ¥è¯¢ä¼˜åŒ–ç‰ˆ)

        Args:
            ts_codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            start_date: å¼€å§‹æ—¥æœŸ 'YYYY-MM-DD'
            end_date: ç»“æŸæ—¥æœŸ 'YYYY-MM-DD'

        Returns:
            DataFrame: å…¬å‘Šæ•°æ®
        """
        if self.pro is None:
            return pd.DataFrame()

        try:
            self._rate_limit(wait_time=1.0)

            # æ‰¹é‡æŸ¥è¯¢æ•´ä¸ªå¸‚åœºçš„å…¬å‘Šä¿¡æ¯
            df = self.pro.disclosure_date(
                start_date=start_date.replace('-', ''),
                end_date=end_date.replace('-', '')
            )

            if df is not None and len(df) > 0:
                # åªä¿ç•™æŒ‡å®šè‚¡ç¥¨çš„å…¬å‘Šä¿¡æ¯
                df = df[df['ts_code'].isin(ts_codes)]
                
                if len(df) > 0:
                    if 'actual_date' in df.columns:
                        df['actual_date'] = pd.to_datetime(df['actual_date'], format='%Y%m%d', errors='coerce')
                        df['date'] = df['actual_date'].dt.strftime('%Y-%m-%d')  # type: ignore
                    print(f"  âœ“ è·å–å…¬å‘Šä¿¡æ¯: {len(df)} æ¡ (æ‰¹é‡æŸ¥è¯¢)")
                    return df if isinstance(df, pd.DataFrame) else pd.DataFrame()

            return pd.DataFrame()

        except Exception as e:
            print(f"  âš ï¸  è·å–å…¬å‘Šä¿¡æ¯å¤±è´¥: {e}")
            return pd.DataFrame()

    def get_news_batch(self, start_date: str, end_date: str, src: Optional[str] = None) -> pd.DataFrame:
        """
        æ‰¹é‡è·å–è´¢ç»æ–°é—» (æŒ‰æ—¶é—´æ®µæ‰¹é‡æŸ¥è¯¢)

        Args:
            start_date: å¼€å§‹æ—¥æœŸ 'YYYY-MM-DD'
            end_date: ç»“æŸæ—¥æœŸ 'YYYY-MM-DD'
            src: æ–°é—»æ¥æº (sina/ths/wallstreetç­‰)

        Returns:
            DataFrame: æ–°é—»æ•°æ®
        """
        if self.pro is None:
            return pd.DataFrame()

        try:
            # ä¼˜å…ˆè·å–æœ€è¿‘å‡ å¤©çš„æ–°é—»ï¼Œå› ä¸ºè¶Šè¿‘è¶Šé‡è¦
            all_news = []
            current_date = pd.to_datetime(end_date)  # ä»ç»“æŸæ—¥æœŸå¼€å§‹
            start_dt = pd.to_datetime(start_date)
            
            # é™åˆ¶æŸ¥è¯¢å¤©æ•°ï¼Œé¿å…è¶…å‡ºAPIé™åˆ¶
            days_processed = 0
            max_days = 3  # æœ€å¤šæŸ¥è¯¢3å¤©çš„æ–°é—»æ•°æ®ï¼Œä¼˜å…ˆæœ€è¿‘çš„
            
            while current_date >= start_dt and days_processed < max_days:
                date_str = current_date.strftime('%Y-%m-%d')
                date_str_no_dash = current_date.strftime('%Y%m%d')
                
                try:
                    self._rate_limit(2.0)  # å¢åŠ ç­‰å¾…æ—¶é—´
                    
                    df = self.pro.news(
                        start_date=date_str_no_dash,
                        end_date=date_str_no_dash,
                        src=src
                    )
                    
                    if df is not None and len(df) > 0:
                        df['date'] = date_str
                        all_news.append(df)
                        print(f"    âœ“ è·å–{date_str}æ–°é—»: {len(df)}æ¡")
                    else:
                        print(f"    â„¹ï¸  {date_str}æ— æ–°é—»æ•°æ®")
                        
                except Exception as e:
                    if "æœ€å¤šè®¿é—®è¯¥æ¥å£" in str(e):
                        print(f"    âš ï¸  {date_str}æ–°é—»è·å–å—é™: {str(e).split('ã€‚')[0]}")
                        # é‡åˆ°é™åˆ¶æ—¶æš‚åœæ›´é•¿æ—¶é—´
                        time.sleep(5)
                        break  # é‡åˆ°é™åˆ¶ç«‹å³åœæ­¢
                    else:
                        print(f"    âš ï¸  è·å–{date_str}æ–°é—»å¤±è´¥: {e}")
                
                current_date -= timedelta(days=1)  # å‘å‰æ¨ä¸€å¤©
                days_processed += 1
            
            if all_news:
                result = pd.concat(all_news, ignore_index=True)
                if 'datetime' in result.columns:
                    result['datetime'] = pd.to_datetime(result['datetime'], errors='coerce')
                print(f"  âœ“ æ‰¹é‡è·å–è´¢ç»æ–°é—»: {len(result)} æ¡ (ä¼˜å…ˆæœ€è¿‘{max_days}å¤©)")
                return result if isinstance(result, pd.DataFrame) else pd.DataFrame()
            else:
                print(f"  â„¹ï¸  æœªè·å–åˆ°æ–°é—»æ•°æ® (ä¼˜å…ˆæœ€è¿‘{max_days}å¤©)")
                return pd.DataFrame()

        except Exception as e:
            print(f"  âš ï¸  æ‰¹é‡è·å–æ–°é—»å¤±è´¥: {e}")
            return pd.DataFrame()


# ============================================================================
# ç¬¬äºŒéƒ¨åˆ†ï¼šèˆ†æƒ…è§„åˆ™å¼•æ“
# ============================================================================

class SentimentRuleEngine:
    """èˆ†æƒ…è§„åˆ™å¼•æ“ - å®šä¹‰ä¸€ç¥¨å¦å†³å’ŒåŠ åˆ†è§„åˆ™"""

    # ä¸€ç¥¨å¦å†³å…³é”®è¯ (ä¸¥é‡è´Ÿé¢)
    VETO_KEYWORDS = {
        'critical': [
            'ç«‹æ¡ˆè°ƒæŸ¥', 'è¯ç›‘ä¼šè°ƒæŸ¥', 'æ¶‰å«Œè¿è§„', 'æ¬ºè¯ˆå‘è¡Œ',
            'è´¢åŠ¡é€ å‡', 'å†…å¹•äº¤æ˜“', 'ST', '*ST', 'é€€å¸‚é£é™©',
            'é‡å¤§è¿æ³•', 'æš‚åœä¸Šå¸‚', 'ç»ˆæ­¢ä¸Šå¸‚', 'ç ´äº§é‡æ•´'
        ],
        'high_risk': [
            'ä¸šç»©çˆ†é›·', 'ä¸šç»©å¤§å¹…ä¸‹æ»‘', 'å•†èª‰å‡å€¼', 'å€ºåŠ¡è¿çº¦',
            'æ§è‚¡è‚¡ä¸œè´¨æŠ¼', 'èµ„é‡‘é“¾æ–­è£‚', 'é«˜ç®¡è¾èŒ', 'è‘£äº‹é•¿è¾èŒ'
        ]
    }

    # åŠ åˆ†å…³é”®è¯ (æ­£é¢é¢˜æ)
    BOOST_KEYWORDS = {
        'policy_support': {
            'keywords': [
                'æ–°è´¨ç”Ÿäº§åŠ›', 'ä½ç©ºç»æµ', 'äººå·¥æ™ºèƒ½', 'æ•°å­—ç»æµ',
                'å›½ä¼æ”¹é©', 'ä¸€å¸¦ä¸€è·¯', 'ç¢³ä¸­å’Œ', 'æ–°èƒ½æº',
                'åŠå¯¼ä½“', 'è‡ªä¸»å¯æ§', 'å›½äº§æ›¿ä»£', 'ç§‘æŠ€åˆ›æ–°'
            ],
            'boost_score': 0.10  # åŠ 10%è¯„åˆ†
        },
        'hot_concept': {
            'keywords': [
                'ä¸šç»©é¢„å¢', 'ä¸­æŠ¥é¢„å–œ', 'é‡å¤§è®¢å•', 'æˆ˜ç•¥åˆä½œ',
                'è‚¡æƒæ¿€åŠ±', 'å›è´­å¢æŒ', 'å¹¶è´­é‡ç»„', 'èµ„äº§æ³¨å…¥'
            ],
            'boost_score': 0.05  # åŠ 5%è¯„åˆ†
        },
        'cctv_mention': {
            'keywords': [
                # è¿™ä¸ªä¼šåœ¨CCTVæ–°é—»ä¸­åŒ¹é…è¡Œä¸šå…³é”®è¯
                'åˆ¶é€ ä¸š', 'ç§‘æŠ€', 'åˆ›æ–°', 'äº§ä¸šå‡çº§', 'é«˜è´¨é‡å‘å±•'
            ],
            'boost_score': 0.08  # æ–°é—»è”æ’­æåŠåŠ 8%
        }
    }

    def __init__(self):
        """åˆå§‹åŒ–è§„åˆ™å¼•æ“"""
        print("\nğŸ¯ èˆ†æƒ…è§„åˆ™å¼•æ“åˆå§‹åŒ–")
        print(f"  - ä¸€ç¥¨å¦å†³å…³é”®è¯: {len(self.VETO_KEYWORDS['critical']) + len(self.VETO_KEYWORDS['high_risk'])} ä¸ª")
        print(f"  - åŠ åˆ†å…³é”®è¯ç»„: {len(self.BOOST_KEYWORDS)} ç»„")

    def check_veto_triggers(self, text: str) -> Tuple[bool, str]:
        """
        æ£€æŸ¥æ˜¯å¦è§¦å‘ä¸€ç¥¨å¦å†³

        Returns:
            (is_veto, reason)
        """
        if pd.isna(text) or not isinstance(text, str):
            return False, ""

        text = text.lower()

        # Criticalçº§åˆ«ï¼šç›´æ¥å¦å†³
        for keyword in self.VETO_KEYWORDS['critical']:
            if keyword.lower() in text:
                return True, f"Criticalé£é™©: {keyword}"

        # High Riskçº§åˆ«ï¼šè®¡æ•°è§¦å‘
        high_risk_count = sum(1 for kw in self.VETO_KEYWORDS['high_risk']
                              if kw.lower() in text)
        if high_risk_count >= 2:  # åŒæ—¶å‡ºç°2ä¸ªä»¥ä¸Šé«˜é£é™©è¯
            return True, f"é«˜é£é™©é¢„è­¦ ({high_risk_count}ä¸ªè´Ÿé¢è¯)"

        return False, ""

    def calculate_boost_score(self, text: str, source: str = 'news') -> Tuple[float, List[str]]:
        """
        è®¡ç®—åŠ åˆ†å€¼

        Returns:
            (boost_score, matched_keywords)
        """
        if pd.isna(text) or not isinstance(text, str):
            return 0.0, []

        text = text.lower()
        total_boost = 0.0
        matched = []

        for category, config in self.BOOST_KEYWORDS.items():
            # CCTVæ–°é—»ç‰¹æ®Šå¤„ç†
            if category == 'cctv_mention' and source != 'cctv':
                continue

            for keyword in config['keywords']:
                if keyword.lower() in text:
                    total_boost += config['boost_score']
                    matched.append(f"{keyword}(+{config['boost_score']:.1%})")
                    break  # æ¯ä¸ªç±»åˆ«åªåŠ åˆ†ä¸€æ¬¡

        return min(total_boost, 0.20), matched  # æœ€å¤šåŠ 20%


# ============================================================================
# ç¬¬ä¸‰éƒ¨åˆ†ï¼šèˆ†æƒ…åˆ†æå™¨
# ============================================================================

class SentimentAnalyzer:
    """èˆ†æƒ…åˆ†æå™¨ - æ•´åˆæ•°æ®é‡‡é›†å’Œè§„åˆ™åˆ¤æ–­"""

    def __init__(self, collector: SentimentDataCollector, rule_engine: SentimentRuleEngine):
        """åˆå§‹åŒ–åˆ†æå™¨"""
        self.collector = collector
        self.rules = rule_engine

    def analyze_stock_sentiment(self, ts_code: str, start_date: str, end_date: str,
                              cached_data: Optional[Dict[str, pd.DataFrame]] = None) -> Dict:
        """
        åˆ†æå•åªè‚¡ç¥¨çš„èˆ†æƒ… (ä½¿ç”¨ç¼“å­˜æ•°æ®)

        Args:
            ts_code: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            cached_data: ç¼“å­˜çš„æ•°æ®å­—å…¸ï¼ŒåŒ…å«audit_df, disclosure_df, news_df

        Returns:
            {
                'ts_code': str,
                'is_veto': bool,
                'veto_reason': str,
                'boost_score': float,
                'boost_reasons': List[str],
                'news_count': int,
                'audit_issues': int
            }
        """
        result = {
            'ts_code': ts_code,
            'is_veto': False,
            'veto_reason': '',
            'boost_score': 0.0,
            'boost_reasons': [],
            'news_count': 0,
            'audit_issues': 0
        }

        # ä½¿ç”¨ç¼“å­˜æ•°æ®è¿›è¡Œåˆ†æ
        if cached_data:
            audit_df = cached_data.get('audit_df', pd.DataFrame())
            disclosure_df = cached_data.get('disclosure_df', pd.DataFrame())
            news_df = cached_data.get('news_df', pd.DataFrame())
        else:
            # å¦‚æœæ²¡æœ‰ç¼“å­˜æ•°æ®ï¼Œåˆ™å•ç‹¬æŸ¥è¯¢
            audit_df = self.collector.get_financial_audit([ts_code], start_date, end_date)
            disclosure_df = self.collector.get_disclosure_info([ts_code], start_date, end_date)
            news_df = self.collector.get_news_batch(start_date, end_date)

        # 1. æ£€æŸ¥è´¢åŠ¡å®¡è®¡ (æœ€é«˜ä¼˜å…ˆçº§)
        if not audit_df.empty:
            stock_audit = audit_df[audit_df['ts_code'] == ts_code]
            result['audit_issues'] = len(stock_audit)
            # å¦‚æœæœ‰å®¡è®¡é—®é¢˜ï¼Œé»˜è®¤ä¸€ç¥¨å¦å†³
            if len(stock_audit) > 0:
                result['is_veto'] = True
                result['veto_reason'] = f"è´¢åŠ¡å®¡è®¡å¼‚å¸¸ ({len(stock_audit)}æ¡)"
                return result

        # 2. æ£€æŸ¥å…¬å‘Šä¿¡æ¯
        if not disclosure_df.empty:
            stock_disclosure = disclosure_df[disclosure_df['ts_code'] == ts_code]
            # æ£€æŸ¥æ˜¯å¦æœ‰å…³é”®è´Ÿé¢è¯
            critical_keywords_found = []
            high_risk_keywords_found = []
            
            for _, row in stock_disclosure.iterrows():
                title = str(row.get('title', ''))
                if pd.isna(title):
                    continue
                    
                # æ£€æŸ¥Criticalçº§åˆ«å…³é”®è¯
                for keyword in self.rules.VETO_KEYWORDS['critical']:
                    if keyword.lower() in title.lower():
                        critical_keywords_found.append(keyword)
                
                # æ£€æŸ¥High Riskçº§åˆ«å…³é”®è¯
                for keyword in self.rules.VETO_KEYWORDS['high_risk']:
                    if keyword.lower() in title.lower():
                        high_risk_keywords_found.append(keyword)
            
            # Criticalçº§åˆ«ï¼šç›´æ¥å¦å†³
            if critical_keywords_found:
                result['is_veto'] = True
                result['veto_reason'] = f"ä¸¥é‡é£é™©: {critical_keywords_found[0]}"
                return result
            
            # High Riskçº§åˆ«ï¼šå¤šä¸ªå…³é”®è¯è§¦å‘å¦å†³
            if len(high_risk_keywords_found) >= 2:
                result['is_veto'] = True
                result['veto_reason'] = f"é«˜é£é™©é¢„è­¦ ({len(high_risk_keywords_found)}ä¸ªè´Ÿé¢è¯)"
                return result

        # 3. åˆ†ææ–°é—»
        if not news_df.empty:
            # ç­›é€‰è¯¥è‚¡ç¥¨çš„æ–°é—»
            if 'ts_code' in news_df.columns:
                stock_news = news_df[news_df['ts_code'] == ts_code]
            else:
                # å¦‚æœæ²¡æœ‰ts_codeåˆ—ï¼Œå‡è®¾æ‰€æœ‰æ–°é—»éƒ½æ˜¯ç›¸å…³çš„
                stock_news = news_df
                
            result['news_count'] = len(stock_news)
            
            # è®¡ç®—åŠ åˆ†
            boost_scores = []
            for _, row in stock_news.iterrows():
                title = str(row.get('title', ''))
                content = str(row.get('content', ''))
                full_text = f"{title} {content}"
                
                if pd.isna(title) and pd.isna(content):
                    continue
                
                boost_score, matched_keywords = self.rules.calculate_boost_score(full_text, source='news')
                if boost_score > 0:
                    boost_scores.append((boost_score, matched_keywords))
            
            # ç´¯åŠ åŠ åˆ†é¡¹ï¼ˆè®¾ç½®ä¸Šé™ï¼‰
            total_boost = 0.0
            all_matched = []
            for boost_score, matched_keywords in boost_scores:
                total_boost += boost_score
                all_matched.extend(matched_keywords)
            
            # è®¾ç½®æœ€å¤§åŠ åˆ†é™åˆ¶
            result['boost_score'] = min(total_boost, 0.20)  # æœ€å¤šåŠ 20%
            result['boost_reasons'] = all_matched[:10]  # æœ€å¤šè®°å½•10ä¸ªåŒ¹é…è¯

        return result

    def batch_analyze_sentiment(self, ts_codes: List[str], start_date: str, end_date: str) -> Dict[str, Dict]:
        """
        æ‰¹é‡åˆ†æå¤šåªè‚¡ç¥¨çš„èˆ†æƒ…

        Args:
            ts_codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ

        Returns:
            Dict[ts_code, sentiment_analysis_result]
        """
        print(f"  ğŸ“Š æ‰¹é‡åˆ†æ {len(ts_codes)} åªè‚¡ç¥¨èˆ†æƒ…...")
        
        # 1. æ‰¹é‡è·å–æ‰€æœ‰æ•°æ®
        print("    [1/3] æ‰¹é‡è·å–è´¢åŠ¡å®¡è®¡æ•°æ®...")
        audit_df = self.collector.get_financial_audit(ts_codes, start_date, end_date)
        
        print("    [2/3] æ‰¹é‡è·å–å…¬å‘Šä¿¡æ¯...")
        disclosure_df = self.collector.get_disclosure_info(ts_codes, start_date, end_date)
        
        print("    [3/3] æ‰¹é‡è·å–æ–°é—»æ•°æ®...")
        news_df = self.collector.get_news_batch(start_date, end_date)
        
        # 2. æ„å»ºç¼“å­˜æ•°æ®å­—å…¸
        cached_data = {
            'audit_df': audit_df,
            'disclosure_df': disclosure_df,
            'news_df': news_df
        }
        
        # 3. é€ä¸ªåˆ†ææ¯åªè‚¡ç¥¨
        results = {}
        for i, ts_code in enumerate(ts_codes):
            if (i + 1) % 50 == 0:
                print(f"      è¿›åº¦: {i + 1}/{len(ts_codes)}")
            
            results[ts_code] = self.analyze_stock_sentiment(ts_code, start_date, end_date, cached_data)
        
        # 4. ç»Ÿè®¡åˆ†æç»“æœ
        veto_count = sum(1 for r in results.values() if r['is_veto'])
        boost_count = sum(1 for r in results.values() if r['boost_score'] > 0)
        
        if veto_count > 0:
            print(f"    ğŸš« å‘ç° {veto_count} åªé£é™©è‚¡ç¥¨")
        if boost_count > 0:
            print(f"    ğŸ“ˆ å‘ç° {boost_count} åªåŠ åˆ†è‚¡ç¥¨")
        
        return results

    def analyze_market_sentiment(self, start_date: str, end_date: str) -> Dict:
        """
        åˆ†æå¸‚åœºæ•´ä½“èˆ†æƒ… (æ–°é—»è”æ’­ã€çƒ­ç‚¹é¢˜æ)

        Returns:
            {
                'hot_themes': List[str],
                'policy_support_keywords': List[str],
                'market_mood': str  # 'positive', 'neutral', 'negative'
            }
        """
        result = {
            'hot_themes': [],
            'policy_support_keywords': [],
            'market_mood': 'neutral'
        }

        # è·å–æ–°é—»è”æ’­
        cctv_df = self.collector.get_cctv_news(start_date, end_date)

        if not cctv_df.empty:
            all_text = ' '.join(cctv_df['title'].dropna().tolist())

            # æå–æ”¿ç­–æ”¯æŒå…³é”®è¯
            for keyword in self.rules.BOOST_KEYWORDS['policy_support']['keywords']:
                if keyword.lower() in all_text.lower():
                    result['policy_support_keywords'].append(keyword)

            # ç®€å•æƒ…ç»ªåˆ¤æ–­
            positive_count = sum(1 for kw in result['policy_support_keywords'])
            if positive_count >= 3:
                result['market_mood'] = 'positive'

        return result


# ============================================================================
# ç¬¬å››éƒ¨åˆ†ï¼šä¸»æ§åˆ¶å™¨
# ============================================================================

class SentimentRiskController:
    """èˆ†æƒ…é£æ§/å¢å¼ºä¸»æ§åˆ¶å™¨"""

    def __init__(self, tushare_token: Optional[str] = None, cache_manager=None,
                 lookback_days: int = 30):
        """
        åˆå§‹åŒ–æ§åˆ¶å™¨

        Args:
            tushare_token: Tushare Token
            cache_manager: ç¼“å­˜ç®¡ç†å™¨
            lookback_days: èˆ†æƒ…å›æº¯å¤©æ•° (é»˜è®¤30å¤©)
        """
        print("\n" + "=" * 80)
        print("ğŸ›¡ï¸  èˆ†æƒ…é£æ§/å¢å¼ºæ¨¡å—åˆå§‹åŒ–")
        print("=" * 80)

        self.lookback_days = lookback_days

        # åˆå§‹åŒ–ç»„ä»¶
        self.collector = SentimentDataCollector(token=tushare_token, cache_manager=cache_manager)
        self.rules = SentimentRuleEngine()
        self.analyzer = SentimentAnalyzer(self.collector, self.rules)

        print(f"\nâœ“ åˆå§‹åŒ–å®Œæˆ (å›æº¯æœŸ: {lookback_days}å¤©)")

    def apply_sentiment_filter(self, selected_stocks: pd.DataFrame,
                               factor_data: pd.DataFrame,
                               price_data: pd.DataFrame,
                               enable_veto: bool = True,
                               enable_boost: bool = True) -> pd.DataFrame:
        """
        å¯¹é€‰è‚¡ç»“æœåº”ç”¨èˆ†æƒ…è¿‡æ»¤å’Œå¢å¼º

        Args:
            selected_stocks: é€‰è‚¡ç»“æœ (å¿…é¡»åŒ…å« 'instrument' åˆ—)
            factor_data: å› å­æ•°æ® (ç”¨äºè·å–æ—¥æœŸ)
            price_data: ä»·æ ¼æ•°æ®
            enable_veto: æ˜¯å¦å¯ç”¨ä¸€ç¥¨å¦å†³
            enable_boost: æ˜¯å¦å¯ç”¨åŠ åˆ†å¢å¼º

        Returns:
            DataFrame: è¿‡æ»¤åçš„è‚¡ç¥¨åˆ—è¡¨
        """
        print("\n" + "=" * 80)
        print("ğŸ” æ‰§è¡Œèˆ†æƒ…é£æ§/å¢å¼º")
        print("=" * 80)

        if selected_stocks.empty:
            print("  âš ï¸  è¾“å…¥ä¸ºç©ºï¼Œè·³è¿‡èˆ†æƒ…åˆ†æ")
            return selected_stocks

        # ç¡®å®šåˆ†ææ—¶é—´èŒƒå›´
        latest_date = factor_data['date'].max()
        end_date = str(latest_date).split(' ')[0]
        start_date = (pd.to_datetime(end_date) - timedelta(days=self.lookback_days)).strftime('%Y-%m-%d')

        print(f"  ğŸ“… åˆ†ææœŸé—´: {start_date} ~ {end_date}")
        print(f"  ğŸ“Š å¾…åˆ†æè‚¡ç¥¨: {len(selected_stocks)} åª")

        # è·å–è‚¡ç¥¨åˆ—è¡¨
        stock_list = selected_stocks['instrument'].unique().tolist()

        # 1. å¸‚åœºæ•´ä½“èˆ†æƒ…åˆ†æ
        print("\n  [1/3] åˆ†æå¸‚åœºæ•´ä½“èˆ†æƒ…...")
        market_sentiment = self.analyzer.analyze_market_sentiment(start_date, end_date)

        if market_sentiment['policy_support_keywords']:
            print(f"    âœ“ æ”¿ç­–çƒ­ç‚¹: {', '.join(market_sentiment['policy_support_keywords'][:5])}")

        # 2. æ‰¹é‡ä¸ªè‚¡èˆ†æƒ…åˆ†æ (é«˜æ•ˆæ–¹å¼)
        print(f"\n  [2/3] æ‰¹é‡ä¸ªè‚¡èˆ†æƒ…åˆ†æ...")
        sentiment_results = self.analyzer.batch_analyze_sentiment(stock_list, start_date, end_date)

        # 3. åº”ç”¨è¿‡æ»¤è§„åˆ™
        print(f"\n  [3/3] åº”ç”¨è¿‡æ»¤è§„åˆ™...")

        result = selected_stocks.copy()

        # ä¸€ç¥¨å¦å†³
        if enable_veto:
            veto_list = []
            for ts_code, sentiment in sentiment_results.items():
                if sentiment['is_veto']:
                    veto_list.append({
                        'instrument': ts_code,
                        'reason': sentiment['veto_reason']
                    })

            if veto_list:
                veto_codes = [item['instrument'] for item in veto_list]
                original_count = len(result)
                result = result[~result['instrument'].isin(veto_codes)]
                filtered_count = original_count - len(result)

                print(f"\n  ğŸš« ä¸€ç¥¨å¦å†³: {filtered_count} åª")
                for item in veto_list[:5]:  # åªæ‰“å°å‰5ä¸ª
                    print(f"     â€¢ {item['instrument']}: {item['reason']}")
                if len(veto_list) > 5:
                    print(f"     ... è¿˜æœ‰ {len(veto_list) - 5} åª")
            else:
                print(f"\n  âœ… ä¸€ç¥¨å¦å†³æ£€æŸ¥: æœªå‘ç°é£é™©è‚¡ç¥¨")

        # åŠ åˆ†å¢å¼º
        if enable_boost:
            # ç¡®ä¿resultä¸­æœ‰positionæˆ–ml_scoreåˆ—
            score_col = 'ml_score' if 'ml_score' in result.columns else 'position'

            if score_col in result.columns:
                boost_count = 0
                boost_examples = []  # è®°å½•åŠ åˆ†ç¤ºä¾‹
                
                for ts_code, sentiment in sentiment_results.items():
                    if sentiment['boost_score'] > 0.01:  # è‡³å°‘è¦æœ‰1%çš„åŠ åˆ†æ‰è®°å½•
                        # æ›´æ–°resultä¸­å¯¹åº”è‚¡ç¥¨çš„è¯„åˆ†
                        mask = result['instrument'] == ts_code
                        if mask.any():
                            old_score = result.loc[mask, score_col].values[0]
                            new_score = old_score * (1 + sentiment['boost_score'])
                            result.loc[mask, score_col] = new_score
                            boost_count += 1
                            
                            # è®°å½•ç¤ºä¾‹ï¼ˆæœ€å¤šè®°å½•5ä¸ªï¼‰
                            if len(boost_examples) < 5:
                                boost_examples.append({
                                    'code': ts_code,
                                    'boost': sentiment['boost_score'],
                                    'reasons': sentiment['boost_reasons'][:3]  # æœ€å¤š3ä¸ªåŸå› 
                                })

                if boost_count > 0:
                    print(f"\n  ğŸ“ˆ åŠ åˆ†å¢å¼º: {boost_count} åª")
                    # æ˜¾ç¤ºåŠ åˆ†ç¤ºä¾‹
                    for example in boost_examples:
                        reasons_str = ', '.join(example['reasons']) if example['reasons'] else 'é¢˜æåŠ åˆ†'
                        print(f"     â€¢ {example['code']}: +{example['boost']:.1%} ({reasons_str})")
                    if boost_count > len(boost_examples):
                        print(f"     ... è¿˜æœ‰ {boost_count - len(boost_examples)} åª")
                else:
                    print(f"\n  â„¹ï¸  åŠ åˆ†å¢å¼º: æœªå‘ç°å¯åŠ åˆ†è‚¡ç¥¨")
            else:
                print(f"\n  âš ï¸  åŠ åˆ†å¢å¼º: æœªæ‰¾åˆ°è¯„åˆ†åˆ—({score_col})")

        # é‡æ–°æ’åº
        if 'ml_score' in result.columns:
            result = result.sort_values('ml_score', ascending=False)  # type: ignore
        elif 'position' in result.columns:
            result = result.sort_values('position', ascending=False)  # type: ignore

        print(f"\n  âœ… èˆ†æƒ…é£æ§å®Œæˆ: {len(selected_stocks)} â†’ {len(result)} åª")

        return result.reset_index(drop=True)  # type: ignore

    def generate_sentiment_report(self, selected_stocks: pd.DataFrame,
                                  filtered_stocks: pd.DataFrame) -> Dict:
        """
        ç”Ÿæˆèˆ†æƒ…åˆ†ææŠ¥å‘Š

        Returns:
            {
                'original_count': int,
                'filtered_count': int,
                'veto_count': int,
                'boost_count': int,
                'summary': str
            }
        """
        report = {
            'original_count': len(selected_stocks),
            'filtered_count': len(filtered_stocks),
            'veto_count': len(selected_stocks) - len(filtered_stocks),
            'boost_count': 0,
            'summary': ''
        }

        # ç”Ÿæˆæ‘˜è¦
        summary_lines = [
            f"åŸå§‹é€‰è‚¡: {report['original_count']} åª",
            f"ä¸€ç¥¨å¦å†³: {report['veto_count']} åª",
            f"æœ€ç»ˆé€šè¿‡: {report['filtered_count']} åª",
        ]

        report['summary'] = '\n'.join(summary_lines)

        return report


# ============================================================================
# ç¬¬äº”éƒ¨åˆ†ï¼šä¾¿æ·å‡½æ•°
# ============================================================================

def apply_sentiment_control(selected_stocks: pd.DataFrame,
                            factor_data: pd.DataFrame,
                            price_data: pd.DataFrame,
                            tushare_token: Optional[str] = None,
                            cache_manager=None,
                            enable_veto: bool = True,
                            enable_boost: bool = True,
                            lookback_days: int = 30) -> pd.DataFrame:
    """
    ä¾¿æ·å‡½æ•°ï¼šä¸€é”®åº”ç”¨èˆ†æƒ…é£æ§

    ä½¿ç”¨ç¤ºä¾‹:
    ```python
    from sentiment_risk_control import apply_sentiment_control

    filtered = apply_sentiment_control(
        selected_stocks=top_stocks,
        factor_data=factor_data,
        price_data=price_data,
        tushare_token=YOUR_TOKEN
    )
    ```
    """
    controller = SentimentRiskController(
        tushare_token=tushare_token,
        cache_manager=cache_manager,
        lookback_days=lookback_days
    )

    return controller.apply_sentiment_filter(
        selected_stocks=selected_stocks,
        factor_data=factor_data,
        price_data=price_data,
        enable_veto=enable_veto,
        enable_boost=enable_boost
    )


# ============================================================================
# æµ‹è¯•ä»£ç 
# ============================================================================

if __name__ == "__main__":
    print("\n" + "=" * 80)
    print("èˆ†æƒ…é£æ§æ¨¡å— - ç‹¬ç«‹æµ‹è¯•")
    print("=" * 80)

    # æ¨¡æ‹Ÿæ•°æ®
    test_stocks = pd.DataFrame({
        'instrument': ['000001.SZ', '600000.SH', '000002.SZ'],
        'position': [0.95, 0.92, 0.88],
        'date': ['2024-01-15'] * 3
    })

    test_factor_data = pd.DataFrame({
        'date': ['2024-01-15'] * 3,
        'instrument': ['000001.SZ', '600000.SH', '000002.SZ'],
        'position': [0.95, 0.92, 0.88]
    })

    test_price_data = pd.DataFrame({
        'date': ['2024-01-15'] * 3,
        'instrument': ['000001.SZ', '600000.SH', '000002.SZ'],
        'close': [10.0, 15.0, 20.0]
    })

    print("\nâœ“ æ¨¡å—åŠ è½½æˆåŠŸï¼")
    print("\nä½¿ç”¨æ–¹æ³•:")
    print("```python")
    print("from sentiment_risk_control import SentimentRiskController")
    print("")
    print("controller = SentimentRiskController(tushare_token=YOUR_TOKEN)")
    print("filtered = controller.apply_sentiment_filter(")
    print("    selected_stocks=top_stocks,")
    print("    factor_data=factor_data,")
    print("    price_data=price_data")
    print(")")
    print("```")