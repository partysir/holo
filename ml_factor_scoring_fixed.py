# -*- coding: utf-8 -*-
"""
ml_factor_scoring_fixed.py - ä¿®å¤æ•°æ®æ³„éœ²åçš„é«˜çº§æœºå™¨å­¦ä¹ å› å­è¯„åˆ†ç³»ç»Ÿ

ğŸ”§ ä¸»è¦ä¿®å¤å†…å®¹ï¼š
1. âœ… ä¸¥æ ¼éš”ç¦»é¢„æµ‹åˆ—ï¼ˆposition, ml_scoreç­‰ï¼‰é˜²æ­¢æ³„éœ²
2. âœ… ç§»é™¤å…±çº¿æ€§å› å­ï¼ˆpb/psåªä¿ç•™peï¼‰
3. âœ… æ·»åŠ ç‰¹å¾éªŒè¯æ–­è¨€
4. âœ… ä¼˜åŒ–ç‰¹å¾æ’é™¤é€»è¾‘
5. âœ… ä¿®å¤XGBoost 2.0+å…¼å®¹æ€§é—®é¢˜

æ ¸å¿ƒä¼˜åŒ–ç‰¹æ€§ï¼š
âœ… 1. æ—¶é—´åºåˆ—åˆ‡åˆ†ï¼ˆé¿å…å‰è§†åå·®ï¼‰
âœ… 2. åˆ†ç±»ç›®æ ‡ï¼ˆé¢„æµ‹TOP 20%ï¼‰
âœ… 3. ICåŠ æƒ - å› å­æœ‰æ•ˆæ€§åŠ¨æ€è¯„ä¼°
âœ… 4. æ»šåŠ¨è®­ç»ƒ - è‡ªé€‚åº”å¸‚åœºå˜åŒ–
âœ… 5. æ ‡ç­¾ä¼˜åŒ– - ä½¿ç”¨è¶…é¢æ”¶ç›Šï¼ˆActive Returnï¼‰
âœ… 6. StockRankerå¤šå› å­å®Œæ•´å®ç°
âœ… 7. è¡Œä¸š/å¸‚å€¼/é£æ ¼ä¸­æ€§åŒ–
"""

import pandas as pd
import numpy as np
import warnings
from typing import List, Dict, Tuple, Optional, Union
from datetime import datetime, timedelta

# ----------------------------------------------------------------------------
# ä¾èµ–åº“æ£€æŸ¥ä¸å¯¼å…¥
# ----------------------------------------------------------------------------
warnings.filterwarnings('ignore')

# æœºå™¨å­¦ä¹ æ¨¡å‹åº“
try:
    import xgboost as xgb

    XGBOOST_AVAILABLE = True
except ImportError:
    print("âš ï¸  XGBoost æœªå®‰è£…ï¼Œè¿è¡Œ: pip install xgboost")
    xgb = None
    XGBOOST_AVAILABLE = False

try:
    import lightgbm as lgb

    LIGHTGBM_AVAILABLE = True
except ImportError:
    print("âš ï¸  LightGBM æœªå®‰è£…ï¼Œè¿è¡Œ: pip install lightgbm")
    lgb = None
    LIGHTGBM_AVAILABLE = False

# Sklearn å·¥å…·
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.metrics import (
    classification_report, roc_auc_score, accuracy_score,
    precision_score, recall_score
)
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression


# ============================================================================
# ç¬¬ä¸€éƒ¨åˆ†ï¼šæ ¸å¿ƒåŸºç¡€æ¨¡å— (ICè®¡ç®—ä¸æ—¶é—´åºåˆ—åˆ‡åˆ†)
# ============================================================================

class ICCalculator:
    """
    å› å­ICï¼ˆä¿¡æ¯ç³»æ•°ï¼‰è®¡ç®—å™¨

    IC = å› å­å€¼ä¸æœªæ¥æ”¶ç›Šçš„ç›¸å…³æ€§
    ICIR = ICçš„å‡å€¼ / ICçš„æ ‡å‡†å·®ï¼ˆå¤æ™®æ¯”ç‡çš„å› å­ç‰ˆï¼‰
    RankIC = å› å­æ’åä¸æ”¶ç›Šæ’åçš„ç›¸å…³æ€§ï¼ˆæ›´ç¨³å¥ï¼‰
    """

    def __init__(self, forward_periods: List[int] = [5, 10, 20]):
        self.forward_periods = forward_periods
        self.ic_history = {}  # {factor: {period: [ic_values]}}
        self.rank_ic_history = {}  # Rank ICå†å²

    def calculate_factor_ic(self,
                            factor_data: pd.DataFrame,
                            price_data: pd.DataFrame,
                            factor_columns: List[str]) -> Dict:
        """è®¡ç®—æ‰€æœ‰å› å­çš„ICå€¼"""
        print("\nğŸ“Š è®¡ç®—å› å­IC...")

        # æ£€æµ‹ä»·æ ¼åˆ—
        price_col = self._detect_price_column(price_data)
        if price_col is None:
            print("  âš ï¸  æœªæ‰¾åˆ°ä»·æ ¼åˆ—ï¼Œè·³è¿‡ICè®¡ç®—")
            return {}

        # åˆå¹¶æ•°æ®
        merged = factor_data.merge(
            price_data[['instrument', 'date', price_col]],
            on=['instrument', 'date'],
            how='left'
        )

        merged = merged.sort_values(['instrument', 'date']).reset_index(drop=True)

        # è®¡ç®—ä¸åŒå‘¨æœŸçš„æœªæ¥æ”¶ç›Š
        for period in self.forward_periods:
            # ç»å¯¹æ”¶ç›Š
            merged[f'abs_return_{period}d'] = merged.groupby('instrument')[price_col].pct_change(
                period
            ).shift(-period)

            # è¶…é¢æ”¶ç›Šï¼ˆç›¸å¯¹å¸‚åœºï¼‰
            market_return = merged.groupby('date')[f'abs_return_{period}d'].transform('mean')
            merged[f'future_return_{period}d'] = merged[f'abs_return_{period}d'] - market_return

        ic_results = {}
        merged_filtered = merged.dropna(subset=[price_col])

        for factor in factor_columns:
            if factor not in merged_filtered.columns:
                continue

            ic_results[factor] = {}

            for period in self.forward_periods:
                return_col = f'future_return_{period}d'
                valid_data = merged_filtered[[factor, return_col, 'date']].dropna()

                if len(valid_data) < 10:
                    continue

                grouped = valid_data.groupby('date')

                # Pearson IC
                daily_ic_series = grouped.apply(
                    lambda x: x[factor].corr(x[return_col]) if len(x) >= 10 else np.nan
                )
                daily_ic = daily_ic_series.dropna().tolist()

                # Rank IC (Spearman)
                daily_rank_ic_series = grouped.apply(
                    lambda x: x[factor].corr(x[return_col], method='spearman')
                    if len(x) >= 10 else np.nan
                )
                daily_rank_ic = daily_rank_ic_series.dropna().tolist()

                if len(daily_ic) > 0:
                    ic_mean = np.mean(daily_ic)
                    ic_std = np.std(daily_ic)
                    icir = ic_mean / ic_std if ic_std > 0 else 0

                    rank_ic_mean = np.mean(daily_rank_ic)
                    rank_ic_std = np.std(daily_rank_ic)
                    rank_icir = rank_ic_mean / rank_ic_std if rank_ic_std > 0 else 0

                    ic_win_rate = np.mean([1 if ic > 0 else 0 for ic in daily_ic])

                    ic_results[factor][period] = {
                        'ic': ic_mean, 'ic_std': ic_std, 'icir': icir,
                        'rank_ic': rank_ic_mean, 'rank_ic_std': rank_ic_std, 'rank_icir': rank_icir,
                        'ic_win_rate': ic_win_rate, 'sample_days': len(daily_ic)
                    }

                    # è®°å½•å†å²
                    if factor not in self.ic_history:
                        self.ic_history[factor] = {}
                        self.rank_ic_history[factor] = {}
                    self.ic_history[factor][period] = daily_ic
                    self.rank_ic_history[factor][period] = daily_rank_ic

        self._print_ic_summary(ic_results)
        return ic_results

    def _detect_price_column(self, df: pd.DataFrame) -> Optional[str]:
        candidates = ['close', 'Close', 'CLOSE', 'price', 'Price', 'adj_close']
        for col in candidates:
            if col in df.columns:
                return col
        return None

    def _print_ic_summary(self, ic_results: Dict):
        print(f"\n  ğŸ“ˆ å› å­ICç»Ÿè®¡:")
        print(f"  {'å› å­':<25s} | {'IC(5æ—¥)':<10s} | {'RankIC':<10s} | {'ICIR':<10s} | {'èƒœç‡':<10s}")
        print(f"  {'-' * 80}")

        for factor, periods in ic_results.items():
            ic_5 = periods.get(5, {}).get('ic', 0)
            rank_ic_5 = periods.get(5, {}).get('rank_ic', 0)
            icir_5 = periods.get(5, {}).get('icir', 0)
            win_rate = periods.get(5, {}).get('ic_win_rate', 0)

            print(f"  {factor:<25s} | {ic_5:>9.4f} | {rank_ic_5:>9.4f} | "
                  f"{icir_5:>9.4f} | {win_rate:>9.2%}")

    def get_ic_weights(self, ic_results: Dict, period: int = 5, method: str = 'icir') -> Dict[str, float]:
        """æ ¹æ®ICè®¡ç®—å› å­æƒé‡"""
        weights = {}
        total_score = 0.0

        for factor, periods in ic_results.items():
            if period not in periods:
                weights[factor] = 0.0
                continue

            period_data = periods[period]
            ic_val = period_data.get('ic', 0.0) or 0.0
            rank_ic_val = period_data.get('rank_ic', 0.0) or 0.0
            icir_val = period_data.get('icir', 0.0) or 0.0
            rank_icir_val = period_data.get('rank_icir', 0.0) or 0.0

            val_map = {
                'ic': abs(float(ic_val)),
                'rank_ic': abs(float(rank_ic_val)),
                'icir': abs(float(icir_val)),
                'rank_icir': abs(float(rank_icir_val))
            }
            score = val_map.get(method, abs(float(ic_val)))

            weights[factor] = float(score)
            total_score += float(score)

        if total_score > 0:
            weights = {k: float(v / total_score) for k, v in weights.items()}

        return weights


class TimeSeriesSplitter:
    """
    æ—¶é—´åºåˆ—æ•°æ®åˆ‡åˆ†å™¨ (Walk-Forward)
    è®­ç»ƒé›† -> éªŒè¯é›† -> æµ‹è¯•é›†ï¼Œé¿å…ä¿¡æ¯æ³„éœ²
    """

    def __init__(self, train_months: int = 12, valid_months: int = 1,
                 test_months: int = 1, gap_days: int = 0, expanding: bool = False):
        self.train_months = train_months
        self.valid_months = valid_months
        self.test_months = test_months
        self.gap_days = gap_days
        self.expanding = expanding

    def split(self, data: pd.DataFrame, date_column: str = 'date') -> List[Tuple]:
        data = data.copy()
        data[date_column] = pd.to_datetime(data[date_column])
        data = data.sort_values(date_column).reset_index(drop=True)

        data['year_month'] = data[date_column].dt.to_period('M')
        months = sorted(data['year_month'].unique())

        print(f"\n  ğŸ“… æ—¶é—´èŒƒå›´: {months[0]} è‡³ {months[-1]} (å…±{len(months)}ä¸ªæœˆ)")

        splits = []
        min_required_months = self.train_months + self.valid_months + self.test_months

        if len(months) < min_required_months:
            print(f"  âš ï¸  æ•°æ®ä¸è¶³: éœ€è¦è‡³å°‘{min_required_months}ä¸ªæœˆï¼Œå®é™…{len(months)}ä¸ªæœˆ")
            return []

        for i in range(len(months) - min_required_months + 1):
            train_start = 0 if self.expanding else i
            train_end = i + self.train_months
            train_months_list = months[train_start:train_end]

            valid_start = train_end
            valid_end = valid_start + self.valid_months
            valid_months_list = months[valid_start:valid_end]

            test_start = valid_end
            test_end = test_start + self.test_months
            if test_end > len(months): break
            test_months_list = months[test_start:test_end]

            train_idx = data[data['year_month'].isin(train_months_list)].index.tolist()
            valid_idx = data[data['year_month'].isin(valid_months_list)].index.tolist()
            test_idx = data[data['year_month'].isin(test_months_list)].index.tolist()

            # Gap handling
            if self.gap_days > 0:
                train_end_date = data.loc[train_idx, date_column].max()
                gap_cutoff = train_end_date + timedelta(days=self.gap_days)
                valid_idx = [idx for idx in valid_idx if data.loc[idx, date_column] >= gap_cutoff]

            if len(train_idx) > 0 and len(valid_idx) > 0 and len(test_idx) > 0:
                splits.append((train_idx, valid_idx, test_idx))

        print(f"  âœ“ ç”Ÿæˆ {len(splits)} ä¸ªæ—¶é—´çª—å£")
        if len(splits) > 0:
            self._print_split_info(data, splits[0], date_column, "ç¬¬1ä¸ª")
        return splits

    def _print_split_info(self, data, split, date_column, label):
        train_idx, valid_idx, test_idx = split
        train_dates = data.loc[train_idx, date_column]
        valid_dates = data.loc[valid_idx, date_column]
        test_dates = data.loc[test_idx, date_column]
        print(f"\n  {label}çª—å£:")
        print(f"    è®­ç»ƒé›†: {train_dates.min().date()} - {train_dates.max().date()} ({len(train_idx)})")
        print(f"    éªŒè¯é›†: {valid_dates.min().date()} - {valid_dates.max().date()} ({len(valid_idx)})")
        print(f"    æµ‹è¯•é›†: {test_dates.min().date()} - {test_dates.max().date()} ({len(test_idx)})")


# ============================================================================
# ç¬¬äºŒéƒ¨åˆ†ï¼šå› å­å¤„ç†æ¨¡å— (StockRanker & Generator)
# ============================================================================

class StockRanker:
    """StockRanker å¤šå› å­ç»¼åˆè¯„åˆ†å™¨ (é¢„å¤„ç†ã€åˆæˆã€ä¸­æ€§åŒ–)"""

    def __init__(self, method: str = 'equal', normalize_method: str = 'zscore',
                 winsorize: bool = True, winsorize_std: float = 3.0):
        self.method = method
        self.normalize_method = normalize_method
        self.winsorize = winsorize
        self.winsorize_std = winsorize_std
        self.factor_weights = {}

        print(f"\nğŸ¯ åˆå§‹åŒ– StockRanker [åˆæˆ: {method}, æ ‡å‡†åŒ–: {normalize_method}]")

    def preprocess_factors(self, factor_data: pd.DataFrame, factor_columns: List[str]) -> pd.DataFrame:
        print(f"\n  ğŸ”§ å› å­é¢„å¤„ç† ({len(factor_columns)}ä¸ªå› å­)...")
        data = factor_data.copy()

        for factor in factor_columns:
            if factor not in data.columns: continue
            data[f'{factor}_processed'] = data.groupby('date')[factor].transform(
                lambda x: self._preprocess_single_factor(x)
            )
        print(f"  âœ“ é¢„å¤„ç†å®Œæˆ")
        return data

    def _preprocess_single_factor(self, x: pd.Series) -> pd.Series:
        # å»æå€¼
        if self.winsorize:
            mean, std = x.mean(), x.std()
            x = x.clip(mean - self.winsorize_std * std, mean + self.winsorize_std * std)

        # æ ‡å‡†åŒ–
        if self.normalize_method == 'zscore':
            std = x.std()
            x = (x - x.mean()) / std if std > 0 else (x - x.mean())
        elif self.normalize_method == 'minmax':
            x = (x - x.min()) / (x.max() - x.min()) if x.max() > x.min() else x
        elif self.normalize_method == 'rank':
            x = x.rank(pct=True)
        return x

    def calculate_composite_score(self, factor_data: pd.DataFrame, factor_columns: List[str],
                                  ic_weights: Optional[Dict[str, float]] = None) -> pd.DataFrame:
        print(f"\n  ğŸ“Š è®¡ç®—ç»¼åˆè¯„åˆ† (æ–¹æ³•: {self.method})...")
        data = factor_data.copy()

        processed_columns = [f'{factor}_processed' for factor in factor_columns
                             if f'{factor}_processed' in data.columns]

        if not processed_columns:
            print("  âš ï¸  æœªæ‰¾åˆ°é¢„å¤„ç†å› å­ï¼Œä½¿ç”¨åŸå§‹å› å­")
            processed_columns = [f for f in factor_columns if f in data.columns]

        if self.method == 'equal':
            data['composite_score'] = data[processed_columns].mean(axis=1)
            self.factor_weights = {col: 1.0 / len(processed_columns) for col in processed_columns}

        elif self.method in ['ic_weight', 'optimize']:
            if ic_weights is None:
                print("  âš ï¸  æ— ICæƒé‡ï¼Œå›é€€è‡³ç­‰æƒ")
                data['composite_score'] = data[processed_columns].mean(axis=1)
            else:
                weights, valid_cols = [], []
                for col in processed_columns:
                    fname = col.replace('_processed', '')
                    if fname in ic_weights:
                        w = ic_weights[fname]
                        if self.method == 'optimize': w = w ** 2  # ç®€å•ä¼˜åŒ–ï¼šå¹³æ–¹åŠ å¼ºé«˜ICå› å­
                        weights.append(w)
                        valid_cols.append(col)

                if valid_cols:
                    weights = np.array(weights) / sum(weights)
                    data['composite_score'] = (data[valid_cols] * weights).sum(axis=1)
                    self.factor_weights = dict(zip(valid_cols, weights))
                else:
                    data['composite_score'] = data[processed_columns].mean(axis=1)

        data['score_rank'] = data.groupby('date')['composite_score'].rank(pct=True)
        print(f"  âœ“ ç»¼åˆè¯„åˆ†å®Œæˆ")
        self._print_weight_summary()
        return data

    def _print_weight_summary(self):
        if not self.factor_weights: return
        print(f"\n  ğŸ“Š å› å­æƒé‡ (Top 10):")
        sorted_w = sorted(self.factor_weights.items(), key=lambda x: x[1], reverse=True)
        for f, w in sorted_w[:10]:
            print(f"     {f.replace('_processed', ''):<25s}: {w:>7.2%}")

    def apply_industry_neutralization(self, factor_data: pd.DataFrame,
                                      industry_column: str = 'industry') -> pd.DataFrame:
        print(f"\n  ğŸ¢ åº”ç”¨è¡Œä¸šä¸­æ€§åŒ–...")
        data = factor_data.copy()
        if industry_column not in data.columns: return data

        data['composite_score_neutral'] = data.groupby(['date', industry_column])['composite_score'].transform(
            lambda x: (x - x.mean()) / x.std() if x.std() > 0 else 0
        )
        data['score_rank_neutral'] = data.groupby('date')['composite_score_neutral'].rank(pct=True)
        print(f"  âœ“ è¡Œä¸šä¸­æ€§åŒ–å®Œæˆ")
        return data

    def apply_market_cap_neutralization(self, factor_data: pd.DataFrame,
                                        cap_column: str = 'market_cap') -> pd.DataFrame:
        print(f"\n  ğŸ’° åº”ç”¨å¸‚å€¼ä¸­æ€§åŒ–...")
        data = factor_data.copy()
        if cap_column not in data.columns: return data

        data['log_cap'] = np.log(data[cap_column].clip(lower=1))

        def neutralize(group):
            if len(group) < 10: return group
            X = group[['log_cap']].values
            y = group['composite_score'].values
            reg = LinearRegression().fit(X, y)
            group['composite_score_neutral'] = y - reg.predict(X)
            return group

        data = data.groupby('date').apply(neutralize).reset_index(drop=True)
        data['score_rank_neutral'] = data.groupby('date')['composite_score_neutral'].rank(pct=True)
        print(f"  âœ“ å¸‚å€¼ä¸­æ€§åŒ–å®Œæˆ")
        return data


class FactorGenerator:
    """å› å­ç”Ÿæˆå™¨ç¤ºä¾‹"""

    @staticmethod
    def generate_momentum_factors(price_data: pd.DataFrame, periods=[5, 10, 20, 60]) -> pd.DataFrame:
        data = price_data.sort_values(['instrument', 'date']).copy()
        price_col = 'close' if 'close' in data.columns else 'Close'
        for p in periods:
            data[f'momentum_{p}d'] = data.groupby('instrument')[price_col].pct_change(p)
            if p <= 5: data[f'reversal_{p}d'] = -data[f'momentum_{p}d']
        return data

    @staticmethod
    def generate_volatility_factors(price_data: pd.DataFrame, periods=[5, 10, 20]) -> pd.DataFrame:
        data = price_data.sort_values(['instrument', 'date']).copy()
        price_col = 'close' if 'close' in data.columns else 'Close'
        data['ret'] = data.groupby('instrument')[price_col].pct_change()
        for p in periods:
            data[f'volatility_{p}d'] = data.groupby('instrument')['ret'].transform(lambda x: x.rolling(p).std())
        return data


# ============================================================================
# ç¬¬ä¸‰éƒ¨åˆ†ï¼šé«˜çº§MLè¯„åˆ†å™¨ (å®Œæ•´å®ç° - å·²ä¿®å¤æ•°æ®æ³„éœ²)
# ============================================================================

class AdvancedMLScorer:
    """
    é«˜çº§æœºå™¨å­¦ä¹ è¯„åˆ†å™¨ (ä¿®å¤ç‰ˆ)
    æ•´åˆ: æ—¶é—´åºåˆ—åˆ‡åˆ†, ICç‰¹å¾, Active Returnæ ‡ç­¾, æ¨¡å‹é›†æˆ

    ğŸ”§ ä¿®å¤å†…å®¹:
    1. ä¸¥æ ¼æ’é™¤æ‰€æœ‰é¢„æµ‹ç›¸å…³åˆ—ï¼ˆposition, ml_scoreç­‰ï¼‰
    2. æ·»åŠ ç‰¹å¾éªŒè¯æ–­è¨€
    3. é¢„æµ‹ç»“æœç‹¬ç«‹å­˜å‚¨ï¼Œä¸æ±¡æŸ“è®­ç»ƒæ•°æ®
    """

    def __init__(self, model_type: str = 'xgboost', target_period: int = 5, top_percentile: float = 0.20,
                 use_classification: bool = True, use_ic_features: bool = True, use_active_return: bool = True,
                 train_months: int = 12, scaler_type: str = 'standard', random_state: int = 42):
        self.model_type = model_type
        self.target_period = target_period
        self.top_percentile = top_percentile
        self.use_classification = use_classification
        self.use_ic_features = use_ic_features
        self.use_active_return = use_active_return
        self.train_months = train_months
        self.scaler = RobustScaler() if scaler_type == 'robust' else StandardScaler()
        self.random_state = random_state

        self.models = {}
        self.feature_names = None
        self.ic_calculator = ICCalculator([target_period])

        print(f"\nğŸš€ åˆå§‹åŒ–é«˜çº§MLè¯„åˆ†å™¨ [æ¨¡å‹: {model_type}, ç›®æ ‡: {target_period}d, åˆ†ç±»: {use_classification}]")

    def prepare_training_data(self, factor_data: pd.DataFrame, price_data: pd.DataFrame,
                              factor_columns: List[str]) -> Tuple[pd.DataFrame, np.ndarray, pd.DataFrame]:
        """
        ğŸ”§ ä¿®å¤ï¼šä¸¥æ ¼æ’é™¤é¢„æµ‹åˆ—ï¼Œé˜²æ­¢æ•°æ®æ³„éœ²
        """
        print(f"\nğŸ“¦ å‡†å¤‡è®­ç»ƒæ•°æ®...")
        price_col = self._detect_price_column(price_data)

        merged = factor_data.merge(
            price_data[['instrument', 'date', price_col]],
            on=['instrument', 'date'], how='left'
        ).sort_values(['instrument', 'date']).reset_index(drop=True)

        # è®¡ç®—ICç‰¹å¾
        if self.use_ic_features:
            print("  âœ“ è®¡ç®—å› å­ICç‰¹å¾...")
            ic_results = self.ic_calculator.calculate_factor_ic(factor_data, price_data, factor_columns)
            for factor in factor_columns:
                if factor in ic_results:
                    stats = ic_results[factor].get(self.target_period, {})
                    merged[f'{factor}_ic'] = stats.get('ic', 0)
                    merged[f'{factor}_icir'] = stats.get('icir', 0)

        # æ„å»ºç›®æ ‡å˜é‡
        print(f"  âœ“ æ„å»ºç›®æ ‡å˜é‡ (Active Return: {self.use_active_return})...")
        # ä¿®å¤æ”¶ç›Šç‡è®¡ç®—æ–¹å‘ - ä½¿ç”¨æœªæ¥ä»·æ ¼ä¸å½“å‰ä»·æ ¼çš„æ¯”å€¼æ¥è®¡ç®—æ”¶ç›Šç‡
        # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨å‘é‡åŒ–æ“ä½œæ›¿ä»£groupby.applyé¿å…ç´¢å¼•ä¸åŒ¹é…é—®é¢˜
        merged = merged.sort_values(['instrument', 'date']).reset_index(drop=True)
        future_prices = merged.groupby('instrument')[price_col].shift(-self.target_period)
        current_prices = merged[price_col]
        merged['abs_return'] = (future_prices / current_prices) - 1

        if self.use_active_return:
            market_return = merged.groupby('date')['abs_return'].transform('mean')
            merged['future_return'] = merged['abs_return'] - market_return
        else:
            merged['future_return'] = merged['abs_return']

        if self.use_classification:
            merged['target'] = 0
            for date in merged['date'].unique():
                mask = merged['date'] == date
                daily_data = merged[mask]
                
                # ä¼˜åŒ–ç­–ç•¥ï¼šæ—¢è¦è·‘èµ¢å¸‚åœºï¼Œåˆè¦æœ‰ç»å¯¹æ”¶ç›Š
                # 1. ç›¸å¯¹æ”¶ç›Š Top 20%
                # 2. ç»å¯¹æ”¶ç›Š > 0 (å‰”é™¤å¤§è·Œå¸‚ä¸­çš„"æŠ—è·Œè‚¡", ç†Šå¸‚ç©ºä»“æ¯”ä¹°æŠ—è·Œæ›´å¥½)
                
                thresh = daily_data['future_return'].quantile(1 - self.top_percentile)
                
                # èƒœç‡ä¼˜åŒ–æ ¸å¿ƒï¼šåŒé‡è¿‡æ»¤
                # future_return æ˜¯ç›¸å¯¹æ”¶ç›Š (Active Return)
                # abs_return æ˜¯ç»å¯¹æ”¶ç›Š
                
                target_mask = (daily_data['future_return'] >= thresh) & (daily_data['abs_return'] > 0.0)
                
                merged.loc[mask & target_mask, 'target'] = 1
            target_col = 'target'
        else:
            target_col = 'future_return'

        merged = merged.dropna(subset=[target_col])

        # ğŸ”¥ ä¿®å¤ï¼šä¸¥æ ¼æ’é™¤æ‰€æœ‰å¯èƒ½æ³„éœ²çš„åˆ—
        exclude = [
            # åŸºç¡€æ ‡è¯†åˆ—
            'date', 'instrument',
            # ç›®æ ‡å˜é‡ç›¸å…³
            'future_return', 'abs_return', 'target',
            # ä»·æ ¼åˆ—
            price_col, 'close', 'Close', 'price', 'Price', 'adj_close',
            # åˆ†ç±»åˆ—
            'industry', 'sector', 'market_cap', 'log_cap',
            # ğŸ”¥ å…³é”®ï¼šæ‰€æœ‰é¢„æµ‹/è¯„åˆ†ç›¸å…³åˆ—ï¼ˆé˜²æ­¢æ•°æ®æ³„éœ²ï¼‰
            'ml_score', 'position', 'score_rank',
            'composite_score', 'composite_score_neutral',
            'score_rank_neutral', 'industry_rank',
            # ä¸­é—´å¤„ç†åˆ—
            'year_month'
        ]

        # ç‰¹å¾é€‰æ‹©ï¼šæ’é™¤éæ•°å€¼åˆ—å’Œå¤„ç†è¿‡çš„åˆ—
        feature_cols = [c for c in merged.columns
                        if c not in exclude
                        and pd.api.types.is_numeric_dtype(merged[c])
                        and not c.endswith('_processed')]  # æ’é™¤ä¸­é—´å¤„ç†åˆ—

        # ğŸ”¥ ä¿®å¤ï¼šæ·»åŠ æ–­è¨€éªŒè¯ï¼Œé˜²æ­¢positionç­‰åˆ—æ³„éœ²
        leaked_cols = [c for c in ['position', 'ml_score', 'score_rank', 'composite_score']
                       if c in feature_cols]
        if leaked_cols:
            raise ValueError(f"âš ï¸ CRITICAL: æ£€æµ‹åˆ°æ•°æ®æ³„éœ²ï¼ä»¥ä¸‹åˆ—ä¸åº”ä½œä¸ºç‰¹å¾: {leaked_cols}")

        print(f"  âœ“ éªŒè¯é€šè¿‡ï¼šå·²æ’é™¤ {len(exclude)} ç±»åˆ—ï¼Œä¿ç•™ {len(feature_cols)} ä¸ªæœ‰æ•ˆç‰¹å¾")

        X = merged[feature_cols].replace([np.inf, -np.inf], np.nan).fillna(0)
        y = merged[target_col].values
        self.feature_names = feature_cols

        # æ‰“å°å‰10ä¸ªç‰¹å¾ç”¨äºéªŒè¯
        print(f"  ğŸ“‹ ç‰¹å¾ç¤ºä¾‹: {feature_cols[:10]}")

        # ç¡®ä¿è¿”å›çš„æ˜¯DataFrameè€Œä¸æ˜¯Series
        if isinstance(X, pd.Series):
            X = X.to_frame()
        # ç¡®ä¿yæ˜¯numpyæ•°ç»„
        if not isinstance(y, np.ndarray):
            y = np.array(y)
        return X, y, merged

    def train_walk_forward(self, X: pd.DataFrame, y: np.ndarray, merged: pd.DataFrame, n_splits: int = 3):
        print(f"\nğŸ¯ Walk-Forward è®­ç»ƒ...")
        splitter = TimeSeriesSplitter(train_months=self.train_months, valid_months=1, test_months=1)
        splits = splitter.split(merged)

        if not splits:
            print("  âš ï¸ æ•°æ®ä¸è¶³ï¼Œåˆ‡æ¢ç®€å•åˆ‡åˆ†")
            return self._train_simple(X, y)

        if n_splits and n_splits < len(splits):
            splits = splits[-n_splits:]

        window_results = []
        for i, (train_idx, valid_idx, test_idx) in enumerate(splits):
            print(f"\n  === çª—å£ {i + 1}/{len(splits)} ===")

            X_train, y_train = X.iloc[train_idx], y[train_idx]
            X_valid, y_valid = X.iloc[valid_idx], y[valid_idx]

            X_train_s = self.scaler.fit_transform(X_train)
            X_valid_s = self.scaler.transform(X_valid)

            model = self._train_model(X_train_s, y_train, X_valid_s, y_valid)

            # è¯„ä¼°
            if model is not None:
                try:
                    if self.use_classification:
                        # å¯¹äºåˆ†ç±»æ¨¡å‹ï¼Œä½¿ç”¨AUCä½œä¸ºè¯„ä¼°æŒ‡æ ‡
                        try:
                            # æ£€æŸ¥æ¨¡å‹ç±»å‹ï¼Œé¿å…åœ¨å›å½’æ¨¡å‹ä¸Šè°ƒç”¨predict_proba
                            model_name = type(model).__name__
                            if 'Regressor' in model_name:
                                # å¦‚æœæ˜¯å›å½’æ¨¡å‹ï¼Œä½¿ç”¨predictæ–¹æ³•
                                pred = model.predict(X_valid_s)
                                # å®‰å…¨åœ°è½¬æ¢ä¸ºnumpyæ•°ç»„
                                if str(type(pred)).find('sparse') >= 0 or hasattr(pred, 'toarray'):
                                    try:
                                        pred = pred.toarray()  # type: ignore
                                    except:
                                        pass
                                pred = np.asarray(pred).flatten()
                                valid_score = roc_auc_score(y_valid, pred)
                            elif hasattr(model, 'predict_proba') and 'Classifier' in model_name:
                                proba = model.predict_proba(X_valid_s)
                                # å®‰å…¨åœ°è½¬æ¢ä¸ºnumpyæ•°ç»„
                                if str(type(proba)).find('sparse') >= 0 or hasattr(proba, 'toarray'):
                                    try:
                                        proba = proba.toarray()  # type: ignore
                                    except:
                                        pass
                                proba = np.asarray(proba)
                                if len(proba.shape) > 1 and proba.shape[1] > 1:
                                    valid_score = roc_auc_score(y_valid, proba[:, 1])
                                else:
                                    valid_score = roc_auc_score(y_valid, proba[:, 0] if len(proba.shape) > 1 else proba)
                            else:
                                # å¦‚æœæ²¡æœ‰predict_probaæ–¹æ³•ï¼Œä½¿ç”¨predictæ–¹æ³•
                                pred = model.predict(X_valid_s)
                                # å®‰å…¨åœ°è½¬æ¢ä¸ºnumpyæ•°ç»„
                                if str(type(pred)).find('sparse') >= 0 or hasattr(pred, 'toarray'):
                                    try:
                                        pred = pred.toarray()  # type: ignore
                                    except:
                                        pass
                                pred = np.asarray(pred).flatten()
                                valid_score = roc_auc_score(y_valid, pred)
                            print(f"     éªŒè¯AUC: {valid_score:.4f}")
                        except Exception as e:
                            print(f"     AUCè®¡ç®—å‡ºé”™: {e}")
                            valid_score = 0.0
                    else:
                        # å¯¹äºå›å½’æ¨¡å‹ï¼Œä½¿ç”¨ICä½œä¸ºè¯„ä¼°æŒ‡æ ‡
                        try:
                            pred = model.predict(X_valid_s)
                            # å®‰å…¨åœ°è½¬æ¢ä¸ºnumpyæ•°ç»„
                            if str(type(pred)).find('sparse') >= 0 or hasattr(pred, 'toarray'):
                                try:
                                    pred = pred.toarray()  # type: ignore
                                except:
                                    pass
                            pred = np.asarray(pred)
                            # ç¡®ä¿è¾“å…¥æ˜¯1ç»´æ•°ç»„
                            if len(pred.shape) > 1:
                                pred = pred.flatten()
                            # ç¡®ä¿y_validæ˜¯numpyæ•°ç»„
                            y_valid_flat = np.asarray(y_valid)
                            if len(y_valid_flat.shape) > 1:
                                y_valid_flat = y_valid_flat.flatten()
                            # è®¡ç®—ç›¸å…³ç³»æ•°
                            correlation_matrix = np.corrcoef(y_valid_flat, pred)
                            valid_score = correlation_matrix[0, 1] if correlation_matrix.size > 1 else 0
                            print(f"     éªŒè¯IC: {valid_score:.4f}")
                        except Exception as e:
                            print(f"     ICè®¡ç®—å‡ºé”™: {e}")
                            valid_score = 0.0
                    window_results.append({'model': model, 'score': float(valid_score), 'window': i})
                except Exception as e:
                    print(f"     è¯„ä¼°å‡ºé”™: {e}")
                    window_results.append({'model': model, 'score': 0.0, 'window': i})

        # é€‰æ‹©æœ€ä½³æ¨¡å‹
        if window_results:
            best = max(window_results, key=lambda x: x['score'])
            self.models['best'] = best['model']
            print(f"\n  ğŸ† æœ€ä½³æ¨¡å‹æ¥è‡ªçª—å£ {best['window'] + 1}, å¾—åˆ†: {best['score']:.4f}")
        return self

    def _train_model(self, X_train, y_train, X_valid, y_valid):
        """ğŸ”§ ä¿®å¤ï¼šXGBoost 2.0+ å…¼å®¹æ€§"""
        if self.use_classification:
            if self.model_type == 'xgboost' and XGBOOST_AVAILABLE and xgb is not None:
                # ä¿®å¤ï¼šearly_stopping_rounds ç§»å…¥æ„é€ å‡½æ•°
                model = xgb.XGBClassifier(
                    n_estimators=300, learning_rate=0.05, max_depth=6,
                    eval_metric='auc', random_state=self.random_state, n_jobs=-1,
                    early_stopping_rounds=30
                )
                model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], verbose=False)
                return model
            elif LIGHTGBM_AVAILABLE and lgb is not None:
                model = lgb.LGBMClassifier(
                    n_estimators=300, learning_rate=0.05, max_depth=6,
                    metric='auc', random_state=self.random_state, n_jobs=-1, verbose=-1
                )
                model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)],
                          callbacks=[lgb.early_stopping(30, verbose=False)])
                return model
        else:
            # å›å½’é€»è¾‘
            if self.model_type == 'xgboost' and XGBOOST_AVAILABLE and xgb is not None:
                model = xgb.XGBRegressor(
                    n_estimators=300, max_depth=6, random_state=self.random_state, n_jobs=-1,
                    early_stopping_rounds=30
                )
                model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], verbose=False)
                return model
        return None

    def _train_simple(self, X, y):
        print("  ä½¿ç”¨ç®€å•è®­ç»ƒæ¨¡å¼...")
        X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=self.random_state)
        X_train_s = self.scaler.fit_transform(X_train)
        X_valid_s = self.scaler.transform(X_valid)
        self.models['best'] = self._train_model(X_train_s, y_train, X_valid_s, y_valid)
        return self

    def predict_scores(self, factor_data: pd.DataFrame) -> pd.DataFrame:
        """
        ğŸ”§ ä¿®å¤ï¼šé¢„æµ‹ç»“æœç‹¬ç«‹å­˜å‚¨ï¼Œä¸æ±¡æŸ“åŸå§‹ç‰¹å¾
        """
        if 'best' not in self.models:
            raise ValueError("æ¨¡å‹æœªè®­ç»ƒ")

        data = factor_data.copy()

        # åªæå–ç‰¹å¾åˆ—è¿›è¡Œé¢„æµ‹
        X = data[self.feature_names].replace([np.inf, -np.inf], np.nan).fillna(0)
        X_scaled = self.scaler.transform(X)

        model = self.models['best']

        # ğŸ”¥ ä¿®å¤ï¼šåˆ›å»ºç‹¬ç«‹çš„ç»“æœDataFrame
        predictions = model.predict_proba(X_scaled)[:, 1] if self.use_classification else model.predict(X_scaled)

        result = pd.DataFrame({
            'date': data['date'].values,
            'instrument': data['instrument'].values,
            'ml_score': predictions
        })

        # è®¡ç®—æ’åï¼ˆåœ¨ç‹¬ç«‹DataFrameä¸­ï¼‰
        result['position'] = result.groupby('date')['ml_score'].rank(pct=True)

        # ğŸ”¥ å…³é”®ï¼šåªåˆå¹¶å¿…è¦çš„é¢„æµ‹åˆ—ï¼Œä¿æŒåŸå§‹æ•°æ®æ¸…æ´
        # å¦‚æœåŸæ•°æ®å·²æœ‰è¿™äº›åˆ—ï¼Œå…ˆåˆ é™¤
        for col in ['ml_score', 'position']:
            if col in data.columns:
                data = data.drop(columns=[col])

        # åˆå¹¶é¢„æµ‹ç»“æœ
        data = data.merge(result, on=['date', 'instrument'], how='left')

        print(f"  âœ“ é¢„æµ‹å®Œæˆï¼Œç”Ÿæˆ ml_score å’Œ position åˆ—")
        return data

    def get_feature_importance(self, top_n: int = 20):
        if 'best' not in self.models: return None
        imp = self.models['best'].feature_importances_
        df = pd.DataFrame({'feature': self.feature_names, 'importance': imp})
        return df.sort_values('importance', ascending=False).head(top_n)

    def _detect_price_column(self, df):
        for col in ['close', 'Close', 'price', 'Price']:
            if col in df.columns: return col
        return None

    def _safe_to_numpy_array(self, data):
        """å®‰å…¨åœ°å°†æ•°æ®è½¬æ¢ä¸ºnumpyæ•°ç»„"""
        try:
            # æ£€æŸ¥æ˜¯å¦ä¸ºç¨€ç–çŸ©é˜µ
            if str(type(data)).find('sparse') >= 0:
                if hasattr(data, 'toarray'):
                    try:
                        data = data.toarray()
                    except:
                        pass
            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            return np.asarray(data)
        except:
            return np.asarray(data)


# ============================================================================
# ç¬¬å››éƒ¨åˆ†ï¼šè¡Œä¸šæ•°æ®ä¸å›æµ‹è¾…åŠ©
# ============================================================================

def get_industry_data(instruments: List[str], tushare_token: Optional[str] = None) -> pd.DataFrame:
    """è·å–è¡Œä¸šæ•°æ® (æ”¯æŒTushare)"""
    if tushare_token is None:
        print("  âš ï¸  æœªæä¾› Tushare Tokenï¼Œä½¿ç”¨éšæœº/é»˜è®¤è¡Œä¸š")
        return pd.DataFrame({'instrument': instruments, 'industry': 'å…¶ä»–', 'industry_code': 'Z99'})

    try:
        import tushare as ts
        ts.set_token(tushare_token)
        pro = ts.pro_api()
        df = pro.stock_basic(exchange='', list_status='L', fields='ts_code,name,industry')
        df = df[df['ts_code'].isin(instruments)]
        df = df.rename(columns={'ts_code': 'instrument'})  # type: ignore
        df['industry'] = df['industry'].fillna('å…¶ä»–')
        result = df[['instrument', 'industry']]
        return result if isinstance(result, pd.DataFrame) else pd.DataFrame()  # type: ignore
    except Exception as e:
        print(f"  âš ï¸  è·å–è¡Œä¸šå¤±è´¥: {e}")
        return pd.DataFrame({'instrument': instruments, 'industry': 'å…¶ä»–'})


class IndustryBasedScorer:
    """åˆ†è¡Œä¸šè¯„åˆ†ä¸è½®åŠ¨åˆ†æ"""

    def __init__(self, tushare_token: Optional[str] = None):
        self.tushare_token = tushare_token

    def score_by_industry(self, factor_data: pd.DataFrame, score_column: str = 'position') -> pd.DataFrame:
        print("\nğŸ¢ åˆ†è¡Œä¸šè¯„åˆ†...")
        data = factor_data.copy()
        instruments = data['instrument'].unique().tolist()
        ind_data = get_industry_data(instruments, self.tushare_token)

        if 'industry' in data.columns: data = data.drop(columns=['industry'])
        data = data.merge(ind_data, on='instrument', how='left').fillna({'industry': 'å…¶ä»–'})

        data['industry_rank'] = data.groupby(['date', 'industry'])[score_column].rank(pct=True)
        return data

    def analyze_industry_rotation(self, factor_data: pd.DataFrame, top_n: int = 5) -> pd.DataFrame:
        print(f"\n  ğŸ”„ è¡Œä¸šè½®åŠ¨åˆ†æ (Top {top_n})...")
        stats = factor_data.groupby(['date', 'industry']).agg(
            {'position': 'mean', 'instrument': 'count'}
        ).reset_index()
        stats.columns = ['date', 'industry', 'avg_score', 'count']
        stats['rank'] = stats.groupby('date')['avg_score'].rank(ascending=False)

        latest = stats[stats['date'] == stats['date'].max()].nsmallest(top_n, 'rank')
        print(f"  æœ€æ–°å¼ºåŠ¿è¡Œä¸š: {latest['industry'].tolist()}")
        return stats


class EnhancedStockSelector:
    """å¢å¼ºé€‰è‚¡å™¨ (è¯„åˆ†è¿‡æ»¤ + è¡Œä¸šåˆ†æ•£)"""

    def select_stocks(self, factor_data: pd.DataFrame, min_score: float = 0.6,
                      max_stocks: Optional[int] = None, max_industry_conc: float = 0.3) -> pd.DataFrame:
        print(f"\nğŸ¯ å¢å¼ºé€‰è‚¡ [é˜ˆå€¼: {min_score:.0%}, ä¸Šé™: {max_stocks}]...")
        data = factor_data.copy()
        if 'industry' not in data.columns: data['industry'] = 'å…¶ä»–'

        results = []
        for date in data['date'].unique():
            daily = data[(data['date'] == date) & (data['position'] >= min_score)].sort_values('position',
                                                                                               ascending=False)  # type: ignore

            if max_stocks and len(daily) > max_stocks:
                limit = int(max_stocks * max_industry_conc)
                selected, counts = [], {}
                for _, row in daily.iterrows():
                    if len(selected) >= max_stocks: break
                    ind = row['industry']
                    if counts.get(ind, 0) < limit:
                        selected.append(row)
                        counts[ind] = counts.get(ind, 0) + 1
                daily = pd.DataFrame(selected)

            results.append(daily)

        final = pd.concat(results) if results else pd.DataFrame()
        print(f"  âœ“ é€‰å‡º {len(final)} æ¡äº¤æ˜“è®°å½•")
        return final


class SimpleBacktester:
    """ç®€å•å›æµ‹å™¨"""

    @staticmethod
    def backtest(selected_stocks: pd.DataFrame, price_data: pd.DataFrame, holding_period: int = 5) -> Dict:
        print(f"\nğŸ“Š ç®€å•å›æµ‹ (æŒæœ‰{holding_period}å¤©)...")
        price_col = 'close' if 'close' in price_data.columns else 'Close'

        merged = selected_stocks.merge(price_data[['instrument', 'date', price_col]], on=['instrument', 'date'],
                                       how='left')
        merged = merged.sort_values(['instrument', 'date'])
        # ä¿®å¤æ”¶ç›Šç‡è®¡ç®—æ–¹å‘ - ä½¿ç”¨æœªæ¥ä»·æ ¼ä¸å½“å‰ä»·æ ¼çš„æ¯”å€¼æ¥è®¡ç®—æ”¶ç›Šç‡
        # ä¿®å¤ç´¢å¼•ä¸åŒ¹é…é—®é¢˜
        merged = merged.sort_values(['instrument', 'date']).reset_index(drop=True)
        future_prices = merged.groupby('instrument')[price_col].shift(-holding_period)
        current_prices = merged[price_col]
        merged['ret'] = (future_prices / current_prices) - 1

        valid = merged.dropna(subset=['ret'])
        if len(valid) == 0: return {}

        res = {
            'avg_return': valid['ret'].mean(),
            'sharpe': valid['ret'].mean() / valid['ret'].std() if valid['ret'].std() > 0 else 0,
            'win_rate': (valid['ret'] > 0).mean(),
            'n_trades': len(valid)
        }

        print(f"  å¹³å‡æ”¶ç›Š: {res['avg_return']:.2%}")
        print(f"  å¤æ™®æ¯”ç‡: {res['sharpe']:.2f}")
        print(f"  èƒœç‡:     {res['win_rate']:.2%}")
        return res


# ============================================================================
# ç¬¬äº”éƒ¨åˆ†ï¼šç­–ç•¥ç¼–æ’ä¸ç¤ºä¾‹
# ============================================================================

class MultiFactorMLStrategy:
    """
    å¤šå› å­MLé€‰è‚¡ç­–ç•¥ç¼–æ’å™¨ (ä¿®å¤ç‰ˆ)
    æµç¨‹: å› å­æ¸…æ´— -> ICåˆ†æ -> StockRanker -> Walk-Forward ML -> è¡Œä¸šè¯„åˆ† -> é€‰è‚¡ -> å›æµ‹

    ğŸ”§ ä¿®å¤å†…å®¹:
    1. è‡ªåŠ¨å‰”é™¤å…±çº¿æ€§å› å­ï¼ˆpb/psï¼‰
    2. å¯é€‰å‰”é™¤æ— æ•ˆåŸºæœ¬é¢å› å­
    3. è®­ç»ƒå‰æ¸…ç†æ±¡æŸ“åˆ—
    """

    def __init__(self, model_type='xgboost', target_period=5, train_months=12,
                 tushare_token=None, remove_collinear=True, remove_weak_factors=False):
        self.target_period = target_period
        self.remove_collinear = remove_collinear
        self.remove_weak_factors = remove_weak_factors

        self.ic_calc = ICCalculator([target_period])
        self.ranker = StockRanker(method='ic_weight')
        self.ml = AdvancedMLScorer(model_type=model_type, target_period=target_period, train_months=train_months)
        self.ind_scorer = IndustryBasedScorer(tushare_token)
        self.selector = EnhancedStockSelector()

    def _clean_factors(self, factor_cols: List[str]) -> List[str]:
        """ğŸ”§ ä¿®å¤ï¼šå› å­æ¸…æ´—"""
        cleaned = factor_cols.copy()

        # ç§»é™¤å…±çº¿æ€§å› å­
        if self.remove_collinear:
            collinear = ['pb_ratio', 'ps_ratio']  # åªä¿ç•™pe_ratio
            cleaned = [f for f in cleaned if f not in collinear]
            if any(c in factor_cols for c in collinear):
                print(f"  âœ‚ï¸  ç§»é™¤å…±çº¿æ€§å› å­: {[c for c in collinear if c in factor_cols]}")

        # ç§»é™¤å¼±å› å­
        if self.remove_weak_factors:
            weak = ['roe', 'roa', 'net_profit_margin', 'gross_profit_margin']
            cleaned = [f for f in cleaned if f not in weak]
            if any(w in factor_cols for w in weak):
                print(f"  âœ‚ï¸  ç§»é™¤å¼±å› å­: {[w for w in weak if w in factor_cols]}")

        print(f"  âœ“ å› å­æ¸…æ´—å®Œæˆ: {len(factor_cols)} -> {len(cleaned)}")
        return cleaned

    def run(self, factor_data, price_data, factor_cols, min_score=0.7, max_stocks=30):
        print("=" * 60 + "\n  å¤šå› å­MLç­–ç•¥å¯åŠ¨ (ä¿®å¤ç‰ˆ)\n" + "=" * 60)

        # ğŸ”§ ä¿®å¤ï¼šå› å­æ¸…æ´—
        factor_cols = self._clean_factors(factor_cols)

        # 1. ICåˆ†æ & æƒé‡
        ic_res = self.ic_calc.calculate_factor_ic(factor_data, price_data, factor_cols)
        weights = self.ic_calc.get_ic_weights(ic_res, self.target_period)

        # 2. åŸºç¡€è¯„åˆ†
        processed = self.ranker.preprocess_factors(factor_data, factor_cols)
        scored = self.ranker.calculate_composite_score(processed, factor_cols, weights)

        # ğŸ”§ ä¿®å¤ï¼šè®­ç»ƒå‰æ¸…ç†æ±¡æŸ“åˆ—
        clean_cols = ['ml_score', 'position', 'score_rank', 'composite_score']
        clean_data = scored.drop(columns=[c for c in clean_cols if c in scored.columns], errors='ignore')

        # 3. MLå¢å¼º
        X, y, merged = self.ml.prepare_training_data(clean_data, price_data, factor_cols)
        self.ml.train_walk_forward(X, y, merged)
        ml_scored = self.ml.predict_scores(merged)

        # 4. è¡Œä¸šå¢å¼º
        ind_scored = self.ind_scorer.score_by_industry(ml_scored)
        self.ind_scorer.analyze_industry_rotation(ind_scored)

        # 5. é€‰è‚¡ & å›æµ‹
        picks = self.selector.select_stocks(ind_scored, min_score=min_score, max_stocks=max_stocks)
        backtest = SimpleBacktester.backtest(picks, price_data, self.target_period)

        # ç‰¹å¾é‡è¦æ€§
        imp = self.ml.get_feature_importance()
        if imp is not None:
            print("\n  ğŸ”‘ Top 10 é‡è¦ç‰¹å¾:")
            print(imp.head(10).to_string(index=False))

        return {'picks': picks, 'backtest': backtest, 'feature_importance': imp}


# ============================================================================
# ç¬¬å…­éƒ¨åˆ†ï¼šæµ‹è¯•æ•°æ®ç”Ÿæˆä¸éªŒè¯
# ============================================================================

def generate_sample_data(n_stocks=50, n_days=200):
    """ç”Ÿæˆæµ‹è¯•æ•°æ®"""
    print(f"\nğŸ² ç”Ÿæˆéšæœºæµ‹è¯•æ•°æ® ({n_stocks}åªè‚¡ç¥¨, {n_days}å¤©)...")
    dates = [datetime(2023, 1, 1) + timedelta(days=i) for i in range(n_days)]
    instruments = [f"000{i:03d}.SZ" for i in range(n_stocks)]

    records = []
    prices = []

    for date in dates:
        for inst in instruments:
            rec = {'date': date, 'instrument': inst}
            # ç”Ÿæˆå„ç±»å› å­
            for i in range(5):
                rec[f'factor_{i}'] = np.random.randn()
            # æ·»åŠ ä¼°å€¼å› å­ï¼ˆæ¨¡æ‹Ÿï¼‰
            rec['pe_ratio'] = np.random.uniform(5, 50)
            # æ·»åŠ åŠ¨é‡å› å­
            rec['momentum_20d'] = np.random.randn() * 0.1
            records.append(rec)

            # ä»·æ ¼æ•°æ®
            prices.append({
                'date': date,
                'instrument': inst,
                'close': 100 * (1 + np.random.randn() * 0.02)
            })

    return pd.DataFrame(records), pd.DataFrame(prices)


def validate_no_leakage(strategy_results: Dict):
    """éªŒè¯æ˜¯å¦å­˜åœ¨æ•°æ®æ³„éœ²"""
    print("\nğŸ” æ•°æ®æ³„éœ²éªŒè¯...")
    imp = strategy_results.get('feature_importance')

    if imp is not None:
        leaked = imp[imp['feature'].str.contains('position|ml_score|score_rank', case=False, na=False)]
        if len(leaked) > 0:
            print(f"  âš ï¸  è­¦å‘Šï¼šæ£€æµ‹åˆ°å¯ç–‘ç‰¹å¾: {leaked['feature'].tolist()}")
            return False
        else:
            print(f"  âœ… éªŒè¯é€šè¿‡ï¼šæœªæ£€æµ‹åˆ°æ³„éœ²åˆ—")
            return True
    return None


if __name__ == '__main__':
    print("\n" + "=" * 60)
    print("  æœºå™¨å­¦ä¹ å› å­è¯„åˆ†ç³»ç»Ÿ - ä¿®å¤ç‰ˆæ¼”ç¤º")
    print("=" * 60)

    # ç”Ÿæˆæµ‹è¯•æ•°æ®
    factors, prices = generate_sample_data(n_stocks=50, n_days=200)

    # å› å­åˆ—è¡¨
    cols = [f'factor_{i}' for i in range(5)] + ['pe_ratio', 'momentum_20d']

    # è¿è¡Œç­–ç•¥ï¼ˆå¯ç”¨å› å­æ¸…æ´—ï¼‰
    strategy = MultiFactorMLStrategy(
        model_type='xgboost',
        train_months=3,
        remove_collinear=True,  # ç§»é™¤å…±çº¿æ€§å› å­
        remove_weak_factors=False  # ä¿ç•™åŸºæœ¬é¢å› å­ï¼ˆæµ‹è¯•ç”¨ï¼‰
    )

    results = strategy.run(factors, prices, cols, min_score=0.6, max_stocks=20)

    # éªŒè¯
    validate_no_leakage(results)

    print("\n" + "=" * 60)
    print("  âœ… æ¼”ç¤ºå®Œæˆ")
    print("=" * 60)
    print("\nğŸ’¡ å…³é”®ä¿®å¤ç‚¹:")
    print("  1. prepare_training_data() ä¸¥æ ¼æ’é™¤é¢„æµ‹åˆ—")
    print("  2. predict_scores() ç‹¬ç«‹å­˜å‚¨ç»“æœï¼Œä¸æ±¡æŸ“è®­ç»ƒæ•°æ®")
    print("  3. æ·»åŠ æ–­è¨€éªŒè¯ï¼Œé˜²æ­¢positionç­‰åˆ—æ³„éœ²")
    print("  4. è‡ªåŠ¨æ¸…æ´—å…±çº¿æ€§å’Œå¼±å› å­")
    print("  5. XGBoost 2.0+ å…¼å®¹æ€§ä¿®å¤")