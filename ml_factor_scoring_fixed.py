"""
ml_factor_scoring_fixed.py - é«˜çº§æœºå™¨å­¦ä¹ å› å­è¯„åˆ†æ¨¡å—ï¼ˆä¿®å¤ç‰ˆï¼‰

æ ¸å¿ƒä¼˜åŒ–ï¼š
âœ… 1. æ—¶é—´åºåˆ—åˆ‡åˆ†ï¼ˆé¿å…å‰è§†åå·®ï¼‰
âœ… 2. åˆ†ç±»ç›®æ ‡ï¼ˆé¢„æµ‹TOP 20%ï¼‰
âœ… 3. ICåŠ æƒ - å› å­æœ‰æ•ˆæ€§åŠ¨æ€è¯„ä¼°
âœ… 4. æ»šåŠ¨è®­ç»ƒ - è‡ªé€‚åº”å¸‚åœºå˜åŒ–
âœ… 5. Tushareè¡Œä¸šæ•°æ®é›†æˆ
"""

import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings('ignore')

# æœºå™¨å­¦ä¹ åº“
try:
    import xgboost as xgb
    XGBOOST_AVAILABLE = True
except ImportError:
    print("âš ï¸  XGBoost æœªå®‰è£…ï¼Œè¿è¡Œ: pip install xgboost")
    xgb = None
    XGBOOST_AVAILABLE = False

try:
    import lightgbm as lgb
    LIGHTGBM_AVAILABLE = True
except ImportError:
    print("âš ï¸  LightGBM æœªå®‰è£…ï¼Œè¿è¡Œ: pip install lightgbm")
    lgb = None
    LIGHTGBM_AVAILABLE = False

from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, roc_auc_score


# ============================================================================
# æ ¸å¿ƒä¼˜åŒ–1: ICè®¡ç®—å™¨
# ============================================================================

class ICCalculator:
    """
    å› å­ICï¼ˆä¿¡æ¯ç³»æ•°ï¼‰è®¡ç®—å™¨

    IC = å› å­å€¼ä¸æœªæ¥æ”¶ç›Šçš„ç›¸å…³æ€§
    ICIR = ICçš„å‡å€¼ / ICçš„æ ‡å‡†å·®ï¼ˆå¤æ™®æ¯”ç‡çš„å› å­ç‰ˆï¼‰
    """

    def __init__(self, forward_periods=[5, 10, 20]):
        """
        :param forward_periods: è®¡ç®—ICçš„æœªæ¥å‘¨æœŸåˆ—è¡¨
        """
        self.forward_periods = forward_periods
        self.ic_history = {}  # {factor: {period: [ic_values]}}

    def calculate_factor_ic(self, factor_data, price_data, factor_columns):
        """
        è®¡ç®—æ‰€æœ‰å› å­çš„ICå€¼

        è¿”å›: {factor: {period: {'ic': float, 'icir': float}}}
        """
        print("\nğŸ“Š è®¡ç®—å› å­IC...")

        # æ£€æµ‹ä»·æ ¼åˆ—
        price_col = self._detect_price_column(price_data)
        if price_col is None:
            print("  âš ï¸  æœªæ‰¾åˆ°ä»·æ ¼åˆ—ï¼Œè·³è¿‡ICè®¡ç®—")
            return {}

        # åˆå¹¶æ•°æ®
        merged = factor_data.merge(
            price_data[['instrument', 'date', price_col]],
            on=['instrument', 'date'],
            how='left'
        )

        merged = merged.sort_values(['instrument', 'date'])

        # è®¡ç®—ä¸åŒå‘¨æœŸçš„æœªæ¥æ”¶ç›Š
        for period in self.forward_periods:
            merged[f'future_return_{period}d'] = merged.groupby('instrument')[price_col].pct_change(
                period
            ).shift(-period)

        ic_results = {}

        for factor in factor_columns:
            if factor not in merged.columns:
                continue

            ic_results[factor] = {}

            for period in self.forward_periods:
                return_col = f'future_return_{period}d'

                # æŒ‰æ—¥æœŸåˆ†ç»„è®¡ç®—IC
                daily_ic = []
                for date in merged['date'].unique():
                    date_data = merged[merged['date'] == date]

                    # è¿‡æ»¤æœ‰æ•ˆæ•°æ®
                    valid_data = date_data[[factor, return_col]].dropna()

                    if len(valid_data) < 10:  # è‡³å°‘10ä¸ªæ ·æœ¬
                        continue

                    # è®¡ç®—ç›¸å…³æ€§
                    ic = valid_data[factor].corr(valid_data[return_col])

                    if not np.isnan(ic):
                        daily_ic.append(ic)

                if len(daily_ic) > 0:
                    ic_mean = np.mean(daily_ic)
                    ic_std = np.std(daily_ic)
                    icir = ic_mean / ic_std if ic_std > 0 else 0

                    ic_results[factor][period] = {
                        'ic': ic_mean,
                        'icir': icir,
                        'ic_std': ic_std,
                        'sample_days': len(daily_ic)
                    }

                    # è®°å½•å†å²
                    if factor not in self.ic_history:
                        self.ic_history[factor] = {}
                    self.ic_history[factor][period] = daily_ic

        # æ‰“å°ICç»Ÿè®¡
        self._print_ic_summary(ic_results)

        return ic_results

    def _detect_price_column(self, df):
        """æ£€æµ‹ä»·æ ¼åˆ—"""
        candidates = ['close', 'Close', 'CLOSE', 'price', 'Price']
        for col in candidates:
            if col in df.columns:
                return col
        return None

    def _print_ic_summary(self, ic_results):
        """æ‰“å°ICç»Ÿè®¡"""
        print(f"\n  ğŸ“ˆ å› å­ICç»Ÿè®¡:")
        print(f"  {'å› å­':<20s} | {'IC(5æ—¥)':<10s} | {'IC(10æ—¥)':<10s} | {'IC(20æ—¥)':<10s} | {'ICIR(5æ—¥)':<10s}")
        print(f"  {'-'*80}")

        for factor, periods in ic_results.items():
            ic_5 = periods.get(5, {}).get('ic', 0)
            ic_10 = periods.get(10, {}).get('ic', 0)
            ic_20 = periods.get(20, {}).get('ic', 0)
            icir_5 = periods.get(5, {}).get('icir', 0)

            print(f"  {factor:<20s} | {ic_5:>9.4f} | {ic_10:>9.4f} | {ic_20:>9.4f} | {icir_5:>9.4f}")

    def get_ic_weights(self, ic_results, period=5):
        """
        æ ¹æ®ICè®¡ç®—å› å­æƒé‡

        æƒé‡ = abs(IC) / sum(abs(IC))
        """
        weights = {}
        total_ic = 0

        for factor, periods in ic_results.items():
            ic = periods.get(period, {}).get('ic', 0)
            weights[factor] = abs(ic)
            total_ic += abs(ic)

        if total_ic > 0:
            weights = {k: v/total_ic for k, v in weights.items()}

        return weights


# ============================================================================
# æ ¸å¿ƒä¼˜åŒ–2: æ—¶é—´åºåˆ—åˆ‡åˆ†å™¨
# ============================================================================

class TimeSeriesSplitter:
    """
    æ—¶é—´åºåˆ—æ•°æ®åˆ‡åˆ†å™¨

    ä½¿ç”¨Walk-Forwardæ–¹å¼ï¼š
    - è®­ç»ƒé›†ï¼šå†å²Nä¸ªæœˆ
    - éªŒè¯é›†ï¼šæ¥ä¸‹æ¥çš„1ä¸ªæœˆ
    - æµ‹è¯•é›†ï¼šå†æ¥ä¸‹æ¥çš„1ä¸ªæœˆ
    """

    def __init__(self, train_months=12, valid_months=1, test_months=1):
        self.train_months = train_months
        self.valid_months = valid_months
        self.test_months = test_months

    def split(self, data, date_column='date'):
        """
        æ—¶é—´åºåˆ—åˆ‡åˆ†

        è¿”å›: [(train_idx, valid_idx, test_idx), ...]
        """
        data = data.copy()
        data[date_column] = pd.to_datetime(data[date_column])
        data = data.sort_values(date_column)

        # æŒ‰æœˆåˆ†ç»„
        data['year_month'] = data[date_column].dt.to_period('M')
        months = sorted(data['year_month'].unique())

        splits = []

        # æ»šåŠ¨çª—å£
        for i in range(len(months) - self.train_months - self.valid_months - self.test_months + 1):
            train_end = i + self.train_months
            valid_end = train_end + self.valid_months
            test_end = valid_end + self.test_months

            train_months_list = months[i:train_end]
            valid_months_list = months[train_end:valid_end]
            test_months_list = months[valid_end:test_end]

            train_idx = data[data['year_month'].isin(train_months_list)].index
            valid_idx = data[data['year_month'].isin(valid_months_list)].index
            test_idx = data[data['year_month'].isin(test_months_list)].index

            if len(train_idx) > 0 and len(valid_idx) > 0 and len(test_idx) > 0:
                splits.append((train_idx, valid_idx, test_idx))

        return splits


# ============================================================================
# æ ¸å¿ƒä¼˜åŒ–3: é«˜çº§MLè¯„åˆ†å™¨
# ============================================================================

class AdvancedMLScorer:
    """
    é«˜çº§æœºå™¨å­¦ä¹ è¯„åˆ†å™¨

    æ•´åˆä¸‰å¤§ä¼˜åŒ–ï¼š
    1. æ—¶é—´åºåˆ—åˆ‡åˆ†ï¼ˆé¿å…å‰è§†åå·®ï¼‰
    2. åˆ†ç±»ç›®æ ‡ï¼ˆé¢„æµ‹TOPè‚¡ç¥¨ï¼‰
    3. ICåŠ æƒç‰¹å¾ï¼ˆå› å­æœ‰æ•ˆæ€§ï¼‰
    """

    def __init__(self,
                 model_type='xgboost',
                 target_period=5,
                 top_percentile=0.20,  # é¢„æµ‹TOP 20%
                 use_classification=True,
                 use_ic_features=True,
                 train_months=12,
                 random_state=42):
        """
        :param model_type: 'xgboost' æˆ– 'lightgbm'
        :param target_period: é¢„æµ‹å‘¨æœŸï¼ˆå¤©ï¼‰
        :param top_percentile: TOPè‚¡ç¥¨æ¯”ä¾‹
        :param use_classification: æ˜¯å¦ä½¿ç”¨åˆ†ç±»æ¨¡å‹
        :param use_ic_features: æ˜¯å¦ä½¿ç”¨ICä½œä¸ºç‰¹å¾
        :param train_months: è®­ç»ƒçª—å£ï¼ˆæœˆï¼‰
        """
        self.model_type = model_type
        self.target_period = target_period
        self.top_percentile = top_percentile
        self.use_classification = use_classification
        self.use_ic_features = use_ic_features
        self.train_months = train_months
        self.random_state = random_state

        self.model = None
        self.scaler = StandardScaler()
        self.feature_names = None
        self.ic_calculator = ICCalculator([target_period])
        self.ic_weights = {}

        print(f"\nğŸš€ åˆå§‹åŒ–é«˜çº§MLè¯„åˆ†å™¨")
        print(f"  æ¨¡å‹ç±»å‹: {model_type.upper()}")
        print(f"  ç›®æ ‡æ¨¡å¼: {'åˆ†ç±»' if use_classification else 'å›å½’'}")
        print(f"  é¢„æµ‹ç›®æ ‡: {'TOP ' + str(int(top_percentile*100)) + '%' if use_classification else f'{target_period}æ—¥æ”¶ç›Šç‡'}")
        print(f"  ICç‰¹å¾: {'å¯ç”¨' if use_ic_features else 'å…³é—­'}")
        print(f"  è®­ç»ƒçª—å£: {train_months}ä¸ªæœˆ")

    def prepare_training_data(self, factor_data, price_data, factor_columns):
        """
        å‡†å¤‡è®­ç»ƒæ•°æ®

        âœ… ä¼˜åŒ–1: é¿å…å‰è§†åå·®
        âœ… ä¼˜åŒ–2: åˆ†ç±»ç›®æ ‡
        âœ… ä¼˜åŒ–3: ICç‰¹å¾
        """
        print(f"\nğŸ“¦ å‡†å¤‡è®­ç»ƒæ•°æ®...")

        # æ£€æµ‹ä»·æ ¼åˆ—
        price_col = self._detect_price_column(price_data)
        if price_col is None:
            raise ValueError("æœªæ‰¾åˆ°ä»·æ ¼åˆ—")

        # åˆå¹¶æ•°æ®
        merged = factor_data.merge(
            price_data[['instrument', 'date', price_col]],
            on=['instrument', 'date'],
            how='left'
        )

        merged = merged.sort_values(['instrument', 'date'])

        # ===== ä¼˜åŒ–1: è®¡ç®—IC =====
        if self.use_ic_features:
            print("  âœ“ è®¡ç®—å› å­IC...")
            ic_results = self.ic_calculator.calculate_factor_ic(
                factor_data, price_data, factor_columns
            )
            self.ic_weights = self.ic_calculator.get_ic_weights(ic_results, self.target_period)

            # æ·»åŠ ICä½œä¸ºç‰¹å¾
            for factor in factor_columns:
                if factor in ic_results:
                    ic_value = ic_results[factor].get(self.target_period, {}).get('ic', 0)
                    merged[f'{factor}_ic'] = ic_value

        # ===== ä¼˜åŒ–2: è®¡ç®—ç›®æ ‡å˜é‡ =====
        print(f"  âœ“ è®¡ç®—æœªæ¥{self.target_period}æ—¥æ”¶ç›Š...")
        merged['future_return'] = merged.groupby('instrument')[price_col].pct_change(
            self.target_period
        ).shift(-self.target_period)

        if self.use_classification:
            # åˆ†ç±»ç›®æ ‡ï¼šæ¯å¤©TOP 20%çš„è‚¡ç¥¨æ ‡è®°ä¸º1
            print(f"  âœ“ è½¬æ¢ä¸ºåˆ†ç±»ç›®æ ‡ (TOP {self.top_percentile:.0%})...")
            merged['target'] = 0

            for date in merged['date'].unique():
                date_mask = merged['date'] == date
                returns = merged.loc[date_mask, 'future_return']
                threshold = returns.quantile(1 - self.top_percentile)
                merged.loc[date_mask & (merged['future_return'] >= threshold), 'target'] = 1

            target_col = 'target'
        else:
            target_col = 'future_return'

        # è¿‡æ»¤æœ‰æ•ˆæ•°æ®
        initial_len = len(merged)
        merged = merged.dropna(subset=[target_col])
        print(f"  âœ“ æœ‰æ•ˆæ ·æœ¬: {len(merged)} / {initial_len} ({len(merged)/initial_len*100:.1f}%)")

        if self.use_classification:
            pos_rate = merged['target'].mean()
            print(f"  âœ“ æ­£æ ·æœ¬æ¯”ä¾‹: {pos_rate:.2%}")

        # ===== æ„å»ºç‰¹å¾ =====
        base_exclude = [
            'date', 'instrument', 'future_return', 'target', price_col,
            'industry', 'ml_score', 'industry_rank', 'year_month'
        ]

        all_cols = merged.columns.tolist()
        feature_cols = [col for col in all_cols if col not in base_exclude]

        # å¤„ç†åªæœ‰positionçš„æƒ…å†µ
        if len(feature_cols) == 0 and 'position' in merged.columns:
            feature_cols = ['position']

        print(f"  âœ“ ç‰¹å¾æ•°é‡: {len(feature_cols)}")

        X = merged[feature_cols].copy()
        X = X.replace([np.inf, -np.inf], np.nan).fillna(X.median())
        y = merged[target_col].values

        self.feature_names = feature_cols

        return X, y, merged

    def train_walk_forward(self, X, y, merged, verbose=True):
        """
        âœ… Walk-Forwardè®­ç»ƒï¼ˆé¿å…å‰è§†åå·®ï¼‰

        ä½¿ç”¨æ»šåŠ¨çª—å£ï¼š
        - æ¯æ¬¡ç”¨è¿‡å»12ä¸ªæœˆè®­ç»ƒ
        - åœ¨ä¸‹1ä¸ªæœˆéªŒè¯
        - ä¿å­˜æœ€ä½³æ¨¡å‹
        """
        print(f"\nğŸ¯ Walk-Forwardè®­ç»ƒ...")

        # æ—¶é—´åºåˆ—åˆ‡åˆ†
        splitter = TimeSeriesSplitter(
            train_months=self.train_months,
            valid_months=1,
            test_months=1
        )

        splits = splitter.split(merged, date_column='date')

        if len(splits) == 0:
            print("  âš ï¸  æ•°æ®ä¸è¶³ä»¥è¿›è¡Œæ—¶é—´åºåˆ—åˆ‡åˆ†ï¼Œä½¿ç”¨ç®€å•åˆ‡åˆ†")
            return self._train_simple(X, y, verbose)

        print(f"  âœ“ ç”Ÿæˆäº† {len(splits)} ä¸ªæ—¶é—´çª—å£")

        best_model = None
        best_score = -np.inf

        for i, (train_idx, valid_idx, test_idx) in enumerate(splits):
            if i >= 1:  # åªè®­ç»ƒæœ€åä¸€ä¸ªçª—å£ï¼ˆæœ€æ–°æ•°æ®ï¼‰
                continue

            X_train = X.iloc[train_idx]
            y_train = y[train_idx]
            X_valid = X.iloc[valid_idx]
            y_valid = y[valid_idx]

            print(f"\n  çª—å£ {i+1}/{len(splits)}:")
            print(f"    è®­ç»ƒ: {len(X_train)} æ ·æœ¬")
            print(f"    éªŒè¯: {len(X_valid)} æ ·æœ¬")

            # æ ‡å‡†åŒ–
            X_train_scaled = self.scaler.fit_transform(X_train)
            X_valid_scaled = self.scaler.transform(X_valid)

            # è®­ç»ƒæ¨¡å‹
            if self.use_classification:
                model = self._train_classifier(
                    X_train_scaled, y_train,
                    X_valid_scaled, y_valid,
                    verbose=False
                )

                # è¯„ä¼°
                y_pred_proba = model.predict_proba(X_valid_scaled)[:, 1]
                score = roc_auc_score(y_valid, y_pred_proba)
                print(f"    éªŒè¯AUC: {score:.4f}")
            else:
                model = self._train_regressor(
                    X_train_scaled, y_train,
                    X_valid_scaled, y_valid,
                    verbose=False
                )

                # è¯„ä¼°
                y_pred = model.predict(X_valid_scaled)
                score = np.corrcoef(y_valid, y_pred)[0, 1]
                print(f"    éªŒè¯ç›¸å…³æ€§: {score:.4f}")

            if score > best_score:
                best_score = score
                best_model = model

        self.model = best_model
        print(f"\n  âœ“ æœ€ä½³æ¨¡å‹éªŒè¯å¾—åˆ†: {best_score:.4f}")

        return self

    def _train_simple(self, X, y, verbose):
        """ç®€å•è®­ç»ƒï¼ˆæ•°æ®ä¸è¶³æ—¶ä½¿ç”¨ï¼‰"""
        from sklearn.model_selection import train_test_split

        X_train, X_valid, y_train, y_valid = train_test_split(
            X, y, test_size=0.2, random_state=self.random_state
        )

        X_train_scaled = self.scaler.fit_transform(X_train)
        X_valid_scaled = self.scaler.transform(X_valid)

        if self.use_classification:
            self.model = self._train_classifier(
                X_train_scaled, y_train,
                X_valid_scaled, y_valid,
                verbose
            )
        else:
            self.model = self._train_regressor(
                X_train_scaled, y_train,
                X_valid_scaled, y_valid,
                verbose
            )

        return self

    def _train_classifier(self, X_train, y_train, X_valid, y_valid, verbose):
        """è®­ç»ƒåˆ†ç±»å™¨"""
        if self.model_type == 'xgboost':
            if not XGBOOST_AVAILABLE:
                raise ImportError("XGBoost æœªå®‰è£…")

            params = {
                'objective': 'binary:logistic',
                'eval_metric': 'auc',
                'max_depth': 6,
                'learning_rate': 0.05,
                'n_estimators': 200,
                'subsample': 0.8,
                'colsample_bytree': 0.8,
                'random_state': self.random_state,
                'n_jobs': -1
            }

            model = xgb.XGBClassifier(**params)

            try:
                model.fit(
                    X_train, y_train,
                    eval_set=[(X_valid, y_valid)],
                    early_stopping_rounds=20,
                    verbose=verbose
                )
            except:
                model.fit(X_train, y_train)

            return model

        elif self.model_type == 'lightgbm':
            if not LIGHTGBM_AVAILABLE:
                raise ImportError("LightGBM æœªå®‰è£…")

            params = {
                'objective': 'binary',
                'metric': 'auc',
                'max_depth': 6,
                'learning_rate': 0.05,
                'n_estimators': 200,
                'subsample': 0.8,
                'colsample_bytree': 0.8,
                'random_state': self.random_state,
                'n_jobs': -1,
                'verbose': -1
            }

            model = lgb.LGBMClassifier(**params)

            try:
                model.fit(
                    X_train, y_train,
                    eval_set=[(X_valid, y_valid)],
                    callbacks=[lgb.early_stopping(20, verbose=verbose)]
                )
            except:
                model.fit(X_train, y_train)

            return model

    def _train_regressor(self, X_train, y_train, X_valid, y_valid, verbose):
        """è®­ç»ƒå›å½’å™¨"""
        if self.model_type == 'xgboost':
            if not XGBOOST_AVAILABLE:
                raise ImportError("XGBoost æœªå®‰è£…")

            params = {
                'objective': 'reg:squarederror',
                'max_depth': 6,
                'learning_rate': 0.05,
                'n_estimators': 200,
                'subsample': 0.8,
                'colsample_bytree': 0.8,
                'random_state': self.random_state,
                'n_jobs': -1
            }

            model = xgb.XGBRegressor(**params)

            try:
                model.fit(
                    X_train, y_train,
                    eval_set=[(X_valid, y_valid)],
                    early_stopping_rounds=20,
                    verbose=verbose
                )
            except:
                model.fit(X_train, y_train)

            return model

    def _detect_price_column(self, df):
        """æ£€æµ‹ä»·æ ¼åˆ—"""
        candidates = ['close', 'Close', 'CLOSE', 'price', 'Price']
        for col in candidates:
            if col in df.columns:
                return col
        return None

    def predict_scores(self, factor_data, price_data=None, factor_columns=None):
        """é¢„æµ‹è¯„åˆ†"""
        if price_data is not None:
            X, y, merged = self.prepare_training_data(factor_data, price_data, factor_columns)
            self.train_walk_forward(X, y, merged, verbose=False)
            factor_data = merged.copy()

        if self.model is None:
            raise ValueError("æ¨¡å‹æœªè®­ç»ƒ")

        print(f"\nğŸ¯ é¢„æµ‹è‚¡ç¥¨è¯„åˆ†...")

        X = factor_data[self.feature_names].copy()
        X = X.replace([np.inf, -np.inf], np.nan).fillna(X.median())

        X_scaled = self.scaler.transform(X)

        if self.use_classification:
            # é¢„æµ‹æ¦‚ç‡
            predicted_proba = self.model.predict_proba(X_scaled)[:, 1]
            factor_data['ml_score'] = predicted_proba
        else:
            # é¢„æµ‹æ”¶ç›Šç‡
            predicted_returns = self.model.predict(X_scaled)
            factor_data['ml_score'] = predicted_returns

        # æ ‡å‡†åŒ–åˆ°0-1
        factor_data['position'] = factor_data.groupby('date')['ml_score'].rank(pct=True)

        print(f"  âœ“ é¢„æµ‹å®Œæˆ")
        print(f"  âœ“ å¹³å‡è¯„åˆ†: {factor_data['ml_score'].mean():.4f}")
        print(f"  âœ“ è¯„åˆ†æ ‡å‡†å·®: {factor_data['ml_score'].std():.4f}")

        return factor_data


# ============================================================================
# è¡Œä¸šæ•°æ®è·å–ï¼ˆä¿®å¤ç‰ˆ - ä½¿ç”¨ Tushare stock_basicï¼‰
# ============================================================================

def get_industry_data(instruments, tushare_token=None):
    """
    è·å–è¡Œä¸šæ•°æ® - ä½¿ç”¨ Tushare stock_basicï¼ˆæœ€ç®€å•æœ€å¿«ï¼‰

    Args:
        instruments: è‚¡ç¥¨ä»£ç åˆ—è¡¨
        tushare_token: Tushare token

    Returns:
        DataFrame: [instrument, industry]
    """
    if tushare_token is None:
        print("  âš ï¸  æœªæä¾› Tushare Token")
        return pd.DataFrame({
            'instrument': instruments,
            'industry': 'Unknown'
        })

    try:
        import tushare as ts
        ts.set_token(tushare_token)
        pro = ts.pro_api()

        print(f"  ğŸ“Š è·å– {len(instruments)} åªè‚¡ç¥¨çš„è¡Œä¸šæ•°æ®...")

        # âœ… ä½¿ç”¨ stock_basic è·å–ç”³ä¸‡è¡Œä¸šï¼ˆä¸€æ¬¡è°ƒç”¨è·å–æ‰€æœ‰ï¼‰
        stock_basic = pro.stock_basic(
            exchange='',
            list_status='L',
            fields='ts_code,name,industry'  # industryæ˜¯ç”³ä¸‡ä¸€çº§è¡Œä¸š
        )

        # è¿‡æ»¤ç›®æ ‡è‚¡ç¥¨
        stock_basic = stock_basic[stock_basic['ts_code'].isin(instruments)]
        stock_basic['instrument'] = stock_basic['ts_code']
        stock_basic['industry'] = stock_basic['industry'].fillna('å…¶ä»–')

        result = stock_basic[['instrument', 'industry']]

        # è¡¥å……æœªåŒ¹é…çš„è‚¡ç¥¨
        missing = set(instruments) - set(result['instrument'])
        if missing:
            print(f"  âš ï¸  {len(missing)} åªè‚¡ç¥¨æœªæ‰¾åˆ°è¡Œä¸šï¼Œæ ‡è®°ä¸º'å…¶ä»–'")
            missing_df = pd.DataFrame({
                'instrument': list(missing),
                'industry': 'å…¶ä»–'
            })
            result = pd.concat([result, missing_df], ignore_index=True)

        print(f"  âœ“ è·å–åˆ° {len(result)} åªè‚¡ç¥¨çš„è¡Œä¸šä¿¡æ¯")
        print(f"  âœ“ è¦†ç›–ç‡: {(len(result) - len(missing))/len(instruments)*100:.1f}%")
        print(f"  âœ“ è¡Œä¸šåˆ†ç±»: {result['industry'].nunique()} ä¸ª")

        # æ˜¾ç¤ºTOP5è¡Œä¸š
        top_industries = result['industry'].value_counts().head(5)
        print(f"\n  ğŸ“Š TOP5è¡Œä¸š:")
        for industry, count in top_industries.items():
            print(f"     {industry}: {count}åª")

        return result

    except Exception as e:
        print(f"  âš ï¸  è·å–è¡Œä¸šæ•°æ®å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return pd.DataFrame({
            'instrument': instruments,
            'industry': 'Unknown'
        })


class IndustryBasedScorer:
    """åˆ†è¡Œä¸šè¯„åˆ†å™¨"""

    def __init__(self, tushare_token=None):
        self.tushare_token = tushare_token

    def score_by_industry(self, factor_data, factor_columns=None):
        """åˆ†è¡Œä¸šè¯„åˆ†"""
        print("\nğŸ¢ åˆ†è¡Œä¸šè¯„åˆ†...")

        instruments = factor_data['instrument'].unique()
        industry_data = get_industry_data(instruments, self.tushare_token)

        if 'industry' in factor_data.columns:
            factor_data = factor_data.drop(columns=['industry'])

        factor_data = factor_data.merge(industry_data, on='instrument', how='left')
        factor_data['industry'] = factor_data['industry'].fillna('Unknown')

        try:
            factor_data['industry_rank'] = factor_data.groupby(['date', 'industry'])['position'].rank(pct=True)
            print(f"  âœ“ è¡Œä¸šè¯„åˆ†å®Œæˆ")

            # ç»Ÿè®¡è¡Œä¸šåˆ†å¸ƒ
            industry_dist = factor_data.groupby('industry')['instrument'].nunique()
            print(f"\n  ğŸ“Š è¡Œä¸šåˆ†å¸ƒ (è‚¡ç¥¨æ•°):")
            for industry, count in industry_dist.head(10).items():
                print(f"     {industry}: {count}åª")

        except Exception as e:
            print(f"  âš ï¸  è¡Œä¸šè¯„åˆ†å¤±è´¥: {e}")
            factor_data['industry_rank'] = factor_data['position']

        return factor_data


class EnhancedStockSelector:
    """å¢å¼ºé€‰è‚¡å™¨"""

    def select_stocks(self, factor_data, min_score=0.6, max_concentration=0.15, max_industry_concentration=0.3):
        """é€‰è‚¡"""
        print(f"\nğŸ¯ å¢å¼ºé€‰è‚¡ (é˜ˆå€¼: {min_score})...")

        filtered = factor_data[factor_data['position'] >= min_score].copy()
        print(f"  âœ“ è¯„åˆ†è¿‡æ»¤: {len(filtered)} / {len(factor_data)} åªè‚¡ç¥¨")

        if 'industry' not in filtered.columns:
            filtered['industry'] = 'Unknown'

        filtered['industry'] = filtered['industry'].fillna('Unknown')

        return filtered


# å¯¼å‡º
__all__ = [
    'AdvancedMLScorer',
    'ICCalculator',
    'TimeSeriesSplitter',
    'IndustryBasedScorer',
    'EnhancedStockSelector',
    'get_industry_data'
]
