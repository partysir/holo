"""
ml_factor_scoring_ultra.py - è¶…çº§ä¼˜åŒ–ç‰ˆï¼ˆæé«˜å®ç›˜èƒœç‡ï¼‰

ğŸ¯ å››å¤§æ ¸å¿ƒä¼˜åŒ–ï¼š
âœ… 1. æ•°æ®éš”ç¦» (Purging & Embargoing) - æ¶ˆé™¤ä¿¡æ¯æ³„éœ²
âœ… 2. ç‰¹å¾æ­£äº¤åŒ– (Feature Orthogonalization) - æå–çº¯Alpha
âœ… 3. æ¨¡å‹é›†æˆ (Ensemble Voting) - é™ä½è¿‡æ‹Ÿåˆ
âœ… 4. ç²¾å‡†ç›®æ ‡ (Precision@K Focus) - ä¼˜åŒ–Topé€‰è‚¡
"""

import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings('ignore')

try:
    import xgboost as xgb
    XGBOOST_AVAILABLE = True
except ImportError:
    xgb = None
    XGBOOST_AVAILABLE = False

try:
    import lightgbm as lgb
    LIGHTGBM_AVAILABLE = True
except ImportError:
    lgb = None
    LIGHTGBM_AVAILABLE = False

from sklearn.preprocessing import StandardScaler
from sklearn.metrics import roc_auc_score, precision_score, recall_score
from sklearn.linear_model import LinearRegression


# ============================================================================
# ä¼˜åŒ–1: æ•°æ®éš”ç¦»å™¨ (Purging & Embargoing)
# ============================================================================

class PurgingEmbargoSplitter:
    """
    æ•°æ®éš”ç¦»åˆ‡åˆ†å™¨

    æ ¸å¿ƒæ€æƒ³ï¼š
    - Purging: åˆ é™¤è®­ç»ƒé›†æœ«å°¾ä¸éªŒè¯é›†æœ‰é‡å çš„æ ·æœ¬
    - Embargo: åœ¨è®­ç»ƒé›†å’ŒéªŒè¯é›†ä¹‹é—´åŠ å…¥Gapï¼ˆéš”ç¦»æœŸï¼‰

    ç¤ºä¾‹ï¼š
        é¢„æµ‹5æ—¥æ”¶ç›Šï¼Œéœ€è¦5æ—¥Gap
        Train: [æœˆ1-12] -> Gap: [12æœˆæœ«5å¤©] -> Valid: [æœˆ13]
    """

    def __init__(self, train_months=12, valid_months=1, test_months=1,
                 embargo_days=5):
        """
        Args:
            embargo_days: éš”ç¦»æœŸï¼ˆå¤©ï¼‰- åº”è¯¥ >= é¢„æµ‹å‘¨æœŸ
        """
        self.train_months = train_months
        self.valid_months = valid_months
        self.test_months = test_months
        self.embargo_days = embargo_days

    def split(self, data, date_column='date'):
        """æ—¶é—´åºåˆ—åˆ‡åˆ† + æ•°æ®éš”ç¦»"""
        data = data.copy()
        data[date_column] = pd.to_datetime(data[date_column])
        data = data.sort_values(date_column)

        data['year_month'] = data[date_column].dt.to_period('M')
        months = sorted(data['year_month'].unique())

        splits = []

        for i in range(len(months) - self.train_months - self.valid_months - self.test_months + 1):
            train_end = i + self.train_months
            valid_end = train_end + self.valid_months
            test_end = valid_end + self.test_months

            train_months_list = months[i:train_end]
            valid_months_list = months[train_end:valid_end]
            test_months_list = months[valid_end:test_end]

            # åˆå§‹ç´¢å¼•
            train_idx = data[data['year_month'].isin(train_months_list)].index
            valid_idx = data[data['year_month'].isin(valid_months_list)].index
            test_idx = data[data['year_month'].isin(test_months_list)].index

            # âœ… å…³é”®ä¼˜åŒ–ï¼šPurging + Embargo
            if self.embargo_days > 0 and len(train_idx) > 0 and len(valid_idx) > 0:
                # è·å–è®­ç»ƒé›†æœ€åä¸€å¤©
                train_last_date = data.loc[train_idx, date_column].max()

                # åˆ é™¤è®­ç»ƒé›†ä¸­ä¼šä¸éªŒè¯é›†é‡å çš„æ ·æœ¬
                # å³åˆ é™¤è®­ç»ƒé›†æœ€å embargo_days å¤©çš„æ•°æ®
                embargo_cutoff = train_last_date - pd.Timedelta(days=self.embargo_days)
                train_idx = train_idx[data.loc[train_idx, date_column] <= embargo_cutoff]

            if len(train_idx) > 0 and len(valid_idx) > 0 and len(test_idx) > 0:
                splits.append((train_idx, valid_idx, test_idx))

        return splits


# ============================================================================
# ä¼˜åŒ–2: ç‰¹å¾æ­£äº¤åŒ–å™¨ (Feature Orthogonalization)
# ============================================================================

class FeatureOrthogonalizer:
    """
    ç‰¹å¾æ­£äº¤åŒ– - æå–çº¯Alpha

    æ–¹æ³•ï¼š
    1. å¸‚åœºä¸­æ€§åŒ–ï¼šæ®‹å·® = å› å­ - Î²_market Ã— å¸‚åœºæ”¶ç›Š
    2. è¡Œä¸šä¸­æ€§åŒ–ï¼šæ®‹å·® = å› å­ - Î£(Î²_industry Ã— è¡Œä¸šå“‘å˜é‡)
    """

    def __init__(self, neutralize_market=True, neutralize_industry=True):
        self.neutralize_market = neutralize_market
        self.neutralize_industry = neutralize_industry
        self.market_models = {}  # {factor: LinearRegression}
        self.industry_models = {}

    def fit_transform(self, factor_data, factor_columns, price_data=None):
        """
        æ‹Ÿåˆå¹¶è½¬æ¢å› å­

        Args:
            factor_data: å› å­æ•°æ®ï¼ˆå¿…é¡»åŒ…å«date, instrumentï¼‰
            factor_columns: éœ€è¦ä¸­æ€§åŒ–çš„å› å­åˆ—è¡¨
            price_data: ä»·æ ¼æ•°æ®ï¼ˆç”¨äºè®¡ç®—å¸‚åœºæ”¶ç›Šï¼‰
        """
        print("\nğŸ”§ ç‰¹å¾æ­£äº¤åŒ–...")

        factor_data = factor_data.copy()

        # ===== 1. å¸‚åœºä¸­æ€§åŒ– =====
        if self.neutralize_market and price_data is not None:
            print("  âœ“ å¸‚åœºä¸­æ€§åŒ–...")
            factor_data = self._neutralize_market(
                factor_data, factor_columns, price_data
            )

        # ===== 2. è¡Œä¸šä¸­æ€§åŒ– =====
        if self.neutralize_industry and 'industry' in factor_data.columns:
            print("  âœ“ è¡Œä¸šä¸­æ€§åŒ–...")
            factor_data = self._neutralize_industry(
                factor_data, factor_columns
            )

        print("  âœ“ æ­£äº¤åŒ–å®Œæˆ")
        return factor_data

    def _neutralize_market(self, factor_data, factor_columns, price_data):
        """å¸‚åœºä¸­æ€§åŒ–"""
        # è®¡ç®—å¸‚åœºæ”¶ç›Šï¼ˆæ¯æ—¥å¹³å‡æ”¶ç›Šï¼‰
        price_col = self._detect_price_column(price_data)
        if price_col is None:
            return factor_data

        merged = factor_data.merge(
            price_data[['instrument', 'date', price_col]],
            on=['instrument', 'date'],
            how='left'
        )

        # æ¯æ—¥å¸‚åœºæ”¶ç›Š
        merged['daily_return'] = merged.groupby('instrument')[price_col].pct_change()
        market_return = merged.groupby('date')['daily_return'].transform('mean')

        # å¯¹æ¯ä¸ªå› å­å›å½’
        for factor in factor_columns:
            if factor not in merged.columns:
                continue

            # è¿‡æ»¤æœ‰æ•ˆæ•°æ®
            valid = merged[[factor, 'daily_return']].dropna()
            if len(valid) < 100:
                continue

            # å›å½’ï¼šfactor = Î± + Î² Ã— market_return + Îµ
            X = valid['daily_return'].values.reshape(-1, 1)
            y = valid[factor].values

            model = LinearRegression()
            model.fit(X, y)

            # æ®‹å·® = å› å­ - é¢„æµ‹å€¼
            merged.loc[valid.index, factor] = y - model.predict(X)

            self.market_models[factor] = model

        factor_data = merged.drop(columns=[price_col, 'daily_return'], errors='ignore')
        return factor_data

    def _neutralize_industry(self, factor_data, factor_columns):
        """è¡Œä¸šä¸­æ€§åŒ–"""
        # åˆ›å»ºè¡Œä¸šå“‘å˜é‡
        industry_dummies = pd.get_dummies(
            factor_data['industry'],
            prefix='ind',
            drop_first=True  # é¿å…å®Œå…¨å…±çº¿æ€§
        )

        for factor in factor_columns:
            if factor not in factor_data.columns:
                continue

            # è¿‡æ»¤æœ‰æ•ˆæ•°æ®
            valid_idx = factor_data[factor].notna()
            if valid_idx.sum() < 100:
                continue

            X = industry_dummies.loc[valid_idx]
            y = factor_data.loc[valid_idx, factor].values

            # å›å½’ï¼šfactor = Î£(Î²_i Ã— industry_i) + Îµ
            model = LinearRegression()
            model.fit(X, y)

            # æ®‹å·®
            factor_data.loc[valid_idx, factor] = y - model.predict(X)

            self.industry_models[factor] = model

        return factor_data

    def _detect_price_column(self, df):
        candidates = ['close', 'Close', 'CLOSE', 'price', 'Price']
        for col in candidates:
            if col in df.columns:
                return col
        return None


# ============================================================================
# ä¼˜åŒ–3: é›†æˆæŠ•ç¥¨å™¨ (Ensemble Voting)
# ============================================================================

class EnsembleVotingScorer:
    """
    é›†æˆæŠ•ç¥¨è¯„åˆ†å™¨

    ç­–ç•¥ï¼š
    - åŒæ—¶è®­ç»ƒ XGBoost å’Œ LightGBM
    - é¢„æµ‹æ—¶å–æ¦‚ç‡å‡å€¼
    - å¯é€‰ï¼šåªæœ‰ä¸¤ä¸ªæ¨¡å‹éƒ½çœ‹å¤šï¼ˆæ¦‚ç‡>0.5ï¼‰æ—¶æ‰ç»™é«˜åˆ†
    """

    def __init__(self, voting_strategy='average', strict_threshold=0.6):
        """
        Args:
            voting_strategy: 'average' | 'strict'
                - average: ç®€å•å¹³å‡ä¸¤ä¸ªæ¨¡å‹çš„é¢„æµ‹
                - strict: åªæœ‰ä¸¤ä¸ªæ¨¡å‹éƒ½çœ‹å¤šæ—¶æ‰ç»™é«˜åˆ†
            strict_threshold: strictæ¨¡å¼ä¸‹çš„é˜ˆå€¼
        """
        self.voting_strategy = voting_strategy
        self.strict_threshold = strict_threshold
        self.xgb_model = None
        self.lgb_model = None
        self.scaler = StandardScaler()

    def train(self, X_train, y_train, X_valid, y_valid, verbose=False):
        """è®­ç»ƒä¸¤ä¸ªæ¨¡å‹"""
        print(f"\nğŸ¤ é›†æˆè®­ç»ƒ ({self.voting_strategy})...")

        # æ ‡å‡†åŒ–
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_valid_scaled = self.scaler.transform(X_valid)

        # ===== XGBoost =====
        if XGBOOST_AVAILABLE:
            print("  âœ“ è®­ç»ƒ XGBoost...")
            self.xgb_model = xgb.XGBClassifier(
                objective='binary:logistic',
                eval_metric='auc',
                max_depth=5,  # é™ä½å¤æ‚åº¦
                learning_rate=0.03,
                n_estimators=300,
                subsample=0.7,
                colsample_bytree=0.7,
                random_state=42,
                n_jobs=-1
            )

            try:
                self.xgb_model.fit(
                    X_train_scaled, y_train,
                    eval_set=[(X_valid_scaled, y_valid)],
                    early_stopping_rounds=30,
                    verbose=verbose
                )
            except:
                self.xgb_model.fit(X_train_scaled, y_train)

        # ===== LightGBM =====
        if LIGHTGBM_AVAILABLE:
            print("  âœ“ è®­ç»ƒ LightGBM...")
            self.lgb_model = lgb.LGBMClassifier(
                objective='binary',
                metric='auc',
                max_depth=5,
                learning_rate=0.03,
                n_estimators=300,
                subsample=0.7,
                colsample_bytree=0.7,
                random_state=42,
                n_jobs=-1,
                verbose=-1
            )

            try:
                self.lgb_model.fit(
                    X_train_scaled, y_train,
                    eval_set=[(X_valid_scaled, y_valid)],
                    callbacks=[lgb.early_stopping(30, verbose=verbose)]
                )
            except:
                self.lgb_model.fit(X_train_scaled, y_train)

        # è¯„ä¼°
        y_pred = self.predict_proba(X_valid)
        auc = roc_auc_score(y_valid, y_pred)
        print(f"  âœ“ é›†æˆéªŒè¯AUC: {auc:.4f}")

        return self

    def predict_proba(self, X):
        """é›†æˆé¢„æµ‹"""
        X_scaled = self.scaler.transform(X)

        predictions = []

        if self.xgb_model is not None:
            pred_xgb = self.xgb_model.predict_proba(X_scaled)[:, 1]
            predictions.append(pred_xgb)

        if self.lgb_model is not None:
            pred_lgb = self.lgb_model.predict_proba(X_scaled)[:, 1]
            predictions.append(pred_lgb)

        if len(predictions) == 0:
            raise ValueError("æ²¡æœ‰å¯ç”¨æ¨¡å‹")

        # ===== æŠ•ç¥¨ç­–ç•¥ =====
        if self.voting_strategy == 'average':
            # ç®€å•å¹³å‡
            return np.mean(predictions, axis=0)

        elif self.voting_strategy == 'strict':
            # ä¸¥æ ¼æ¨¡å¼ï¼šä¸¤ä¸ªéƒ½çœ‹å¤šæ‰ç»™é«˜åˆ†
            avg_pred = np.mean(predictions, axis=0)

            # åªæœ‰å½“ä¸¤ä¸ªæ¨¡å‹éƒ½è¶…è¿‡é˜ˆå€¼æ—¶ï¼Œæ‰ä¿ç•™åŸå§‹åˆ†æ•°
            if len(predictions) == 2:
                both_bullish = (predictions[0] > self.strict_threshold) & \
                               (predictions[1] > self.strict_threshold)
                return np.where(both_bullish, avg_pred, avg_pred * 0.5)
            else:
                return avg_pred


# ============================================================================
# ä¼˜åŒ–4: Precision@K è¯„ä¼°å™¨
# ============================================================================

class PrecisionAtKEvaluator:
    """
    Precision@K è¯„ä¼°å™¨

    å…³æ³¨æŒ‡æ ‡ï¼š
    - Precision@20%: Top 20% ä¸­æœ‰å¤šå°‘æ˜¯çœŸæ­£çš„èµ¢å®¶
    - Recall@20%: çœŸæ­£çš„èµ¢å®¶æœ‰å¤šå°‘è¢«é€‰ä¸­
    """

    @staticmethod
    def precision_at_k(y_true, y_pred_proba, k=0.2):
        """
        è®¡ç®— Precision@K

        Args:
            y_true: çœŸå®æ ‡ç­¾
            y_pred_proba: é¢„æµ‹æ¦‚ç‡
            k: Top Kæ¯”ä¾‹

        Returns:
            precision, recall
        """
        n = len(y_true)
        top_k = int(n * k)

        # é€‰å‡ºTop K
        top_k_idx = np.argsort(y_pred_proba)[-top_k:]

        y_true_top = y_true[top_k_idx]

        precision = y_true_top.sum() / len(y_true_top) if len(y_true_top) > 0 else 0
        recall = y_true_top.sum() / y_true.sum() if y_true.sum() > 0 else 0

        return precision, recall

    @staticmethod
    def evaluate_model(model, X_valid, y_valid, k=0.2):
        """å®Œæ•´è¯„ä¼°"""
        y_pred_proba = model.predict_proba(X_valid)

        auc = roc_auc_score(y_valid, y_pred_proba)
        prec, rec = PrecisionAtKEvaluator.precision_at_k(y_valid, y_pred_proba, k)

        print(f"    AUC: {auc:.4f}")
        print(f"    Precision@{int(k*100)}%: {prec:.4f}")
        print(f"    Recall@{int(k*100)}%: {rec:.4f}")

        return {'auc': auc, 'precision': prec, 'recall': rec}


# ============================================================================
# è¶…çº§MLè¯„åˆ†å™¨ (æ•´åˆå››å¤§ä¼˜åŒ–)
# ============================================================================

class UltraMLScorer:
    """
    è¶…çº§MLè¯„åˆ†å™¨

    æ•´åˆï¼š
    1. âœ… Purging & Embargo
    2. âœ… Feature Orthogonalization
    3. âœ… Ensemble Voting
    4. âœ… Precision@K Focus
    """

    def __init__(self,
                 target_period=5,
                 top_percentile=0.20,
                 embargo_days=5,
                 neutralize_market=True,
                 neutralize_industry=True,
                 voting_strategy='average',
                 train_months=12,
                 random_state=42):

        self.target_period = target_period
        self.top_percentile = top_percentile
        self.embargo_days = embargo_days
        self.neutralize_market = neutralize_market
        self.neutralize_industry = neutralize_industry
        self.voting_strategy = voting_strategy
        self.train_months = train_months
        self.random_state = random_state

        self.orthogonalizer = FeatureOrthogonalizer(
            neutralize_market, neutralize_industry
        )
        self.ensemble = EnsembleVotingScorer(voting_strategy)
        self.feature_names = None

        print(f"\nğŸš€ è¶…çº§MLè¯„åˆ†å™¨")
        print(f"  âœ… æ•°æ®éš”ç¦»: {embargo_days}å¤©Gap")
        print(f"  âœ… ç‰¹å¾æ­£äº¤: å¸‚åœº={neutralize_market}, è¡Œä¸š={neutralize_industry}")
        print(f"  âœ… é›†æˆæŠ•ç¥¨: {voting_strategy}")
        print(f"  âœ… ç›®æ ‡ä¼˜åŒ–: Precision@{int(top_percentile*100)}%")

    def prepare_data(self, factor_data, price_data, factor_columns):
        """å‡†å¤‡æ•°æ® + ç‰¹å¾æ­£äº¤åŒ–"""
        print(f"\nğŸ“¦ å‡†å¤‡è®­ç»ƒæ•°æ®...")

        # æ£€æµ‹ä»·æ ¼åˆ—
        price_col = self._detect_price_column(price_data)
        if price_col is None:
            raise ValueError("æœªæ‰¾åˆ°ä»·æ ¼åˆ—")

        # åˆå¹¶
        merged = factor_data.merge(
            price_data[['instrument', 'date', price_col]],
            on=['instrument', 'date'],
            how='left'
        )
        merged = merged.sort_values(['instrument', 'date'])

        # ===== ç‰¹å¾æ­£äº¤åŒ– =====
        merged = self.orthogonalizer.fit_transform(
            merged, factor_columns, price_data
        )

        # ===== è®¡ç®—è¶…é¢æ”¶ç›Šç›®æ ‡ =====
        merged['abs_return'] = merged.groupby('instrument')[price_col].pct_change(
            self.target_period
        ).shift(-self.target_period)

        market_return = merged.groupby('date')['abs_return'].transform('mean')
        merged['future_return'] = merged['abs_return'] - market_return

        # åˆ†ç±»ç›®æ ‡
        merged['target'] = 0
        for date in merged['date'].unique():
            date_mask = merged['date'] == date
            returns = merged.loc[date_mask, 'future_return']
            if len(returns) > 5:
                threshold = returns.quantile(1 - self.top_percentile)
                merged.loc[date_mask & (merged['future_return'] >= threshold), 'target'] = 1

        # è¿‡æ»¤
        merged = merged.dropna(subset=['target'])

        print(f"  âœ“ æœ‰æ•ˆæ ·æœ¬: {len(merged)}")
        print(f"  âœ“ æ­£æ ·æœ¬æ¯”ä¾‹: {merged['target'].mean():.2%}")

        # æ„å»ºç‰¹å¾
        exclude = [
            'date', 'instrument', 'future_return', 'abs_return',
            'target', price_col, 'industry', 'year_month'
        ]
        feature_cols = [c for c in merged.columns
                       if c not in exclude and pd.api.types.is_numeric_dtype(merged[c])]

        X = merged[feature_cols].copy()
        X = X.replace([np.inf, -np.inf], np.nan).fillna(X.median())
        y = merged['target'].values

        self.feature_names = feature_cols

        return X, y, merged

    def train(self, X, y, merged, verbose=True):
        """Walk-Forwardè®­ç»ƒ + Purging"""
        print(f"\nğŸ¯ Walk-Forwardè®­ç»ƒ (Purging={self.embargo_days}å¤©)...")

        # ä½¿ç”¨ä¼˜åŒ–çš„åˆ‡åˆ†å™¨
        splitter = PurgingEmbargoSplitter(
            train_months=self.train_months,
            valid_months=1,
            test_months=1,
            embargo_days=self.embargo_days
        )

        splits = splitter.split(merged, date_column='date')

        if len(splits) == 0:
            print("  âš ï¸  æ•°æ®ä¸è¶³")
            return self

        print(f"  âœ“ ç”Ÿæˆ {len(splits)} ä¸ªçª—å£")

        best_model = None
        best_score = -np.inf

        for i, (train_idx, valid_idx, test_idx) in enumerate(splits):
            X_train = X.iloc[train_idx]
            y_train = y[train_idx]
            X_valid = X.iloc[valid_idx]
            y_valid = y[valid_idx]

            print(f"\n  çª—å£ {i+1}/{len(splits)}")

            # è®­ç»ƒé›†æˆæ¨¡å‹
            ensemble = EnsembleVotingScorer(self.voting_strategy)
            ensemble.train(X_train, y_train, X_valid, y_valid, verbose=False)

            # ===== Precision@K è¯„ä¼° =====
            metrics = PrecisionAtKEvaluator.evaluate_model(
                ensemble, X_valid, y_valid, self.top_percentile
            )

            # ä½¿ç”¨ Precision@K ä½œä¸ºé€‰æ‹©æ ‡å‡†ï¼ˆè€ŒéAUCï¼‰
            score = metrics['precision']

            if score > best_score:
                best_score = score
                best_model = ensemble

        self.ensemble = best_model
        print(f"\n  âœ“ æœ€ä½³æ¨¡å‹ Precision@{int(self.top_percentile*100)}%: {best_score:.4f}")

        return self

    def predict(self, factor_data, price_data=None):
        """é¢„æµ‹è¯„åˆ†"""
        if price_data is not None:
            # é‡æ–°è®­ç»ƒ
            X, y, merged = self.prepare_data(
                factor_data, price_data, self.feature_names
            )
            self.train(X, y, merged, verbose=False)
            factor_data = merged.copy()

        print(f"\nğŸ¯ é¢„æµ‹è¯„åˆ†...")

        valid_features = [c for c in self.feature_names if c in factor_data.columns]
        X = factor_data[valid_features].copy()
        X = X.replace([np.inf, -np.inf], np.nan).fillna(X.median())

        predicted_proba = self.ensemble.predict_proba(X)
        factor_data['ml_score'] = predicted_proba
        factor_data['position'] = factor_data.groupby('date')['ml_score'].rank(pct=True)

        print(f"  âœ“ é¢„æµ‹å®Œæˆ")
        print(f"  âœ“ Top 20% å¹³å‡åˆ†: {factor_data[factor_data['position']>=0.8]['ml_score'].mean():.4f}")

        return factor_data

    def _detect_price_column(self, df):
        candidates = ['close', 'Close', 'CLOSE', 'price', 'Price']
        for col in candidates:
            if col in df.columns:
                return col
        return None


# ============================================================================
# ä½¿ç”¨ç¤ºä¾‹
# ============================================================================

def demo_ultra_scorer():
    """æ¼”ç¤ºè¶…çº§è¯„åˆ†å™¨"""
    print("="*80)
    print("è¶…çº§MLè¯„åˆ†å™¨ - å››å¤§ä¼˜åŒ–æ¼”ç¤º")
    print("="*80)

    # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
    np.random.seed(42)
    dates = pd.date_range('2023-01-01', periods=400, freq='D')
    instruments = [f'STOCK_{i:03d}' for i in range(100)]

    data = []
    for date in dates:
        for inst in instruments:
            data.append({
                'date': date,
                'instrument': inst,
                'close': 100 + np.random.randn() * 10,
                'factor1': np.random.randn(),
                'factor2': np.random.randn(),
                'factor3': np.random.randn(),
                'industry': np.random.choice(['ç§‘æŠ€', 'é‡‘è', 'æ¶ˆè´¹', 'åŒ»è¯'])
            })

    df = pd.DataFrame(data)

    factor_cols = ['factor1', 'factor2', 'factor3']

    # åˆå§‹åŒ–è¶…çº§è¯„åˆ†å™¨
    scorer = UltraMLScorer(
        target_period=5,
        top_percentile=0.20,
        embargo_days=5,
        neutralize_market=True,
        neutralize_industry=True,
        voting_strategy='average',
        train_months=6
    )

    # å‡†å¤‡æ•°æ®
    X, y, merged = scorer.prepare_data(
        df, df, factor_cols
    )

    # è®­ç»ƒ
    scorer.train(X, y, merged)

    # é¢„æµ‹
    result = scorer.predict(df.tail(500), df)

    print("\n" + "="*80)
    print("âœ… æ¼”ç¤ºå®Œæˆï¼")
    print("="*80)


if __name__ == '__main__':
    demo_ultra_scorer()