"""
ml_factor_scoring_fixed.py - ä¿®å¤ç‰ˆæœºå™¨å­¦ä¹ å› å­è¯„åˆ†æ¨¡å—

ä¿®å¤å†…å®¹ï¼š
1. âœ… ä¿®å¤IndustryBasedScorerè¡Œä¸šæ•°æ®è·å–
2. âœ… ä¿®å¤EnhancedStockSelectorè¡Œä¸šåˆ—è®¿é—®
3. âœ… æ”¹è¿›é”™è¯¯å¤„ç†å’Œæç¤ºä¿¡æ¯
4. âœ… ä¿®å¤ç‰¹å¾åˆ—æ£€æµ‹é€»è¾‘ - å¤„ç†åªæœ‰positionåˆ—çš„æƒ…å†µ
"""

import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings('ignore')

# æœºå™¨å­¦ä¹ åº“
try:
    import xgboost as xgb
    XGBOOST_AVAILABLE = True
except ImportError:
    print("âš ï¸  XGBoost æœªå®‰è£…ï¼Œè¿è¡Œ: pip install xgboost")
    xgb = None
    XGBOOST_AVAILABLE = False

try:
    import lightgbm as lgb
    LIGHTGBM_AVAILABLE = True
except ImportError:
    print("âš ï¸  LightGBM æœªå®‰è£…ï¼Œè¿è¡Œ: pip install lightgbm")
    lgb = None
    LIGHTGBM_AVAILABLE = False

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler


# ============================================================================
# å·¥å…·å‡½æ•°
# ============================================================================

def detect_price_column(df):
    """æ™ºèƒ½æ£€æµ‹ä»·æ ¼åˆ—"""
    price_candidates = [
        'close', 'Close', 'CLOSE',
        'close_price', 'closing_price', 
        'price', 'Price'
    ]
    
    for col in price_candidates:
        if col in df.columns:
            print(f"  âœ“ æ£€æµ‹åˆ°ä»·æ ¼åˆ—: {col}")
            return col
    
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    print(f"  âš ï¸  æœªæ‰¾åˆ°æ ‡å‡†ä»·æ ¼åˆ—ï¼Œå¯ç”¨æ•°å€¼åˆ—: {numeric_cols}")
    return None


def get_industry_data(instruments, tushare_token=None):
    """è·å–è‚¡ç¥¨è¡Œä¸šä¿¡æ¯"""
    print("\nğŸ¢ è·å–è¡Œä¸šæ•°æ®...")
    
    if tushare_token is None:
        print("  âš ï¸  æœªæä¾› Tushare Tokenï¼Œä½¿ç”¨é»˜è®¤è¡Œä¸šåˆ†ç±»")
        return pd.DataFrame({
            'instrument': instruments,
            'industry': 'Unknown'
        })
    
    try:
        import tushare as ts
        ts.set_token(tushare_token)
        pro = ts.pro_api()
        
        stock_basic = pro.stock_basic(
            exchange='',
            list_status='L',
            fields='ts_code,industry'
        )
        
        stock_basic['instrument'] = stock_basic['ts_code']
        
        industry_data = stock_basic[
            stock_basic['instrument'].isin(instruments)
        ][['instrument', 'industry']]
        
        industry_data['industry'] = industry_data['industry'].fillna('Unknown')
        
        print(f"  âœ“ è·å–äº† {len(industry_data)} åªè‚¡ç¥¨çš„è¡Œä¸šä¿¡æ¯")
        industry_count = industry_data['industry'].nunique()
        print(f"  âœ“ æ¶µç›– {industry_count} ä¸ªè¡Œä¸š")
        
        return industry_data
        
    except Exception as e:
        print(f"  âš ï¸  è·å–è¡Œä¸šæ•°æ®å¤±è´¥: {e}")
        print(f"  ä½¿ç”¨é»˜è®¤è¡Œä¸šåˆ†ç±»")
        return pd.DataFrame({
            'instrument': instruments,
            'industry': 'Unknown'
        })


# ============================================================================
# æ ¸å¿ƒç±»: MLFactorScorer
# ============================================================================

class MLFactorScorer:
    """æœºå™¨å­¦ä¹ å› å­è¯„åˆ†å™¨"""
    
    def __init__(self, model_type='xgboost', target_period=5, random_state=42):
        self.model_type = model_type
        self.target_period = target_period
        self.random_state = random_state
        
        self.model = None
        self.scaler = StandardScaler()
        self.feature_names = None
        self.feature_importance = None
        
        if model_type == 'xgboost' and not XGBOOST_AVAILABLE:
            raise ImportError("XGBoost æœªå®‰è£…")
        if model_type == 'lightgbm' and not LIGHTGBM_AVAILABLE:
            raise ImportError("LightGBM æœªå®‰è£…")
    
    def prepare_training_data(self, factor_data, price_data):
        """å‡†å¤‡è®­ç»ƒæ•°æ®"""
        print(f"\nğŸ¤– å‡†å¤‡è®­ç»ƒæ•°æ® (ç›®æ ‡å‘¨æœŸ: {self.target_period}æ—¥)...")
        
        price_col = detect_price_column(price_data)
        if price_col is None:
            raise ValueError("æœªæ‰¾åˆ°ä»·æ ¼åˆ—ï¼Œæ— æ³•å‡†å¤‡è®­ç»ƒæ•°æ®")
        
        merged = factor_data.merge(
            price_data[['instrument', 'date', price_col]],
            on=['instrument', 'date'],
            how='left'
        )
        
        print(f"  âœ“ åˆå¹¶æ•°æ®: {len(merged)} æ¡è®°å½•")
        
        merged = merged.sort_values(['instrument', 'date'])
        merged['future_return'] = merged.groupby('instrument')[price_col].pct_change(
            self.target_period
        ).shift(-self.target_period)
        
        initial_len = len(merged)
        merged = merged.dropna(subset=['future_return'])
        
        print(f"  âœ“ è®¡ç®—æœªæ¥{self.target_period}æ—¥æ”¶ç›Šç‡")
        print(f"  âœ“ æœ‰æ•ˆæ ·æœ¬: {len(merged)} / {initial_len} ({len(merged)/initial_len*100:.1f}%)")
        
        # âœ¨ å…³é”®ä¿®å¤ï¼šæ›´æ™ºèƒ½çš„ç‰¹å¾åˆ—æ£€æµ‹
        # åŸºç¡€æ’é™¤åˆ—ï¼ˆå¿…é¡»æ’é™¤çš„ï¼‰
        base_exclude = [
            'date', 'instrument', 'future_return', price_col,
            'industry', 'ml_score', 'industry_rank'
        ]
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„ç‰¹å¾åˆ—
        all_numeric_cols = merged.select_dtypes(include=[np.number]).columns.tolist()
        potential_features = [col for col in all_numeric_cols if col not in base_exclude]
        
        print(f"  âœ“ æ£€æµ‹åˆ° {len(potential_features)} ä¸ªæ½œåœ¨ç‰¹å¾åˆ—")
        
        # âœ¨ å¦‚æœåªæœ‰positionåˆ—ï¼Œå°†å…¶ä½œä¸ºç‰¹å¾ï¼ˆä¸æ’é™¤ï¼‰
        if len(potential_features) == 0:
            print("  âš ï¸  è­¦å‘Šï¼šæ²¡æœ‰æ£€æµ‹åˆ°å¸¸è§„ç‰¹å¾åˆ—")
            # å°è¯•ä½¿ç”¨positionä½œä¸ºç‰¹å¾
            if 'position' in merged.columns:
                print("  âœ“ ä½¿ç”¨ 'position' ä½œä¸ºå”¯ä¸€ç‰¹å¾åˆ—")
                feature_cols = ['position']
            else:
                raise ValueError("æ²¡æœ‰ä»»ä½•å¯ç”¨çš„ç‰¹å¾åˆ—ç”¨äºè®­ç»ƒ")
        elif len(potential_features) == 1 and potential_features[0] == 'position':
            # å¦‚æœå”¯ä¸€çš„ç‰¹å¾å°±æ˜¯positionï¼Œç›´æ¥ä½¿ç”¨
            feature_cols = ['position']
            print("  âœ“ ä½¿ç”¨ 'position' ä½œä¸ºå”¯ä¸€ç‰¹å¾åˆ—")
        else:
            # æ­£å¸¸æƒ…å†µï¼šæ’é™¤positionï¼Œä½¿ç”¨å…¶ä»–æŠ€æœ¯å› å­
            feature_cols = [col for col in potential_features if col != 'position']
            if len(feature_cols) == 0:
                # å¦‚æœæ’é™¤positionåæ²¡æœ‰å…¶ä»–ç‰¹å¾ï¼Œè¿˜æ˜¯ä½¿ç”¨position
                feature_cols = ['position']
                print("  âœ“ ä½¿ç”¨ 'position' ä½œä¸ºå”¯ä¸€ç‰¹å¾åˆ—")
            else:
                print(f"  âœ“ ä½¿ç”¨ {len(feature_cols)} ä¸ªç‰¹å¾åˆ—ï¼ˆå·²æ’é™¤positionï¼‰")
        
        X = merged[feature_cols].copy()
        X = X.replace([np.inf, -np.inf], np.nan)
        
        if X.isnull().all().all():
            raise ValueError("ç‰¹å¾æ•°æ®å…¨ä¸ºNaNï¼Œæ— æ³•è¿›è¡Œè®­ç»ƒ")
        
        X = X.fillna(X.median())
        y = merged['future_return'].values
        
        if len(y) == 0 or np.isnan(y).all():
            raise ValueError("ç›®æ ‡å€¼æ— æ•ˆï¼Œæ— æ³•è¿›è¡Œè®­ç»ƒ")
        
        self.feature_names = feature_cols
        
        print(f"  âœ“ æœ€ç»ˆç‰¹å¾æ•°é‡: {len(feature_cols)}")
        if len(feature_cols) > 0:
            print(f"  âœ“ ç‰¹å¾åˆ—è¡¨: {', '.join(feature_cols[:10])}{'...' if len(feature_cols) > 10 else ''}")
        
        return X, y, merged
    
    def train(self, X, y, test_size=0.2, verbose=True):
        """è®­ç»ƒæ¨¡å‹"""
        print(f"\nğŸš€ è®­ç»ƒ {self.model_type.upper()} æ¨¡å‹...")
        
        if len(X) == 0 or len(y) == 0:
            raise ValueError("è®­ç»ƒæ•°æ®ä¸ºç©º")
        
        if len(X) != len(y):
            raise ValueError(f"ç‰¹å¾çŸ©é˜µå’Œç›®æ ‡æ ‡ç­¾é•¿åº¦ä¸åŒ¹é…: {len(X)} vs {len(y)}")
        
        if not isinstance(X, pd.DataFrame):
            X = pd.DataFrame(X)
        
        y = np.array(y)
        
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, 
            test_size=test_size, 
            random_state=self.random_state,
            shuffle=True
        )
        
        print(f"  è®­ç»ƒé›†: {len(X_train)} æ ·æœ¬")
        print(f"  æµ‹è¯•é›†: {len(X_test)} æ ·æœ¬")
        
        if len(X_train) == 0 or len(X_test) == 0:
            raise ValueError("æ•°æ®é›†åˆ’åˆ†åè®­ç»ƒé›†æˆ–æµ‹è¯•é›†ä¸ºç©º")
        
        if not isinstance(X_train, pd.DataFrame):
            X_train = pd.DataFrame(X_train)
        if not isinstance(X_test, pd.DataFrame):
            X_test = pd.DataFrame(X_test)
        
        try:
            X_train_values = X_train.values
            X_test_values = X_test.values
            
            if np.isnan(X_train_values).any() or np.isinf(X_train_values).any():
                print("  âš ï¸  è®­ç»ƒæ•°æ®ä¸­å­˜åœ¨NaNæˆ–æ— ç©·å€¼ï¼Œè¿›è¡Œæ¸…ç†...")
                X_train = X_train.replace([np.inf, -np.inf], np.nan).fillna(0)
            
            if np.isnan(X_test_values).any() or np.isinf(X_test_values).any():
                print("  âš ï¸  æµ‹è¯•æ•°æ®ä¸­å­˜åœ¨NaNæˆ–æ— ç©·å€¼ï¼Œè¿›è¡Œæ¸…ç†...")
                X_test = X_test.replace([np.inf, -np.inf], np.nan).fillna(0)
        except Exception as e:
            print(f"  âš ï¸  æ•°æ®æ£€æŸ¥å¤±è´¥: {e}")
        
        if len(X_train) == 0 or len(X_test) == 0:
            raise ValueError("æ•°æ®æ¸…ç†åè®­ç»ƒé›†æˆ–æµ‹è¯•é›†ä¸ºç©º")
        
        try:
            X_train_scaled = self.scaler.fit_transform(X_train)
            X_test_scaled = self.scaler.transform(X_test)
        except Exception as e:
            print(f"  âš ï¸  æ ‡å‡†åŒ–å¤±è´¥: {e}")
            X_train_scaled = X_train.values
            X_test_scaled = X_test.values
        
        if self.model_type == 'xgboost':
            self.model = self._train_xgboost(
                X_train_scaled, y_train, 
                X_test_scaled, y_test,
                verbose
            )
        elif self.model_type == 'lightgbm':
            self.model = self._train_lightgbm(
                X_train_scaled, y_train,
                X_test_scaled, y_test,
                verbose
            )
        
        try:
            train_pred = self.model.predict(X_train_scaled)
            test_pred = self.model.predict(X_test_scaled)
            
            train_corr = np.corrcoef(np.array(y_train), np.array(train_pred))[0, 1] if len(y_train) > 1 else 0
            test_corr = np.corrcoef(np.array(y_test), np.array(test_pred))[0, 1] if len(y_test) > 1 else 0
            
            print(f"\n  ğŸ“Š æ¨¡å‹è¯„ä¼°:")
            print(f"     è®­ç»ƒé›†ç›¸å…³æ€§: {train_corr:.4f}")
            print(f"     æµ‹è¯•é›†ç›¸å…³æ€§: {test_corr:.4f}")
        except Exception as e:
            print(f"  âš ï¸  æ¨¡å‹è¯„ä¼°å¤±è´¥: {e}")
        
        self._extract_feature_importance()
        return self
    
    def _train_xgboost(self, X_train, y_train, X_val, y_val, verbose):
        """è®­ç»ƒ XGBoost æ¨¡å‹"""
        if not XGBOOST_AVAILABLE or xgb is None:
            raise ImportError("XGBoost æœªå®‰è£…")
            
        params = {
            'objective': 'reg:squarederror',
            'max_depth': 6,
            'learning_rate': 0.05,
            'n_estimators': 200,
            'subsample': 0.8,
            'colsample_bytree': 0.8,
            'random_state': self.random_state,
            'n_jobs': -1
        }
        
        model = xgb.XGBRegressor(**params)
        
        try:
            model.fit(
                X_train, y_train,
                eval_set=[(X_val, y_val)],
                early_stopping_rounds=20,
                verbose=verbose
            )
        except TypeError:
            model.fit(
                X_train, y_train,
                eval_set=[(X_val, y_val)],
                verbose=verbose
            )
        
        return model
    
    def _train_lightgbm(self, X_train, y_train, X_val, y_val, verbose):
        """è®­ç»ƒ LightGBM æ¨¡å‹"""
        if not LIGHTGBM_AVAILABLE or lgb is None:
            raise ImportError("LightGBM æœªå®‰è£…")
            
        params = {
            'objective': 'regression',
            'metric': 'rmse',
            'max_depth': 6,
            'learning_rate': 0.05,
            'n_estimators': 200,
            'subsample': 0.8,
            'colsample_bytree': 0.8,
            'random_state': self.random_state,
            'n_jobs': -1,
            'verbose': -1
        }
        
        model = lgb.LGBMRegressor(**params)
        
        try:
            model.fit(
                X_train, y_train,
                eval_set=[(X_val, y_val)],
                callbacks=[lgb.early_stopping(20, verbose=verbose)]
            )
        except Exception:
            model.fit(
                X_train, y_train,
                eval_set=[(X_val, y_val)]
            )

        return model
    
    def _extract_feature_importance(self):
        """æå–ç‰¹å¾é‡è¦æ€§"""
        if self.model is None:
            return
        
        importance = self.model.feature_importances_
        importance_sum = np.sum(importance)
        if importance_sum > 0:
            importance = importance / importance_sum
        
        if self.feature_names is not None:
            self.feature_importance = dict(zip(list(self.feature_names), list(importance)))
        
        if self.feature_importance:
            sorted_importance = sorted(
                self.feature_importance.items(),
                key=lambda x: x[1],
                reverse=True
            )
            
            print(f"\n  ğŸ¯ ç‰¹å¾é‡è¦æ€§ TOP5:")
            for i, (feature, score) in enumerate(sorted_importance[:5], 1):
                print(f"     {i}. {feature}: {score:.4f}")
    
    def predict_scores(self, factor_data, price_data=None):
        """é¢„æµ‹è¯„åˆ†"""
        if price_data is not None:
            X, y, merged = self.prepare_training_data(factor_data, price_data)
            self.train(X, y, verbose=False)
            factor_data = merged.copy()
        
        if self.model is None:
            raise ValueError("æ¨¡å‹æœªè®­ç»ƒï¼Œè¯·æä¾› price_data æˆ–å…ˆè°ƒç”¨ train()")
        
        print(f"\nğŸ¯ é¢„æµ‹è‚¡ç¥¨è¯„åˆ†...")
        
        X = factor_data[self.feature_names].copy()
        X = X.replace([np.inf, -np.inf], np.nan)
        X = X.fillna(X.median())
        
        X_scaled = self.scaler.transform(X)
        predicted_returns = self.model.predict(X_scaled)
        
        factor_data['ml_score'] = predicted_returns
        factor_data['position'] = factor_data.groupby('date')['ml_score'].rank(pct=True)
        
        print(f"  âœ“ é¢„æµ‹å®Œæˆ")
        pred_returns_array = np.array(predicted_returns)
        print(f"  âœ“ å¹³å‡é¢„æµ‹æ”¶ç›Š: {pred_returns_array.mean():.4f}")
        print(f"  âœ“ é¢„æµ‹æ”¶ç›Šæ ‡å‡†å·®: {pred_returns_array.std():.4f}")
        
        return factor_data
    
    def get_feature_importance(self):
        """è·å–ç‰¹å¾é‡è¦æ€§å­—å…¸"""
        if self.feature_importance is None:
            return {}
        return self.feature_importance
    
    def dynamic_weight_adjustment(self, factor_data, factor_columns):
        """åŠ¨æ€æƒé‡è°ƒæ•´"""
        weights = {}
        for col in factor_columns:
            if col in factor_data.columns:
                std = factor_data[col].std()
                weights[col] = 1.0 / (std + 1e-6) if std > 0 else 1.0
        
        total_weight = sum(weights.values())
        if total_weight > 0:
            weights = {k: v/total_weight for k, v in weights.items()}
            
        return weights


# ============================================================================
# åˆ†è¡Œä¸šè¯„åˆ†å™¨ï¼ˆä¿®å¤ç‰ˆï¼‰
# ============================================================================

class IndustryBasedScorer:
    """åˆ†è¡Œä¸šè¯„åˆ†å™¨"""
    
    def __init__(self, tushare_token=None):
        self.tushare_token = tushare_token
        self.industry_data = None
    
    def score_by_industry(self, factor_data, factor_columns=None):
        """åˆ†è¡Œä¸šè¯„åˆ†"""
        print("\nğŸ¢ åˆ†è¡Œä¸šè¯„åˆ†...")
        
        # 1. è·å–è¡Œä¸šæ•°æ®
        instruments = factor_data['instrument'].unique()
        self.industry_data = get_industry_data(instruments, self.tushare_token)
        
        # 2. åˆå¹¶è¡Œä¸šæ•°æ®
        if self.industry_data is not None and len(self.industry_data) > 0:
            if 'industry' in factor_data.columns:
                factor_data = factor_data.drop(columns=['industry'])
            
            factor_data = factor_data.merge(
                self.industry_data,
                on='instrument',
                how='left'
            )
            
            factor_data['industry'] = factor_data['industry'].fillna('Unknown')
            
            print(f"  âœ“ æˆåŠŸåˆå¹¶è¡Œä¸šæ•°æ®")
            print(f"  âœ“ æ¶µç›–è¡Œä¸šæ•°: {factor_data['industry'].nunique()}")
        
        # 3. ç¡®ä¿æœ‰industryåˆ—
        if 'industry' not in factor_data.columns:
            print("  âš ï¸  æœªæ‰¾åˆ°è¡Œä¸šæ•°æ®ï¼Œæ·»åŠ é»˜è®¤è¡Œä¸š")
            factor_data['industry'] = 'Unknown'
        
        # 4. æŒ‰è¡Œä¸šåˆ†ç»„è¿›è¡Œæ’å
        try:
            factor_data['industry_rank'] = factor_data.groupby(['date', 'industry'])['position'].rank(pct=True)
            print(f"  âœ“ è¡Œä¸šè¯„åˆ†å®Œæˆ")
        except Exception as e:
            print(f"  âš ï¸  è¡Œä¸šæ’åå¤±è´¥: {e}")
            factor_data['industry_rank'] = factor_data['position']
        
        return factor_data


# ============================================================================
# å¢å¼ºé€‰è‚¡å™¨ï¼ˆä¿®å¤ç‰ˆï¼‰
# ============================================================================

class EnhancedStockSelector:
    """å¢å¼ºé€‰è‚¡å™¨"""
    
    def __init__(self):
        pass
    
    def select_stocks(self, factor_data, min_score=0.6, max_concentration=0.15, max_industry_concentration=0.3):
        """é€‰è‚¡"""
        print(f"\nğŸ¯ å¢å¼ºé€‰è‚¡ (é˜ˆå€¼: {min_score})...")
        
        # 1. è¿‡æ»¤ä½åˆ†è‚¡ç¥¨
        filtered = factor_data[factor_data['position'] >= min_score].copy()
        print(f"  âœ“ è¯„åˆ†è¿‡æ»¤: {len(filtered)} / {len(factor_data)} åªè‚¡ç¥¨")
        
        # 2. ç¡®ä¿æœ‰è¡Œä¸šåˆ—
        if 'industry' not in filtered.columns:
            print("  âš ï¸  ç¼ºå°‘è¡Œä¸šä¿¡æ¯ï¼Œæ·»åŠ é»˜è®¤è¡Œä¸š")
            filtered['industry'] = 'Unknown'
        
        # 3. å¡«å……ç¼ºå¤±çš„è¡Œä¸šå€¼
        filtered['industry'] = filtered['industry'].fillna('Unknown')
        
        # 4. æŒ‰è¡Œä¸šåˆ†ç»„ï¼Œæ§åˆ¶è¡Œä¸šé›†ä¸­åº¦
        max_stocks_per_industry = max(1, int(len(filtered) * max_industry_concentration))
        
        selected_stocks = []
        industry_selected = {}
        
        # æŒ‰è¯„åˆ†æ’åº
        filtered = filtered.sort_values('position', ascending=False)
        
        for idx, row in filtered.iterrows():
            industry = row['industry']
            
            if pd.isna(industry):
                industry = 'Unknown'
            
            if industry not in industry_selected:
                industry_selected[industry] = 0
            
            if industry_selected[industry] < max_stocks_per_industry:
                selected_stocks.append(idx)
                industry_selected[industry] += 1
        
        # 5. è¿”å›é€‰ä¸­çš„è‚¡ç¥¨
        if len(selected_stocks) == 0:
            print("  âš ï¸  æ²¡æœ‰é€‰ä¸­ä»»ä½•è‚¡ç¥¨ï¼Œè¿”å›åŸæ•°æ®")
            return filtered
        
        result = factor_data.loc[selected_stocks].copy()
        print(f"  âœ“ è¡Œä¸šåˆ†æ•£: æœ€ç»ˆé€‰æ‹© {len(result)} åªè‚¡ç¥¨")
        
        if 'industry' in result.columns:
            print(f"  âœ“ æ¶‰åŠè¡Œä¸š: {result['industry'].nunique()} ä¸ª")
        
        return result


# å¯¼å‡ºç±»å’Œå‡½æ•°
__all__ = [
    'MLFactorScorer',
    'IndustryBasedScorer',
    'EnhancedStockSelector'
]